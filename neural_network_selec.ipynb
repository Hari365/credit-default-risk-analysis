{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_tr = pd.read_csv('application_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = app_tr['TARGET'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del app_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pd.read_csv('ready_for_model_building_appl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = app[['SK_ID_CURR',\n",
    "'AMT_INCOME_TOTAL',\n",
    "'AMT_CREDIT',\n",
    "'AMT_ANNUITY_x',\n",
    "'AMT_GOODS_PRICE',\n",
    "'REGION_POPULATION_RELATIVE',\n",
    "'DAYS_BIRTH',\n",
    "'DAYS_EMPLOYED',\n",
    "'DAYS_REGISTRATION',\n",
    "'DAYS_ID_PUBLISH',\n",
    "'OWN_CAR_AGE',\n",
    "'HOUR_APPR_PROCESS_START',\n",
    "'EXT_SOURCE_1',\n",
    "'EXT_SOURCE_2',\n",
    "'EXT_SOURCE_3',\n",
    "'YEARS_BEGINEXPLUATATION_AVG',\n",
    "'LIVINGAREA_AVG',\n",
    "'YEARS_BEGINEXPLUATATION_MODE',\n",
    "'LIVINGAREA_MODE',\n",
    "'YEARS_BEGINEXPLUATATION_MEDI',\n",
    "'LIVINGAREA_MEDI',\n",
    "'TOTALAREA_MODE',\n",
    "'OBS_30_CNT_SOCIAL_CIRCLE',\n",
    "'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "'OBS_60_CNT_SOCIAL_CIRCLE',\n",
    "'DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "'DAYS_LAST_PHONE_CHANGE',\n",
    "'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    "'CREDIT_INCOME_RATIO',\n",
    "'ANNUITY_INCOME_RATIO',\n",
    "'CREDIT_GOODS_PRICE_DIFF',\n",
    "'ENTIRE_INCOME',\n",
    "'CREDIT_ENTIRE_INCOME_RATIO',\n",
    "'ANNUITY_ENTIRE_INCOME_RATIO',\n",
    "'INCOME_PER_CHILD',\n",
    "'INCOME_PER_FAM_MEMBER',\n",
    "'ENTIRE_INCOME_PER_FAM_MEMBER',\n",
    "'ENTIRE_INCOME_PER_CHILD',\n",
    "'AMT_REQ_CREDIT_BUREAU_TOTAL',\n",
    "'AMT_REQ_CREDIT_BUREAU_EMA',\n",
    "'DAYS_CREDIT',\n",
    "'CREDIT_DAY_OVERDUE',\n",
    "'DAYS_CREDIT_ENDDATE',\n",
    "'DAYS_ENDDATE_FACT',\n",
    "'AMT_CREDIT_MAX_OVERDUE',\n",
    "'AMT_CREDIT_SUM',\n",
    "'AMT_CREDIT_SUM_DEBT',\n",
    "'AMT_CREDIT_SUM_LIMIT',\n",
    "'AMT_CREDIT_SUM_OVERDUE',\n",
    "'DAYS_CREDIT_UPDATE',\n",
    "'AMT_ANNUITY_y',\n",
    "'Active_x',\n",
    "'Closed',\n",
    "'Consumer credit',\n",
    "'Credit card',\n",
    "'Microloan',\n",
    "'LATE_DAYS_x',\n",
    "'score',\n",
    "'STATUS_X',\n",
    "'NFLAG_INSURED_ON_APPROVAL',\n",
    "'DAYS_TERMINATION',\n",
    "'DAYS_LAST_DUE',\n",
    "'DAYS_LAST_DUE_1ST_VERSION',\n",
    "'DAYS_FIRST_DUE',\n",
    "'DAYS_FIRST_DRAWING',\n",
    "'LATE_DAYS_y',\n",
    "'EXTRA_DAYS']].values[:y.shape[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]==y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = app[['SK_ID_CURR',\n",
    "'AMT_INCOME_TOTAL',\n",
    "'AMT_CREDIT',\n",
    "'AMT_ANNUITY_x',\n",
    "'AMT_GOODS_PRICE',\n",
    "'REGION_POPULATION_RELATIVE',\n",
    "'DAYS_BIRTH',\n",
    "'DAYS_EMPLOYED',\n",
    "'DAYS_REGISTRATION',\n",
    "'DAYS_ID_PUBLISH',\n",
    "'OWN_CAR_AGE',\n",
    "'HOUR_APPR_PROCESS_START',\n",
    "'EXT_SOURCE_1',\n",
    "'EXT_SOURCE_2',\n",
    "'EXT_SOURCE_3',\n",
    "'YEARS_BEGINEXPLUATATION_AVG',\n",
    "'LIVINGAREA_AVG',\n",
    "'YEARS_BEGINEXPLUATATION_MODE',\n",
    "'LIVINGAREA_MODE',\n",
    "'YEARS_BEGINEXPLUATATION_MEDI',\n",
    "'LIVINGAREA_MEDI',\n",
    "'TOTALAREA_MODE',\n",
    "'OBS_30_CNT_SOCIAL_CIRCLE',\n",
    "'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "'OBS_60_CNT_SOCIAL_CIRCLE',\n",
    "'DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "'DAYS_LAST_PHONE_CHANGE',\n",
    "'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    "'CREDIT_INCOME_RATIO',\n",
    "'ANNUITY_INCOME_RATIO',\n",
    "'CREDIT_GOODS_PRICE_DIFF',\n",
    "'ENTIRE_INCOME',\n",
    "'CREDIT_ENTIRE_INCOME_RATIO',\n",
    "'ANNUITY_ENTIRE_INCOME_RATIO',\n",
    "'INCOME_PER_CHILD',\n",
    "'INCOME_PER_FAM_MEMBER',\n",
    "'ENTIRE_INCOME_PER_FAM_MEMBER',\n",
    "'ENTIRE_INCOME_PER_CHILD',\n",
    "'AMT_REQ_CREDIT_BUREAU_TOTAL',\n",
    "'AMT_REQ_CREDIT_BUREAU_EMA',\n",
    "'DAYS_CREDIT',\n",
    "'CREDIT_DAY_OVERDUE',\n",
    "'DAYS_CREDIT_ENDDATE',\n",
    "'DAYS_ENDDATE_FACT',\n",
    "'AMT_CREDIT_MAX_OVERDUE',\n",
    "'AMT_CREDIT_SUM',\n",
    "'AMT_CREDIT_SUM_DEBT',\n",
    "'AMT_CREDIT_SUM_LIMIT',\n",
    "'AMT_CREDIT_SUM_OVERDUE',\n",
    "'DAYS_CREDIT_UPDATE',\n",
    "'AMT_ANNUITY_y',\n",
    "'Active_x',\n",
    "'Closed',\n",
    "'Consumer credit',\n",
    "'Credit card',\n",
    "'Microloan',\n",
    "'LATE_DAYS_x',\n",
    "'score',\n",
    "'STATUS_X',\n",
    "'NFLAG_INSURED_ON_APPROVAL',\n",
    "'DAYS_TERMINATION',\n",
    "'DAYS_LAST_DUE',\n",
    "'DAYS_LAST_DUE_1ST_VERSION',\n",
    "'DAYS_FIRST_DUE',\n",
    "'DAYS_FIRST_DRAWING',\n",
    "'LATE_DAYS_y',\n",
    "'EXTRA_DAYS']].values[y.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 67)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(app[['SK_ID_CURR',\n",
    "'AMT_INCOME_TOTAL',\n",
    "'AMT_CREDIT',\n",
    "'AMT_ANNUITY_x',\n",
    "'AMT_GOODS_PRICE',\n",
    "'REGION_POPULATION_RELATIVE',\n",
    "'DAYS_BIRTH',\n",
    "'DAYS_EMPLOYED',\n",
    "'DAYS_REGISTRATION',\n",
    "'DAYS_ID_PUBLISH',\n",
    "'OWN_CAR_AGE',\n",
    "'HOUR_APPR_PROCESS_START',\n",
    "'EXT_SOURCE_1',\n",
    "'EXT_SOURCE_2',\n",
    "'EXT_SOURCE_3',\n",
    "'YEARS_BEGINEXPLUATATION_AVG',\n",
    "'LIVINGAREA_AVG',\n",
    "'YEARS_BEGINEXPLUATATION_MODE',\n",
    "'LIVINGAREA_MODE',\n",
    "'YEARS_BEGINEXPLUATATION_MEDI',\n",
    "'LIVINGAREA_MEDI',\n",
    "'TOTALAREA_MODE',\n",
    "'OBS_30_CNT_SOCIAL_CIRCLE',\n",
    "'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "'OBS_60_CNT_SOCIAL_CIRCLE',\n",
    "'DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "'DAYS_LAST_PHONE_CHANGE',\n",
    "'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    "'CREDIT_INCOME_RATIO',\n",
    "'ANNUITY_INCOME_RATIO',\n",
    "'CREDIT_GOODS_PRICE_DIFF',\n",
    "'ENTIRE_INCOME',\n",
    "'CREDIT_ENTIRE_INCOME_RATIO',\n",
    "'ANNUITY_ENTIRE_INCOME_RATIO',\n",
    "'INCOME_PER_CHILD',\n",
    "'INCOME_PER_FAM_MEMBER',\n",
    "'ENTIRE_INCOME_PER_FAM_MEMBER',\n",
    "'ENTIRE_INCOME_PER_CHILD',\n",
    "'AMT_REQ_CREDIT_BUREAU_TOTAL',\n",
    "'AMT_REQ_CREDIT_BUREAU_EMA',\n",
    "'DAYS_CREDIT',\n",
    "'CREDIT_DAY_OVERDUE',\n",
    "'DAYS_CREDIT_ENDDATE',\n",
    "'DAYS_ENDDATE_FACT',\n",
    "'AMT_CREDIT_MAX_OVERDUE',\n",
    "'AMT_CREDIT_SUM',\n",
    "'AMT_CREDIT_SUM_DEBT',\n",
    "'AMT_CREDIT_SUM_LIMIT',\n",
    "'AMT_CREDIT_SUM_OVERDUE',\n",
    "'DAYS_CREDIT_UPDATE',\n",
    "'AMT_ANNUITY_y',\n",
    "'Active_x',\n",
    "'Closed',\n",
    "'Consumer credit',\n",
    "'Credit card',\n",
    "'Microloan',\n",
    "'LATE_DAYS_x',\n",
    "'score',\n",
    "'STATUS_X',\n",
    "'NFLAG_INSURED_ON_APPROVAL',\n",
    "'DAYS_TERMINATION',\n",
    "'DAYS_LAST_DUE',\n",
    "'DAYS_LAST_DUE_1ST_VERSION',\n",
    "'DAYS_FIRST_DUE',\n",
    "'DAYS_FIRST_DRAWING',\n",
    "'LATE_DAYS_y',\n",
    "'EXTRA_DAYS']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = scaler.transform(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0008\n",
    "num_epochs = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 67\n",
    "n_hidden1 = 256\n",
    "n_hidden2 = 512\n",
    "n_hidden3 = 256\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    weights = {\n",
    "        'layer1':tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "        'layer2':tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "        'layer3':tf.Variable(tf.random_normal([n_hidden2, n_hidden3])),\n",
    "        'out':tf.Variable(tf.random_normal([n_hidden3, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'layer1':tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'layer2':tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'layer3':tf.Variable(tf.random_normal([n_hidden3])),\n",
    "        'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "    X_nn = tf.placeholder('float', [None, n_input])\n",
    "    y_nn = tf.placeholder('float', [None, n_classes])\n",
    "    h_layer1 = tf.add(tf.matmul(X_nn, weights['layer1']), biases['layer1'])\n",
    "    drop_connect = tf.nn.dropout(h_layer1, p)*p\n",
    "    h_layer2 = tf.add(tf.matmul(drop_connect, weights['layer2']), biases['layer2'])\n",
    "    h_layer3 = tf.add(tf.matmul(h_layer2, weights['layer3']), biases['layer3'])\n",
    "    out = tf.add(tf.matmul(h_layer3, weights['out']), biases['out'])\n",
    "    loss_op = tf.losses.mean_squared_error(y_nn, out)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "    init_op = tf.global_variables_initializer()\n",
    "with tf.device('/device:CPU:0'):\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 epochs, train loss is 214793056.0, train auc_score is 0.4953998794615915\n",
      "after 10 epochs, test loss is 216308064.0, test auc_score is 0.4898906175807721\n",
      "after 20 epochs, train loss is 142591280.0, train auc_score is 0.48790032026985386\n",
      "after 20 epochs, test loss is 144810416.0, test auc_score is 0.4874379297212098\n",
      "after 30 epochs, train loss is 112486184.0, train auc_score is 0.4884073676820897\n",
      "after 30 epochs, test loss is 115106480.0, test auc_score is 0.4888275804088104\n",
      "after 40 epochs, train loss is 93938296.0, train auc_score is 0.49584735143529296\n",
      "after 40 epochs, test loss is 103981656.0, test auc_score is 0.4955770830644403\n",
      "after 50 epochs, train loss is 75004536.0, train auc_score is 0.511123376100254\n",
      "after 50 epochs, test loss is 76749776.0, test auc_score is 0.5139413817626043\n",
      "after 60 epochs, train loss is 61228884.0, train auc_score is 0.5035050722033446\n",
      "after 60 epochs, test loss is 74382832.0, test auc_score is 0.49723336555167996\n",
      "after 70 epochs, train loss is 56247712.0, train auc_score is 0.5006050712190181\n",
      "after 70 epochs, test loss is 56077204.0, test auc_score is 0.49890619138819736\n",
      "after 80 epochs, train loss is 43866144.0, train auc_score is 0.506582184309843\n",
      "after 80 epochs, test loss is 50039016.0, test auc_score is 0.51136403139952\n",
      "after 90 epochs, train loss is 40731912.0, train auc_score is 0.4957653877859728\n",
      "after 90 epochs, test loss is 43478168.0, test auc_score is 0.4987265329209535\n",
      "after 100 epochs, train loss is 32295174.0, train auc_score is 0.4987091990625157\n",
      "after 100 epochs, test loss is 35977124.0, test auc_score is 0.49320934619150536\n",
      "after 110 epochs, train loss is 26944228.0, train auc_score is 0.5024496662256477\n",
      "after 110 epochs, test loss is 27503240.0, test auc_score is 0.4967119524623478\n",
      "after 120 epochs, train loss is 23858908.0, train auc_score is 0.4959460574368026\n",
      "after 120 epochs, test loss is 34741200.0, test auc_score is 0.5036946543324972\n",
      "after 130 epochs, train loss is 19551254.0, train auc_score is 0.4996827441453607\n",
      "after 130 epochs, test loss is 21084570.0, test auc_score is 0.488966919720601\n",
      "after 140 epochs, train loss is 17214014.0, train auc_score is 0.4966826738579419\n",
      "after 140 epochs, test loss is 16575532.0, test auc_score is 0.49828807340124215\n",
      "after 150 epochs, train loss is 13949435.0, train auc_score is 0.5003964419685987\n",
      "after 150 epochs, test loss is 18378796.0, test auc_score is 0.5113500058551429\n",
      "after 160 epochs, train loss is 12076580.0, train auc_score is 0.4937918250430071\n",
      "after 160 epochs, test loss is 12907807.0, test auc_score is 0.5001383982510479\n",
      "after 170 epochs, train loss is 10167870.0, train auc_score is 0.4996704859032228\n",
      "after 170 epochs, test loss is 10263362.0, test auc_score is 0.5013006082680102\n",
      "after 180 epochs, train loss is 9618542.0, train auc_score is 0.5003369823389981\n",
      "after 180 epochs, test loss is 8830352.0, test auc_score is 0.49024886569461534\n",
      "after 190 epochs, train loss is 8624154.0, train auc_score is 0.49974577901729095\n",
      "after 190 epochs, test loss is 9052567.0, test auc_score is 0.5096764134592128\n",
      "after 200 epochs, train loss is 5892716.0, train auc_score is 0.493195071694349\n",
      "after 200 epochs, test loss is 5894039.0, test auc_score is 0.49236597191662856\n",
      "after 210 epochs, train loss is 5124303.5, train auc_score is 0.5065497188427592\n",
      "after 210 epochs, test loss is 4994062.0, test auc_score is 0.5126665249051102\n",
      "after 220 epochs, train loss is 4026073.75, train auc_score is 0.4950316479954562\n",
      "after 220 epochs, test loss is 4320361.5, test auc_score is 0.4982681148116541\n",
      "after 230 epochs, train loss is 3856671.75, train auc_score is 0.49475168706790706\n",
      "after 230 epochs, test loss is 3825034.5, test auc_score is 0.500501342320318\n",
      "after 240 epochs, train loss is 2976929.5, train auc_score is 0.5063135448676244\n",
      "after 240 epochs, test loss is 3041703.5, test auc_score is 0.5146964459002563\n",
      "after 250 epochs, train loss is 2470141.5, train auc_score is 0.5002298526468388\n",
      "after 250 epochs, test loss is 2787523.5, test auc_score is 0.5010333625976218\n",
      "after 260 epochs, train loss is 2195824.5, train auc_score is 0.5023923294301764\n",
      "after 260 epochs, test loss is 2229871.0, test auc_score is 0.4975964373808522\n",
      "after 270 epochs, train loss is 1654217.875, train auc_score is 0.500567404437452\n",
      "after 270 epochs, test loss is 1727396.5, test auc_score is 0.4920636234341077\n",
      "after 280 epochs, train loss is 1333775.875, train auc_score is 0.5066314090405832\n",
      "after 280 epochs, test loss is 1350782.75, test auc_score is 0.5006387870462428\n",
      "after 290 epochs, train loss is 1131390.25, train auc_score is 0.49401153090862865\n",
      "after 290 epochs, test loss is 1444094.875, test auc_score is 0.49806349018987794\n",
      "after 300 epochs, train loss is 944795.8125, train auc_score is 0.5063295182920078\n",
      "after 300 epochs, test loss is 960147.0625, test auc_score is 0.5037972860431406\n",
      "after 310 epochs, train loss is 803196.0, train auc_score is 0.499287753002603\n",
      "after 310 epochs, test loss is 1075577.125, test auc_score is 0.49980084100915856\n",
      "after 320 epochs, train loss is 632064.0625, train auc_score is 0.5020466292794616\n",
      "after 320 epochs, test loss is 830263.9375, test auc_score is 0.49512484105577537\n",
      "after 330 epochs, train loss is 540548.5, train auc_score is 0.500741434310142\n",
      "after 330 epochs, test loss is 518859.84375, test auc_score is 0.5028974044983825\n",
      "after 340 epochs, train loss is 502032.46875, train auc_score is 0.5033870665589437\n",
      "after 340 epochs, test loss is 446900.8125, test auc_score is 0.4981212470139239\n",
      "after 350 epochs, train loss is 382105.28125, train auc_score is 0.4892416269569683\n",
      "after 350 epochs, test loss is 351699.15625, test auc_score is 0.48425010826872683\n",
      "after 360 epochs, train loss is 321026.4375, train auc_score is 0.5067272951786161\n",
      "after 360 epochs, test loss is 312878.15625, test auc_score is 0.5077246752919766\n",
      "after 370 epochs, train loss is 248786.171875, train auc_score is 0.4973428392734694\n",
      "after 370 epochs, test loss is 253138.609375, test auc_score is 0.5034055243257035\n",
      "after 380 epochs, train loss is 190698.5, train auc_score is 0.50826544421934\n",
      "after 380 epochs, test loss is 184525.171875, test auc_score is 0.505945740182602\n",
      "after 390 epochs, train loss is 192556.0, train auc_score is 0.5014870354672614\n",
      "after 390 epochs, test loss is 188110.734375, test auc_score is 0.497610151315712\n",
      "after 400 epochs, train loss is 135631.15625, train auc_score is 0.5134232163225941\n",
      "after 400 epochs, test loss is 130784.734375, test auc_score is 0.5216296641790464\n",
      "after 410 epochs, train loss is 98821.828125, train auc_score is 0.5051602276284626\n",
      "after 410 epochs, test loss is 121817.28125, test auc_score is 0.5004314046802378\n",
      "after 420 epochs, train loss is 86463.6875, train auc_score is 0.504746619037541\n",
      "after 420 epochs, test loss is 87250.0390625, test auc_score is 0.49559628132680594\n",
      "after 430 epochs, train loss is 74201.1640625, train auc_score is 0.501198857643666\n",
      "after 430 epochs, test loss is 69972.0234375, test auc_score is 0.5060058932838365\n",
      "after 440 epochs, train loss is 55798.515625, train auc_score is 0.49879346761620197\n",
      "after 440 epochs, test loss is 54619.59375, test auc_score is 0.49088441511797254\n",
      "after 450 epochs, train loss is 50141.61328125, train auc_score is 0.5014782086705362\n",
      "after 450 epochs, test loss is 42468.66796875, test auc_score is 0.4995154129234314\n",
      "after 460 epochs, train loss is 37342.9765625, train auc_score is 0.5058485712069818\n",
      "after 460 epochs, test loss is 43945.30078125, test auc_score is 0.5020511976929927\n",
      "after 470 epochs, train loss is 36785.27734375, train auc_score is 0.5043266603391606\n",
      "after 470 epochs, test loss is 27981.087890625, test auc_score is 0.49450375966230997\n",
      "after 480 epochs, train loss is 23286.58984375, train auc_score is 0.5028437759941793\n",
      "after 480 epochs, test loss is 23170.3359375, test auc_score is 0.5043313941042108\n",
      "after 490 epochs, train loss is 19679.072265625, train auc_score is 0.5004383988233859\n",
      "after 490 epochs, test loss is 17899.8046875, test auc_score is 0.49640022453335375\n",
      "after 500 epochs, train loss is 15485.5361328125, train auc_score is 0.5047179427280081\n",
      "after 500 epochs, test loss is 15355.1103515625, test auc_score is 0.5028884488408532\n",
      "after 510 epochs, train loss is 12421.25, train auc_score is 0.5006197210986005\n",
      "after 510 epochs, test loss is 11909.9892578125, test auc_score is 0.49460091016154273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 520 epochs, train loss is 9860.5244140625, train auc_score is 0.5062226423707488\n",
      "after 520 epochs, test loss is 11292.5419921875, test auc_score is 0.49349727650165714\n",
      "after 530 epochs, train loss is 7837.9453125, train auc_score is 0.4957001752907165\n",
      "after 530 epochs, test loss is 10227.708984375, test auc_score is 0.4958558053133536\n",
      "after 540 epochs, train loss is 6625.00048828125, train auc_score is 0.5090006740979918\n",
      "after 540 epochs, test loss is 6319.2587890625, test auc_score is 0.5081056335074463\n",
      "after 550 epochs, train loss is 5576.90869140625, train auc_score is 0.502533005143144\n",
      "after 550 epochs, test loss is 6645.125, test auc_score is 0.5080292081572142\n",
      "after 560 epochs, train loss is 4347.40283203125, train auc_score is 0.5040391690617811\n",
      "after 560 epochs, test loss is 4600.78466796875, test auc_score is 0.4983594911865299\n",
      "after 570 epochs, train loss is 4303.40478515625, train auc_score is 0.517222592157538\n",
      "after 570 epochs, test loss is 4023.1611328125, test auc_score is 0.5168925451349248\n",
      "after 580 epochs, train loss is 3125.442626953125, train auc_score is 0.4914308385936641\n",
      "after 580 epochs, test loss is 3039.66064453125, test auc_score is 0.49509856302517496\n",
      "after 590 epochs, train loss is 2505.546630859375, train auc_score is 0.5023886874320563\n",
      "after 590 epochs, test loss is 2449.513671875, test auc_score is 0.4985088923696364\n",
      "after 600 epochs, train loss is 2168.60205078125, train auc_score is 0.5049499632073238\n",
      "after 600 epochs, test loss is 2312.390869140625, test auc_score is 0.5024138488493164\n",
      "after 610 epochs, train loss is 1805.9847412109375, train auc_score is 0.49848196680296264\n",
      "after 610 epochs, test loss is 2120.598876953125, test auc_score is 0.5051376307568067\n",
      "after 620 epochs, train loss is 1805.6085205078125, train auc_score is 0.5126784174217272\n",
      "after 620 epochs, test loss is 1632.7901611328125, test auc_score is 0.5043491028730833\n",
      "after 630 epochs, train loss is 1361.23486328125, train auc_score is 0.4952709024288934\n",
      "after 630 epochs, test loss is 1258.29296875, test auc_score is 0.4875535493165375\n",
      "after 640 epochs, train loss is 1209.1461181640625, train auc_score is 0.4986406657881124\n",
      "after 640 epochs, test loss is 1172.161376953125, test auc_score is 0.4964032409134821\n",
      "after 650 epochs, train loss is 1067.299560546875, train auc_score is 0.49686087750043195\n",
      "after 650 epochs, test loss is 1096.9534912109375, test auc_score is 0.48928014960746863\n",
      "after 660 epochs, train loss is 996.4122314453125, train auc_score is 0.4994198630081583\n",
      "after 660 epochs, test loss is 986.7457885742188, test auc_score is 0.49363223769972847\n",
      "after 670 epochs, train loss is 887.628662109375, train auc_score is 0.485446215723682\n",
      "after 670 epochs, test loss is 862.6109619140625, test auc_score is 0.4728536570150189\n",
      "after 680 epochs, train loss is 751.1444702148438, train auc_score is 0.5006671297751542\n",
      "after 680 epochs, test loss is 728.4977416992188, test auc_score is 0.500442956045047\n",
      "after 690 epochs, train loss is 771.1492309570312, train auc_score is 0.5058153487786855\n",
      "after 690 epochs, test loss is 709.68701171875, test auc_score is 0.5045634528278968\n",
      "after 700 epochs, train loss is 696.0302124023438, train auc_score is 0.5045547793134029\n",
      "after 700 epochs, test loss is 658.2456665039062, test auc_score is 0.5063395367101875\n",
      "after 710 epochs, train loss is 620.82080078125, train auc_score is 0.5078485380901759\n",
      "after 710 epochs, test loss is 622.3025512695312, test auc_score is 0.49512927837530285\n",
      "after 720 epochs, train loss is 618.1726684570312, train auc_score is 0.4987609361845076\n",
      "after 720 epochs, test loss is 653.3427124023438, test auc_score is 0.4985096464646685\n",
      "after 730 epochs, train loss is 545.602294921875, train auc_score is 0.5010925834145963\n",
      "after 730 epochs, test loss is 550.8589477539062, test auc_score is 0.505063290074246\n",
      "after 740 epochs, train loss is 543.619873046875, train auc_score is 0.4996749595301428\n",
      "after 740 epochs, test loss is 579.2464599609375, test auc_score is 0.4987739224963562\n",
      "after 750 epochs, train loss is 544.7024536132812, train auc_score is 0.504831491063571\n",
      "after 750 epochs, test loss is 503.9425964355469, test auc_score is 0.5054377512312783\n",
      "after 760 epochs, train loss is 492.5820617675781, train auc_score is 0.5050772112156061\n",
      "after 760 epochs, test loss is 539.1265258789062, test auc_score is 0.5034049135710494\n",
      "after 770 epochs, train loss is 511.00933837890625, train auc_score is 0.5019664336201591\n",
      "after 770 epochs, test loss is 473.3382263183594, test auc_score is 0.49825587790590675\n",
      "after 780 epochs, train loss is 478.52252197265625, train auc_score is 0.5002837047900601\n",
      "after 780 epochs, test loss is 513.7418823242188, test auc_score is 0.5059981466712344\n",
      "after 790 epochs, train loss is 483.5121765136719, train auc_score is 0.49851083625924864\n",
      "after 790 epochs, test loss is 494.12725830078125, test auc_score is 0.5077163553178625\n",
      "after 800 epochs, train loss is 428.4730529785156, train auc_score is 0.5015506756905872\n",
      "after 800 epochs, test loss is 449.38677978515625, test auc_score is 0.5028638566177417\n",
      "after 810 epochs, train loss is 421.7659912109375, train auc_score is 0.5037252135145134\n",
      "after 810 epochs, test loss is 423.0726623535156, test auc_score is 0.5029326319543221\n",
      "after 820 epochs, train loss is 413.87445068359375, train auc_score is 0.4997997587382446\n",
      "after 820 epochs, test loss is 401.78863525390625, test auc_score is 0.4948139482402881\n",
      "after 830 epochs, train loss is 383.2877197265625, train auc_score is 0.501784225421435\n",
      "after 830 epochs, test loss is 384.44805908203125, test auc_score is 0.49402609654921753\n",
      "after 840 epochs, train loss is 409.54296875, train auc_score is 0.5010313558938757\n",
      "after 840 epochs, test loss is 429.71942138671875, test auc_score is 0.5097013858459354\n",
      "after 850 epochs, train loss is 379.9437561035156, train auc_score is 0.5010642258515995\n",
      "after 850 epochs, test loss is 380.21392822265625, test auc_score is 0.49507192975972475\n",
      "after 860 epochs, train loss is 385.27239990234375, train auc_score is 0.4941197212761215\n",
      "after 860 epochs, test loss is 368.09820556640625, test auc_score is 0.49373413401191085\n",
      "after 870 epochs, train loss is 344.51507568359375, train auc_score is 0.5019455482552819\n",
      "after 870 epochs, test loss is 348.7378845214844, test auc_score is 0.5033140575840678\n",
      "after 880 epochs, train loss is 412.1798400878906, train auc_score is 0.502338880689723\n",
      "after 880 epochs, test loss is 342.39288330078125, test auc_score is 0.4957319685750527\n",
      "after 890 epochs, train loss is 377.90386962890625, train auc_score is 0.5075275376807433\n",
      "after 890 epochs, test loss is 315.6192626953125, test auc_score is 0.5094011189149906\n",
      "after 900 epochs, train loss is 319.87469482421875, train auc_score is 0.49713770545512387\n",
      "after 900 epochs, test loss is 315.71453857421875, test auc_score is 0.5013235053353471\n",
      "after 910 epochs, train loss is 295.660888671875, train auc_score is 0.5080171059546607\n",
      "after 910 epochs, test loss is 294.1306457519531, test auc_score is 0.5042597706566416\n",
      "after 920 epochs, train loss is 303.2553405761719, train auc_score is 0.5086906912619735\n",
      "after 920 epochs, test loss is 313.4958801269531, test auc_score is 0.5036342301309826\n",
      "after 930 epochs, train loss is 291.43145751953125, train auc_score is 0.5006224541301012\n",
      "after 930 epochs, test loss is 291.61273193359375, test auc_score is 0.49953912329160866\n",
      "after 940 epochs, train loss is 272.3805847167969, train auc_score is 0.5037258067015205\n",
      "after 940 epochs, test loss is 326.5645446777344, test auc_score is 0.5047014459865722\n",
      "after 950 epochs, train loss is 299.09222412109375, train auc_score is 0.49342394238823795\n",
      "after 950 epochs, test loss is 288.4766540527344, test auc_score is 0.4961439880272145\n",
      "after 960 epochs, train loss is 258.9815368652344, train auc_score is 0.5052339831836111\n",
      "after 960 epochs, test loss is 289.68975830078125, test auc_score is 0.4929418512335032\n",
      "after 970 epochs, train loss is 275.5031433105469, train auc_score is 0.4979102065254739\n",
      "after 970 epochs, test loss is 259.77374267578125, test auc_score is 0.5015098447106435\n",
      "after 980 epochs, train loss is 242.0691680908203, train auc_score is 0.5072411755157449\n",
      "after 980 epochs, test loss is 244.07162475585938, test auc_score is 0.5101478537302433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 990 epochs, train loss is 235.5406036376953, train auc_score is 0.5051625235331592\n",
      "after 990 epochs, test loss is 258.95526123046875, test auc_score is 0.5070225349147558\n",
      "after 1000 epochs, train loss is 230.59005737304688, train auc_score is 0.5043844549310066\n",
      "after 1000 epochs, test loss is 241.18450927734375, test auc_score is 0.5033816706171482\n",
      "after 1010 epochs, train loss is 238.39797973632812, train auc_score is 0.4976081895837305\n",
      "after 1010 epochs, test loss is 250.33563232421875, test auc_score is 0.49500968575862864\n",
      "after 1020 epochs, train loss is 242.7432098388672, train auc_score is 0.5020773226028342\n",
      "after 1020 epochs, test loss is 228.84539794921875, test auc_score is 0.5037910258079366\n",
      "after 1030 epochs, train loss is 208.18714904785156, train auc_score is 0.4961653638555548\n",
      "after 1030 epochs, test loss is 204.7582550048828, test auc_score is 0.496976614889837\n",
      "after 1040 epochs, train loss is 208.52499389648438, train auc_score is 0.49182102450629483\n",
      "after 1040 epochs, test loss is 205.27500915527344, test auc_score is 0.49627241165761116\n",
      "after 1050 epochs, train loss is 198.15574645996094, train auc_score is 0.49388282139357875\n",
      "after 1050 epochs, test loss is 218.919677734375, test auc_score is 0.4911009930808353\n",
      "after 1060 epochs, train loss is 194.43270874023438, train auc_score is 0.501830165569501\n",
      "after 1060 epochs, test loss is 214.4937286376953, test auc_score is 0.4947256910766813\n",
      "after 1070 epochs, train loss is 181.67547607421875, train auc_score is 0.5006644869381432\n",
      "after 1070 epochs, test loss is 186.2624969482422, test auc_score is 0.49426376424421636\n",
      "after 1080 epochs, train loss is 175.4135284423828, train auc_score is 0.4967100438308333\n",
      "after 1080 epochs, test loss is 180.14198303222656, test auc_score is 0.5041795156254412\n",
      "after 1090 epochs, train loss is 162.56028747558594, train auc_score is 0.49708968648230145\n",
      "after 1090 epochs, test loss is 196.62709045410156, test auc_score is 0.5037663587985409\n",
      "after 1100 epochs, train loss is 160.8584747314453, train auc_score is 0.4904017165957732\n",
      "after 1100 epochs, test loss is 174.24734497070312, test auc_score is 0.49926151660476753\n",
      "after 1110 epochs, train loss is 180.35118103027344, train auc_score is 0.4942134127804641\n",
      "after 1110 epochs, test loss is 158.06259155273438, test auc_score is 0.5031011254525583\n",
      "after 1120 epochs, train loss is 149.5030975341797, train auc_score is 0.4958020036830544\n",
      "after 1120 epochs, test loss is 163.53677368164062, test auc_score is 0.5162614112184287\n",
      "after 1130 epochs, train loss is 145.89358520507812, train auc_score is 0.5084880364075359\n",
      "after 1130 epochs, test loss is 173.04774475097656, test auc_score is 0.5107081463390587\n",
      "after 1140 epochs, train loss is 155.25131225585938, train auc_score is 0.4989392344718736\n",
      "after 1140 epochs, test loss is 144.9613494873047, test auc_score is 0.5029742287087967\n",
      "after 1150 epochs, train loss is 133.53152465820312, train auc_score is 0.4999404604612462\n",
      "after 1150 epochs, test loss is 134.8625030517578, test auc_score is 0.5020826453254864\n",
      "after 1160 epochs, train loss is 141.71774291992188, train auc_score is 0.4954113589850741\n",
      "after 1160 epochs, test loss is 164.87620544433594, test auc_score is 0.4912342466587514\n",
      "after 1170 epochs, train loss is 129.3679656982422, train auc_score is 0.5094230790252187\n",
      "after 1170 epochs, test loss is 170.24595642089844, test auc_score is 0.502535778537371\n",
      "after 1180 epochs, train loss is 129.8301239013672, train auc_score is 0.49953944527597816\n",
      "after 1180 epochs, test loss is 133.10369873046875, test auc_score is 0.5054830966482471\n",
      "after 1190 epochs, train loss is 116.39874267578125, train auc_score is 0.5040849413808456\n",
      "after 1190 epochs, test loss is 149.068359375, test auc_score is 0.5081422943671656\n",
      "after 1200 epochs, train loss is 114.82586669921875, train auc_score is 0.4802742679541994\n",
      "after 1200 epochs, test loss is 122.42794799804688, test auc_score is 0.4930512666833399\n",
      "after 1210 epochs, train loss is 107.84232330322266, train auc_score is 0.5007919902996855\n",
      "after 1210 epochs, test loss is 104.97229766845703, test auc_score is 0.5062799725509408\n",
      "after 1220 epochs, train loss is 105.59000396728516, train auc_score is 0.5064599974783321\n",
      "after 1220 epochs, test loss is 108.33670806884766, test auc_score is 0.5056252996515022\n",
      "after 1230 epochs, train loss is 98.79405212402344, train auc_score is 0.5041291803935815\n",
      "after 1230 epochs, test loss is 118.15719604492188, test auc_score is 0.5029187061249905\n",
      "after 1240 epochs, train loss is 98.55805206298828, train auc_score is 0.5012867275486133\n",
      "after 1240 epochs, test loss is 111.0694808959961, test auc_score is 0.500975356485962\n",
      "after 1250 epochs, train loss is 91.4043960571289, train auc_score is 0.49743627107306365\n",
      "after 1250 epochs, test loss is 88.13788604736328, test auc_score is 0.49703412865845936\n",
      "after 1260 epochs, train loss is 87.52497100830078, train auc_score is 0.5013807575789854\n",
      "after 1260 epochs, test loss is 89.84310913085938, test auc_score is 0.4977117048574253\n",
      "after 1270 epochs, train loss is 103.74093627929688, train auc_score is 0.5023378393982929\n",
      "after 1270 epochs, test loss is 88.77976989746094, test auc_score is 0.4944982317094717\n",
      "after 1280 epochs, train loss is 82.19480895996094, train auc_score is 0.5017243153138724\n",
      "after 1280 epochs, test loss is 81.24439239501953, test auc_score is 0.5066315709176832\n",
      "after 1290 epochs, train loss is 78.20977783203125, train auc_score is 0.49978080217066645\n",
      "after 1290 epochs, test loss is 79.99382019042969, test auc_score is 0.5038194601763972\n",
      "after 1300 epochs, train loss is 78.55060577392578, train auc_score is 0.5032313623868899\n",
      "after 1300 epochs, test loss is 77.68280029296875, test auc_score is 0.5089968149144791\n",
      "after 1310 epochs, train loss is 74.00860595703125, train auc_score is 0.4961187461609425\n",
      "after 1310 epochs, test loss is 68.7812271118164, test auc_score is 0.49726557974358654\n",
      "after 1320 epochs, train loss is 74.60533142089844, train auc_score is 0.48356636822045096\n",
      "after 1320 epochs, test loss is 76.10809326171875, test auc_score is 0.4829989150379824\n",
      "after 1330 epochs, train loss is 68.37968444824219, train auc_score is 0.4964093508294807\n",
      "after 1330 epochs, test loss is 77.53343963623047, test auc_score is 0.49967066613327427\n",
      "after 1340 epochs, train loss is 64.08589172363281, train auc_score is 0.5084924060932181\n",
      "after 1340 epochs, test loss is 63.2087287902832, test auc_score is 0.5095079978633559\n",
      "after 1350 epochs, train loss is 64.11612701416016, train auc_score is 0.49545688148913686\n",
      "after 1350 epochs, test loss is 58.953529357910156, test auc_score is 0.4952864074744404\n",
      "after 1360 epochs, train loss is 59.010868072509766, train auc_score is 0.5071483264200262\n",
      "after 1360 epochs, test loss is 68.4295883178711, test auc_score is 0.4971452486123561\n",
      "after 1370 epochs, train loss is 61.12717819213867, train auc_score is 0.5016332201647311\n",
      "after 1370 epochs, test loss is 57.743324279785156, test auc_score is 0.4977730202621596\n",
      "after 1380 epochs, train loss is 54.03626251220703, train auc_score is 0.49112815033591467\n",
      "after 1380 epochs, test loss is 53.57347106933594, test auc_score is 0.4971207685686709\n",
      "after 1390 epochs, train loss is 55.31288146972656, train auc_score is 0.5048169832007512\n",
      "after 1390 epochs, test loss is 53.13196563720703, test auc_score is 0.5104976696905462\n",
      "after 1400 epochs, train loss is 52.593021392822266, train auc_score is 0.4903169694772441\n",
      "after 1400 epochs, test loss is 50.25361633300781, test auc_score is 0.4881594490943163\n",
      "after 1410 epochs, train loss is 50.207908630371094, train auc_score is 0.49691728742884245\n",
      "after 1410 epochs, test loss is 50.48961639404297, test auc_score is 0.5034001241327672\n",
      "after 1420 epochs, train loss is 48.366973876953125, train auc_score is 0.5028089196808306\n",
      "after 1420 epochs, test loss is 44.925872802734375, test auc_score is 0.5002074446879085\n",
      "after 1430 epochs, train loss is 45.64018630981445, train auc_score is 0.4888456401145129\n",
      "after 1430 epochs, test loss is 45.92245864868164, test auc_score is 0.48957930409243633\n",
      "after 1440 epochs, train loss is 39.777809143066406, train auc_score is 0.4953397267585422\n",
      "after 1440 epochs, test loss is 46.4794807434082, test auc_score is 0.49514980097811734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1450 epochs, train loss is 38.826663970947266, train auc_score is 0.4892482534828476\n",
      "after 1450 epochs, test loss is 38.84874725341797, test auc_score is 0.49034043838348707\n",
      "after 1460 epochs, train loss is 40.74440002441406, train auc_score is 0.4876508066087793\n",
      "after 1460 epochs, test loss is 42.020843505859375, test auc_score is 0.4909941982670397\n",
      "after 1470 epochs, train loss is 37.56517791748047, train auc_score is 0.5076603627149852\n",
      "after 1470 epochs, test loss is 42.097225189208984, test auc_score is 0.5040167869032763\n",
      "after 1480 epochs, train loss is 35.27774429321289, train auc_score is 0.49962724713946816\n",
      "after 1480 epochs, test loss is 33.56381607055664, test auc_score is 0.4929881688721662\n",
      "after 1490 epochs, train loss is 35.54823303222656, train auc_score is 0.503844193892349\n",
      "after 1490 epochs, test loss is 34.580360412597656, test auc_score is 0.5065814049014806\n",
      "after 1500 epochs, train loss is 33.942630767822266, train auc_score is 0.4896350142795036\n",
      "after 1500 epochs, test loss is 37.55226516723633, test auc_score is 0.4923215706764974\n",
      "after 1510 epochs, train loss is 31.751956939697266, train auc_score is 0.48875875127243834\n",
      "after 1510 epochs, test loss is 35.26652145385742, test auc_score is 0.49440973149044143\n",
      "after 1520 epochs, train loss is 30.7429256439209, train auc_score is 0.4938379955232736\n",
      "after 1520 epochs, test loss is 29.515905380249023, test auc_score is 0.48090522938729535\n",
      "after 1530 epochs, train loss is 30.714618682861328, train auc_score is 0.49523217002712033\n",
      "after 1530 epochs, test loss is 30.94562339782715, test auc_score is 0.4888426311484998\n",
      "after 1540 epochs, train loss is 29.868209838867188, train auc_score is 0.5041616252899922\n",
      "after 1540 epochs, test loss is 28.758525848388672, test auc_score is 0.5134602940609158\n",
      "after 1550 epochs, train loss is 26.134353637695312, train auc_score is 0.502343955514345\n",
      "after 1550 epochs, test loss is 28.129236221313477, test auc_score is 0.5014383022815487\n",
      "after 1560 epochs, train loss is 24.653907775878906, train auc_score is 0.49342069647447334\n",
      "after 1560 epochs, test loss is 26.648324966430664, test auc_score is 0.5011840413797496\n",
      "after 1570 epochs, train loss is 22.931997299194336, train auc_score is 0.4953461711152872\n",
      "after 1570 epochs, test loss is 24.42799949645996, test auc_score is 0.4884200013922713\n",
      "after 1580 epochs, train loss is 21.859874725341797, train auc_score is 0.4931841277995476\n",
      "after 1580 epochs, test loss is 21.43525505065918, test auc_score is 0.48977033007487414\n",
      "after 1590 epochs, train loss is 22.36901092529297, train auc_score is 0.5010641576123472\n",
      "after 1590 epochs, test loss is 23.522329330444336, test auc_score is 0.5038957858115836\n",
      "after 1600 epochs, train loss is 19.624780654907227, train auc_score is 0.511084633116452\n",
      "after 1600 epochs, test loss is 19.40198516845703, test auc_score is 0.5149909667517008\n",
      "after 1610 epochs, train loss is 18.09120750427246, train auc_score is 0.5056908403291367\n",
      "after 1610 epochs, test loss is 19.773969650268555, test auc_score is 0.5042712783961184\n",
      "after 1620 epochs, train loss is 17.598976135253906, train auc_score is 0.5030147324302872\n",
      "after 1620 epochs, test loss is 17.996349334716797, test auc_score is 0.5072182630848108\n",
      "after 1630 epochs, train loss is 16.759206771850586, train auc_score is 0.4870562249495992\n",
      "after 1630 epochs, test loss is 16.264724731445312, test auc_score is 0.4874821097185836\n",
      "after 1640 epochs, train loss is 17.21593475341797, train auc_score is 0.489064971059837\n",
      "after 1640 epochs, test loss is 17.26632308959961, test auc_score is 0.48949549671273773\n",
      "after 1650 epochs, train loss is 15.099133491516113, train auc_score is 0.49742052877206056\n",
      "after 1650 epochs, test loss is 19.008148193359375, test auc_score is 0.5012887515258739\n",
      "after 1660 epochs, train loss is 13.833070755004883, train auc_score is 0.5085779204582962\n",
      "after 1660 epochs, test loss is 14.629120826721191, test auc_score is 0.5033433426465108\n",
      "after 1670 epochs, train loss is 13.424997329711914, train auc_score is 0.5099563757042497\n",
      "after 1670 epochs, test loss is 14.278505325317383, test auc_score is 0.5094253091618246\n",
      "after 1680 epochs, train loss is 12.75937271118164, train auc_score is 0.498010232808168\n",
      "after 1680 epochs, test loss is 13.463310241699219, test auc_score is 0.5028051587329533\n",
      "after 1690 epochs, train loss is 13.56712818145752, train auc_score is 0.5051335290704748\n",
      "after 1690 epochs, test loss is 11.804359436035156, test auc_score is 0.5085097785871039\n",
      "after 1700 epochs, train loss is 11.415763854980469, train auc_score is 0.5103041435043071\n",
      "after 1700 epochs, test loss is 12.695724487304688, test auc_score is 0.5094715925234407\n",
      "after 1710 epochs, train loss is 11.007899284362793, train auc_score is 0.513579347830603\n",
      "after 1710 epochs, test loss is 10.802189826965332, test auc_score is 0.5178007965113195\n",
      "after 1720 epochs, train loss is 10.669090270996094, train auc_score is 0.500347211798498\n",
      "after 1720 epochs, test loss is 11.253705978393555, test auc_score is 0.4975982883413854\n",
      "after 1730 epochs, train loss is 9.675169944763184, train auc_score is 0.5116183705814935\n",
      "after 1730 epochs, test loss is 9.847926139831543, test auc_score is 0.508021888449651\n",
      "after 1740 epochs, train loss is 9.788811683654785, train auc_score is 0.49577015701742166\n",
      "after 1740 epochs, test loss is 10.781539916992188, test auc_score is 0.49334087656879033\n",
      "after 1750 epochs, train loss is 9.502622604370117, train auc_score is 0.4910469257473654\n",
      "after 1750 epochs, test loss is 9.554703712463379, test auc_score is 0.4934086952641523\n",
      "after 1760 epochs, train loss is 8.983895301818848, train auc_score is 0.4920508172212687\n",
      "after 1760 epochs, test loss is 9.21988296508789, test auc_score is 0.489739932566454\n",
      "after 1770 epochs, train loss is 8.642495155334473, train auc_score is 0.5016149485610093\n",
      "after 1770 epochs, test loss is 8.187969207763672, test auc_score is 0.5002481814001152\n",
      "after 1780 epochs, train loss is 7.834864616394043, train auc_score is 0.47292140129842464\n",
      "after 1780 epochs, test loss is 7.8139848709106445, test auc_score is 0.48066591016185434\n",
      "after 1790 epochs, train loss is 7.813205718994141, train auc_score is 0.48882388099051466\n",
      "after 1790 epochs, test loss is 7.041654109954834, test auc_score is 0.4888001961644234\n",
      "after 1800 epochs, train loss is 6.772266387939453, train auc_score is 0.4974083160227575\n",
      "after 1800 epochs, test loss is 6.951263427734375, test auc_score is 0.4921893080168466\n",
      "after 1810 epochs, train loss is 6.542658805847168, train auc_score is 0.49786466898899606\n",
      "after 1810 epochs, test loss is 7.306524753570557, test auc_score is 0.4944000684793075\n",
      "after 1820 epochs, train loss is 6.158775329589844, train auc_score is 0.506004091429747\n",
      "after 1820 epochs, test loss is 5.972465991973877, test auc_score is 0.5058106325280575\n",
      "after 1830 epochs, train loss is 5.8961005210876465, train auc_score is 0.5081986179152169\n",
      "after 1830 epochs, test loss is 6.245235443115234, test auc_score is 0.4995268365283384\n",
      "after 1840 epochs, train loss is 5.183975696563721, train auc_score is 0.5018945218104879\n",
      "after 1840 epochs, test loss is 5.205234527587891, test auc_score is 0.5039744859112925\n",
      "after 1850 epochs, train loss is 5.0951619148254395, train auc_score is 0.5058584351414435\n",
      "after 1850 epochs, test loss is 6.028741836547852, test auc_score is 0.5019394732166322\n",
      "after 1860 epochs, train loss is 4.94957160949707, train auc_score is 0.4983054501534648\n",
      "after 1860 epochs, test loss is 4.589420795440674, test auc_score is 0.49421850607791246\n",
      "after 1870 epochs, train loss is 4.48370885848999, train auc_score is 0.5055701572336115\n",
      "after 1870 epochs, test loss is 5.5590033531188965, test auc_score is 0.5110166054842152\n",
      "after 1880 epochs, train loss is 4.184282302856445, train auc_score is 0.5024771937422038\n",
      "after 1880 epochs, test loss is 4.944745063781738, test auc_score is 0.5056345264093116\n",
      "after 1890 epochs, train loss is 4.377590656280518, train auc_score is 0.5063869835552887\n",
      "after 1890 epochs, test loss is 3.945401668548584, test auc_score is 0.5127944717729453\n",
      "after 1900 epochs, train loss is 3.678577423095703, train auc_score is 0.49834151627952744\n",
      "after 1900 epochs, test loss is 4.023400783538818, test auc_score is 0.49567397181167844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1910 epochs, train loss is 4.077865123748779, train auc_score is 0.503644866047599\n",
      "after 1910 epochs, test loss is 4.401815891265869, test auc_score is 0.4960338309467264\n",
      "after 1920 epochs, train loss is 3.743744373321533, train auc_score is 0.5077429020464609\n",
      "after 1920 epochs, test loss is 4.0252532958984375, test auc_score is 0.5147451286551563\n",
      "after 1930 epochs, train loss is 3.284414768218994, train auc_score is 0.5058927444529022\n",
      "after 1930 epochs, test loss is 3.3197028636932373, test auc_score is 0.5077750469704606\n",
      "after 1940 epochs, train loss is 2.9876043796539307, train auc_score is 0.5208577272877682\n",
      "after 1940 epochs, test loss is 3.175121784210205, test auc_score is 0.5170501416483383\n",
      "after 1950 epochs, train loss is 2.715074300765991, train auc_score is 0.5199915193839683\n",
      "after 1950 epochs, test loss is 2.9817793369293213, test auc_score is 0.5149130955333081\n",
      "after 1960 epochs, train loss is 2.6397111415863037, train auc_score is 0.5192288901598774\n",
      "after 1960 epochs, test loss is 2.6957590579986572, test auc_score is 0.5235530022548688\n",
      "after 1970 epochs, train loss is 2.656041383743286, train auc_score is 0.5005421518593293\n",
      "after 1970 epochs, test loss is 2.5484817028045654, test auc_score is 0.5047384215719042\n",
      "after 1980 epochs, train loss is 2.206259250640869, train auc_score is 0.5053440780196262\n",
      "after 1980 epochs, test loss is 2.6910576820373535, test auc_score is 0.5002683456519847\n",
      "after 1990 epochs, train loss is 2.1012556552886963, train auc_score is 0.5064693972869811\n",
      "after 1990 epochs, test loss is 2.2312023639678955, test auc_score is 0.5157200364234134\n",
      "after 2000 epochs, train loss is 1.9555208683013916, train auc_score is 0.5054939304285574\n",
      "after 2000 epochs, test loss is 2.189692497253418, test auc_score is 0.5065683796236542\n",
      "after 2010 epochs, train loss is 2.0906929969787598, train auc_score is 0.5014171321662475\n",
      "after 2010 epochs, test loss is 2.1408567428588867, test auc_score is 0.4994889011856929\n",
      "after 2020 epochs, train loss is 1.8950636386871338, train auc_score is 0.5053128175192804\n",
      "after 2020 epochs, test loss is 1.7247178554534912, test auc_score is 0.5103314571739771\n",
      "after 2030 epochs, train loss is 1.6545228958129883, train auc_score is 0.5151462766276103\n",
      "after 2030 epochs, test loss is 1.8362797498703003, test auc_score is 0.51498987611839\n",
      "after 2040 epochs, train loss is 1.561509132385254, train auc_score is 0.5133625453968177\n",
      "after 2040 epochs, test loss is 1.7901601791381836, test auc_score is 0.5181318224177246\n",
      "after 2050 epochs, train loss is 1.6301517486572266, train auc_score is 0.5105190334588754\n",
      "after 2050 epochs, test loss is 1.4983211755752563, test auc_score is 0.5098095174645605\n",
      "after 2060 epochs, train loss is 1.4678915739059448, train auc_score is 0.5207653101761855\n",
      "after 2060 epochs, test loss is 1.5265167951583862, test auc_score is 0.5183386283061224\n",
      "after 2070 epochs, train loss is 1.2849371433258057, train auc_score is 0.5183503996851627\n",
      "after 2070 epochs, test loss is 1.3171957731246948, test auc_score is 0.5242982974341511\n",
      "after 2080 epochs, train loss is 1.2603894472122192, train auc_score is 0.5224465228092178\n",
      "after 2080 epochs, test loss is 1.1824973821640015, test auc_score is 0.5249176338143192\n",
      "after 2090 epochs, train loss is 1.1614353656768799, train auc_score is 0.5169044070622987\n",
      "after 2090 epochs, test loss is 1.1667078733444214, test auc_score is 0.5233853158252826\n",
      "after 2100 epochs, train loss is 1.0841656923294067, train auc_score is 0.5233652495205888\n",
      "after 2100 epochs, test loss is 1.1978342533111572, test auc_score is 0.5233014149627286\n",
      "after 2110 epochs, train loss is 1.0645018815994263, train auc_score is 0.5083086361056952\n",
      "after 2110 epochs, test loss is 1.049232840538025, test auc_score is 0.5050588745673847\n",
      "after 2120 epochs, train loss is 0.9777041673660278, train auc_score is 0.5121750298091552\n",
      "after 2120 epochs, test loss is 1.0017448663711548, test auc_score is 0.5151346093909261\n",
      "after 2130 epochs, train loss is 0.9218633770942688, train auc_score is 0.5250216970411132\n",
      "after 2130 epochs, test loss is 0.9056301116943359, test auc_score is 0.5247623151664778\n",
      "after 2140 epochs, train loss is 0.8815415501594543, train auc_score is 0.516437904644611\n",
      "after 2140 epochs, test loss is 0.8328812122344971, test auc_score is 0.5143507307212021\n",
      "after 2150 epochs, train loss is 0.8033344745635986, train auc_score is 0.5098565006357826\n",
      "after 2150 epochs, test loss is 0.8382402658462524, test auc_score is 0.5099873592483181\n",
      "after 2160 epochs, train loss is 0.7760835289955139, train auc_score is 0.5161581025463938\n",
      "after 2160 epochs, test loss is 0.7835490107536316, test auc_score is 0.5166301013671992\n",
      "after 2170 epochs, train loss is 0.6978441476821899, train auc_score is 0.522751381668573\n",
      "after 2170 epochs, test loss is 0.6705339550971985, test auc_score is 0.5214272364043677\n",
      "after 2180 epochs, train loss is 0.6265889406204224, train auc_score is 0.5325869224696858\n",
      "after 2180 epochs, test loss is 0.8279056549072266, test auc_score is 0.523151671009153\n",
      "after 2190 epochs, train loss is 0.6413916945457458, train auc_score is 0.530892248210137\n",
      "after 2190 epochs, test loss is 0.7311293482780457, test auc_score is 0.5342910007856922\n",
      "after 2200 epochs, train loss is 0.5794862508773804, train auc_score is 0.5297999250936739\n",
      "after 2200 epochs, test loss is 0.6101177930831909, test auc_score is 0.5328462699998\n",
      "after 2210 epochs, train loss is 0.5433349609375, train auc_score is 0.5330614744489053\n",
      "after 2210 epochs, test loss is 0.5565364360809326, test auc_score is 0.5404325595051093\n",
      "after 2220 epochs, train loss is 0.5200016498565674, train auc_score is 0.5253397487236696\n",
      "after 2220 epochs, test loss is 0.5531060695648193, test auc_score is 0.5269842561784222\n",
      "after 2230 epochs, train loss is 0.4818493723869324, train auc_score is 0.5197338934603677\n",
      "after 2230 epochs, test loss is 0.49497735500335693, test auc_score is 0.5205643958829402\n",
      "after 2240 epochs, train loss is 0.4759191572666168, train auc_score is 0.5361987103803928\n",
      "after 2240 epochs, test loss is 0.487104207277298, test auc_score is 0.5401271977585553\n",
      "after 2250 epochs, train loss is 0.44965648651123047, train auc_score is 0.5184613561159103\n",
      "after 2250 epochs, test loss is 0.4496515393257141, test auc_score is 0.527810576064413\n",
      "after 2260 epochs, train loss is 0.40295466780662537, train auc_score is 0.5335924218186077\n",
      "after 2260 epochs, test loss is 0.41413116455078125, test auc_score is 0.5309573367307912\n",
      "after 2270 epochs, train loss is 0.3813793659210205, train auc_score is 0.5313234704399322\n",
      "after 2270 epochs, test loss is 0.43753692507743835, test auc_score is 0.535505707658047\n",
      "after 2280 epochs, train loss is 0.3905828297138214, train auc_score is 0.528914344758447\n",
      "after 2280 epochs, test loss is 0.3910950720310211, test auc_score is 0.5236841400041619\n",
      "after 2290 epochs, train loss is 0.35349947214126587, train auc_score is 0.543890830258803\n",
      "after 2290 epochs, test loss is 0.3384363651275635, test auc_score is 0.5413553038401573\n",
      "after 2300 epochs, train loss is 0.30521923303604126, train auc_score is 0.5325730064093085\n",
      "after 2300 epochs, test loss is 0.31183966994285583, test auc_score is 0.5312968726931158\n",
      "after 2310 epochs, train loss is 0.32128363847732544, train auc_score is 0.5389801672236105\n",
      "after 2310 epochs, test loss is 0.3202768564224243, test auc_score is 0.5322842946995907\n",
      "after 2320 epochs, train loss is 0.29697418212890625, train auc_score is 0.5242500037652738\n",
      "after 2320 epochs, test loss is 0.29240310192108154, test auc_score is 0.5218083909338332\n",
      "after 2330 epochs, train loss is 0.2681128978729248, train auc_score is 0.5391418459894411\n",
      "after 2330 epochs, test loss is 0.2698315978050232, test auc_score is 0.5373874614437754\n",
      "after 2340 epochs, train loss is 0.25075581669807434, train auc_score is 0.5436639391955111\n",
      "after 2340 epochs, test loss is 0.2638865113258362, test auc_score is 0.5432331812034895\n",
      "after 2350 epochs, train loss is 0.2538900077342987, train auc_score is 0.5462325870846615\n",
      "after 2350 epochs, test loss is 0.24104472994804382, test auc_score is 0.539458670699974\n",
      "after 2360 epochs, train loss is 0.22089602053165436, train auc_score is 0.5477942008350996\n",
      "after 2360 epochs, test loss is 0.23285512626171112, test auc_score is 0.5567435820747996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2370 epochs, train loss is 0.22368386387825012, train auc_score is 0.5504037000042534\n",
      "after 2370 epochs, test loss is 0.2038123458623886, test auc_score is 0.5543687716658202\n",
      "after 2380 epochs, train loss is 0.21395660936832428, train auc_score is 0.5526505736112919\n",
      "after 2380 epochs, test loss is 0.23500953614711761, test auc_score is 0.557974941359763\n",
      "after 2390 epochs, train loss is 0.21554328501224518, train auc_score is 0.540388940180357\n",
      "after 2390 epochs, test loss is 0.21886248886585236, test auc_score is 0.5381105326322784\n",
      "after 2400 epochs, train loss is 0.20315159857273102, train auc_score is 0.5651299859896014\n",
      "after 2400 epochs, test loss is 0.19387802481651306, test auc_score is 0.5655641755750115\n",
      "after 2410 epochs, train loss is 0.18269923329353333, train auc_score is 0.5337777514191854\n",
      "after 2410 epochs, test loss is 0.2130746841430664, test auc_score is 0.5373948839824794\n",
      "after 2420 epochs, train loss is 0.18831110000610352, train auc_score is 0.5653141612589441\n",
      "after 2420 epochs, test loss is 0.1895371377468109, test auc_score is 0.5557984423637377\n",
      "after 2430 epochs, train loss is 0.1742527037858963, train auc_score is 0.5688957514214857\n",
      "after 2430 epochs, test loss is 0.1673019826412201, test auc_score is 0.5821536617577157\n",
      "after 2440 epochs, train loss is 0.1558447629213333, train auc_score is 0.5753683359760335\n",
      "after 2440 epochs, test loss is 0.15868166089057922, test auc_score is 0.5781369839177705\n",
      "after 2450 epochs, train loss is 0.14805735647678375, train auc_score is 0.564211261355077\n",
      "after 2450 epochs, test loss is 0.145974799990654, test auc_score is 0.5699287093513954\n",
      "after 2460 epochs, train loss is 0.14130473136901855, train auc_score is 0.5653470741381686\n",
      "after 2460 epochs, test loss is 0.13751383125782013, test auc_score is 0.5649129740055964\n",
      "after 2470 epochs, train loss is 0.13222390413284302, train auc_score is 0.5602978166872017\n",
      "after 2470 epochs, test loss is 0.14838755130767822, test auc_score is 0.5622723482139135\n",
      "after 2480 epochs, train loss is 0.12715326249599457, train auc_score is 0.5767296988716619\n",
      "after 2480 epochs, test loss is 0.1257994920015335, test auc_score is 0.5685377343233459\n",
      "after 2490 epochs, train loss is 0.12756988406181335, train auc_score is 0.5735663793266366\n",
      "after 2490 epochs, test loss is 0.12329800426959991, test auc_score is 0.578594006016432\n",
      "after 2500 epochs, train loss is 0.12318572402000427, train auc_score is 0.5666426257143781\n",
      "after 2500 epochs, test loss is 0.12658873200416565, test auc_score is 0.5661628647085581\n",
      "model saved in E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for epoch  in range(1, num_epochs+1):\n",
    "        _ = sess.run(train_op, feed_dict = {X_nn:X_tr, y_nn:y_tr.reshape((y_tr.shape[0], 1))})\n",
    "        if epoch%10 == 0:\n",
    "            loss = sess.run(loss_op, feed_dict={X_nn:X_tr, y_nn:y_tr.reshape((y_tr.shape[0], 1))})\n",
    "            preds = sess.run(out, feed_dict={X_nn:X_tr})\n",
    "            print('after {} epochs, train loss is {}, train auc_score is {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op, feed_dict={X_nn:X_ts, y_nn:y_ts.reshape((y_ts.shape[0], 1))})\n",
    "            preds = sess.run(out, feed_dict={X_nn:X_ts})\n",
    "            print('after {} epochs, test loss is {}, test auc_score is {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path = saver.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt')\n",
    "    print('model saved in {}'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt\n",
      "after 10 epochs, train loss is 0.1146075576543808, train auc_score is 0.5716910795245282\n",
      "after 10 epochs, test loss is 0.11838828772306442, test auc_score is 0.5675226663204892\n",
      "after 20 epochs, train loss is 0.11138316988945007, train auc_score is 0.5827872399319394\n",
      "after 20 epochs, test loss is 0.12114627659320831, test auc_score is 0.5954540346982183\n",
      "after 30 epochs, train loss is 0.11217816174030304, train auc_score is 0.5922233661043903\n",
      "after 30 epochs, test loss is 0.11558612436056137, test auc_score is 0.5887114809348261\n",
      "after 40 epochs, train loss is 0.11203011125326157, train auc_score is 0.5852484273169033\n",
      "after 40 epochs, test loss is 0.10569582879543304, test auc_score is 0.5826558049144934\n",
      "after 50 epochs, train loss is 0.10476762056350708, train auc_score is 0.5946343886392926\n",
      "after 50 epochs, test loss is 0.10316462814807892, test auc_score is 0.596314513219504\n",
      "after 60 epochs, train loss is 0.10034368187189102, train auc_score is 0.5939042350687247\n",
      "after 60 epochs, test loss is 0.10619756579399109, test auc_score is 0.5962354049113274\n",
      "after 70 epochs, train loss is 0.09853685647249222, train auc_score is 0.595173438480672\n",
      "after 70 epochs, test loss is 0.1033492162823677, test auc_score is 0.5938116686920246\n",
      "after 80 epochs, train loss is 0.09850578755140305, train auc_score is 0.6097638287643249\n",
      "after 80 epochs, test loss is 0.09692920744419098, test auc_score is 0.6070833112350251\n",
      "after 90 epochs, train loss is 0.09387412667274475, train auc_score is 0.6072926838878956\n",
      "after 90 epochs, test loss is 0.0947219505906105, test auc_score is 0.6123048490865759\n",
      "after 100 epochs, train loss is 0.09140210598707199, train auc_score is 0.6058099441310112\n",
      "after 100 epochs, test loss is 0.10457272082567215, test auc_score is 0.607125917604336\n",
      "after 110 epochs, train loss is 0.09017372131347656, train auc_score is 0.6064049395771931\n",
      "after 110 epochs, test loss is 0.09650561958551407, test auc_score is 0.6027488851702102\n",
      "after 120 epochs, train loss is 0.08942854404449463, train auc_score is 0.6201139907434918\n",
      "after 120 epochs, test loss is 0.08807294815778732, test auc_score is 0.619452482758178\n",
      "after 130 epochs, train loss is 0.08665052801370621, train auc_score is 0.6193640865575831\n",
      "after 130 epochs, test loss is 0.08955277502536774, test auc_score is 0.6191000150008822\n",
      "after 140 epochs, train loss is 0.08488813042640686, train auc_score is 0.6295389658309479\n",
      "after 140 epochs, test loss is 0.08717912435531616, test auc_score is 0.6287733435258729\n",
      "after 150 epochs, train loss is 0.08381527662277222, train auc_score is 0.6321289201903899\n",
      "after 150 epochs, test loss is 0.08655919879674911, test auc_score is 0.6238057892436507\n",
      "after 160 epochs, train loss is 0.0835675299167633, train auc_score is 0.6278016163254115\n",
      "after 160 epochs, test loss is 0.0841907411813736, test auc_score is 0.6256685660097709\n",
      "after 170 epochs, train loss is 0.08312606811523438, train auc_score is 0.6305706278124839\n",
      "after 170 epochs, test loss is 0.08423002064228058, test auc_score is 0.6333694467990005\n",
      "after 180 epochs, train loss is 0.0820266604423523, train auc_score is 0.6407531492887141\n",
      "after 180 epochs, test loss is 0.0877106636762619, test auc_score is 0.6392423389086301\n",
      "after 190 epochs, train loss is 0.0795564278960228, train auc_score is 0.6491435217773502\n",
      "after 190 epochs, test loss is 0.08096206933259964, test auc_score is 0.6482162723362481\n",
      "after 200 epochs, train loss is 0.07985412329435349, train auc_score is 0.6474551351220614\n",
      "after 200 epochs, test loss is 0.08047275245189667, test auc_score is 0.65248537258184\n",
      "after 210 epochs, train loss is 0.0804075077176094, train auc_score is 0.6476956544541017\n",
      "after 210 epochs, test loss is 0.08020541816949844, test auc_score is 0.6499101505117595\n",
      "after 220 epochs, train loss is 0.07835902273654938, train auc_score is 0.6583544538681457\n",
      "after 220 epochs, test loss is 0.07884339243173599, test auc_score is 0.6660349427694844\n",
      "after 230 epochs, train loss is 0.07735047489404678, train auc_score is 0.6588924384849077\n",
      "after 230 epochs, test loss is 0.07905927300453186, test auc_score is 0.6605580409184428\n",
      "after 240 epochs, train loss is 0.07679061591625214, train auc_score is 0.6629057906596194\n",
      "after 240 epochs, test loss is 0.077601857483387, test auc_score is 0.6654569850171288\n",
      "after 250 epochs, train loss is 0.07626370340585709, train auc_score is 0.6660514665009412\n",
      "after 250 epochs, test loss is 0.07727397978305817, test auc_score is 0.6667431439518182\n",
      "after 260 epochs, train loss is 0.0756789892911911, train auc_score is 0.6691576062007755\n",
      "after 260 epochs, test loss is 0.07715805619955063, test auc_score is 0.6707779855105314\n",
      "after 270 epochs, train loss is 0.0752984806895256, train auc_score is 0.6746228240244294\n",
      "after 270 epochs, test loss is 0.07745233923196793, test auc_score is 0.6767799867914958\n",
      "after 280 epochs, train loss is 0.07476910948753357, train auc_score is 0.6773504283288361\n",
      "after 280 epochs, test loss is 0.07557228952646255, test auc_score is 0.6705227679675139\n",
      "after 290 epochs, train loss is 0.07443235069513321, train auc_score is 0.67652513846083\n",
      "after 290 epochs, test loss is 0.07615616172552109, test auc_score is 0.6812207683006867\n",
      "after 300 epochs, train loss is 0.07404440641403198, train auc_score is 0.6803808230520754\n",
      "after 300 epochs, test loss is 0.07519255578517914, test auc_score is 0.679753617210019\n",
      "after 310 epochs, train loss is 0.07450460642576218, train auc_score is 0.6809282723542249\n",
      "after 310 epochs, test loss is 0.07548485696315765, test auc_score is 0.6786120700201543\n",
      "after 320 epochs, train loss is 0.07332879304885864, train auc_score is 0.6849100212499701\n",
      "after 320 epochs, test loss is 0.07449328899383545, test auc_score is 0.6899825610849696\n",
      "after 330 epochs, train loss is 0.07362145185470581, train auc_score is 0.6861738982421393\n",
      "after 330 epochs, test loss is 0.07445120811462402, test auc_score is 0.6871701605468323\n",
      "after 340 epochs, train loss is 0.0730414092540741, train auc_score is 0.6932988939585191\n",
      "after 340 epochs, test loss is 0.07437663525342941, test auc_score is 0.694603892264624\n",
      "after 350 epochs, train loss is 0.07273096591234207, train auc_score is 0.6932748966859452\n",
      "after 350 epochs, test loss is 0.07392403483390808, test auc_score is 0.693899022188031\n",
      "after 360 epochs, train loss is 0.07260110974311829, train auc_score is 0.6942014570656778\n",
      "after 360 epochs, test loss is 0.07378161698579788, test auc_score is 0.7026147061120276\n",
      "after 370 epochs, train loss is 0.07242482900619507, train auc_score is 0.6958743763549219\n",
      "after 370 epochs, test loss is 0.07357482612133026, test auc_score is 0.6944360936556115\n",
      "after 380 epochs, train loss is 0.072146475315094, train auc_score is 0.699173601293594\n",
      "after 380 epochs, test loss is 0.07332967966794968, test auc_score is 0.7038962282970983\n",
      "after 390 epochs, train loss is 0.0718906819820404, train auc_score is 0.699436102664523\n",
      "after 390 epochs, test loss is 0.07371252030134201, test auc_score is 0.7060878060776694\n",
      "after 400 epochs, train loss is 0.07172350585460663, train auc_score is 0.7026504208641542\n",
      "after 400 epochs, test loss is 0.07329658418893814, test auc_score is 0.7057322440378662\n",
      "after 410 epochs, train loss is 0.0716976597905159, train auc_score is 0.7035821437905618\n",
      "after 410 epochs, test loss is 0.07279857993125916, test auc_score is 0.7092982036396864\n",
      "after 420 epochs, train loss is 0.07176613807678223, train auc_score is 0.7054546571565372\n",
      "after 420 epochs, test loss is 0.07278832793235779, test auc_score is 0.7112765376792307\n",
      "after 430 epochs, train loss is 0.07148438692092896, train auc_score is 0.7088502653908088\n",
      "after 430 epochs, test loss is 0.0725322887301445, test auc_score is 0.7098616435046274\n",
      "after 440 epochs, train loss is 0.07136747241020203, train auc_score is 0.7104693409431163\n",
      "after 440 epochs, test loss is 0.07243525981903076, test auc_score is 0.71387782588544\n",
      "after 450 epochs, train loss is 0.07117043435573578, train auc_score is 0.7093281969931683\n",
      "after 450 epochs, test loss is 0.07216700166463852, test auc_score is 0.7110816633192534\n",
      "after 460 epochs, train loss is 0.07108161598443985, train auc_score is 0.7108450901991035\n",
      "after 460 epochs, test loss is 0.07233460247516632, test auc_score is 0.7098443834534599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 470 epochs, train loss is 0.07098366320133209, train auc_score is 0.7139825085964177\n",
      "after 470 epochs, test loss is 0.07238230854272842, test auc_score is 0.7163406005450799\n",
      "after 480 epochs, train loss is 0.07106871157884598, train auc_score is 0.7154556912976804\n",
      "after 480 epochs, test loss is 0.07222296297550201, test auc_score is 0.7156453155772414\n",
      "after 490 epochs, train loss is 0.07089923322200775, train auc_score is 0.7145781108774572\n",
      "after 490 epochs, test loss is 0.07213713973760605, test auc_score is 0.7205541782068654\n",
      "after 500 epochs, train loss is 0.07071514427661896, train auc_score is 0.715283308265611\n",
      "after 500 epochs, test loss is 0.07194095104932785, test auc_score is 0.7191310232639563\n",
      "model saved in E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, path)\n",
    "    for epoch  in range(1, 500+1):\n",
    "        _ = sess.run(train_op, feed_dict = {X_nn:X_tr, y_nn:y_tr.reshape((y_tr.shape[0], 1))})\n",
    "        if epoch%10 == 0:\n",
    "            loss = sess.run(loss_op, feed_dict={X_nn:X_tr, y_nn:y_tr.reshape((y_tr.shape[0], 1))})\n",
    "            preds = sess.run(out, feed_dict={X_nn:X_tr})\n",
    "            print('after {} epochs, train loss is {}, train auc_score is {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op, feed_dict={X_nn:X_ts, y_nn:y_ts.reshape((y_ts.shape[0], 1))})\n",
    "            preds = sess.run(out, feed_dict={X_nn:X_ts})\n",
    "            print('after {} epochs, test loss is {}, test auc_score is {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path = saver.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt')\n",
    "    print('model saved in {}'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt\n",
      "after 10 epochs, train loss is 0.07079125195741653, train auc_score is 0.7156419496443708\n",
      "after 10 epochs, test loss is 0.07176567614078522, test auc_score is 0.7204824581603458\n",
      "after 20 epochs, train loss is 0.0706205666065216, train auc_score is 0.7167991029184826\n",
      "after 20 epochs, test loss is 0.07176943868398666, test auc_score is 0.7218825103736366\n",
      "after 30 epochs, train loss is 0.07062182575464249, train auc_score is 0.7192337475089694\n",
      "after 30 epochs, test loss is 0.07180514931678772, test auc_score is 0.7210422708905045\n",
      "after 40 epochs, train loss is 0.07058728486299515, train auc_score is 0.7193892319308515\n",
      "after 40 epochs, test loss is 0.07160143554210663, test auc_score is 0.722666772323067\n",
      "after 50 epochs, train loss is 0.07058921456336975, train auc_score is 0.7209096056353431\n",
      "after 50 epochs, test loss is 0.07177093625068665, test auc_score is 0.7266273822625506\n",
      "after 60 epochs, train loss is 0.07059404253959656, train auc_score is 0.7207826823074448\n",
      "after 60 epochs, test loss is 0.07156305760145187, test auc_score is 0.7229558181952911\n",
      "after 70 epochs, train loss is 0.07053497433662415, train auc_score is 0.7204649798318445\n",
      "after 70 epochs, test loss is 0.07151681929826736, test auc_score is 0.7225564469734396\n",
      "after 80 epochs, train loss is 0.0705006942152977, train auc_score is 0.7212820935495607\n",
      "after 80 epochs, test loss is 0.07160894572734833, test auc_score is 0.7252485475412981\n",
      "after 90 epochs, train loss is 0.0704023465514183, train auc_score is 0.7213239948239716\n",
      "after 90 epochs, test loss is 0.07169871032238007, test auc_score is 0.7243871310753651\n",
      "after 100 epochs, train loss is 0.07045780122280121, train auc_score is 0.7217003965065487\n",
      "after 100 epochs, test loss is 0.07168786227703094, test auc_score is 0.7269161944276366\n",
      "after 110 epochs, train loss is 0.07043340057134628, train auc_score is 0.7235497910072519\n",
      "after 110 epochs, test loss is 0.07159949839115143, test auc_score is 0.7252164860380551\n",
      "after 120 epochs, train loss is 0.07036196440458298, train auc_score is 0.7226674548056352\n",
      "after 120 epochs, test loss is 0.07164861261844635, test auc_score is 0.7228852324074146\n",
      "after 130 epochs, train loss is 0.07039982080459595, train auc_score is 0.7231868651924266\n",
      "after 130 epochs, test loss is 0.07150400429964066, test auc_score is 0.727455649708025\n",
      "after 140 epochs, train loss is 0.0703386440873146, train auc_score is 0.7237340169120979\n",
      "after 140 epochs, test loss is 0.07154449075460434, test auc_score is 0.724550975359602\n",
      "after 150 epochs, train loss is 0.07040230184793472, train auc_score is 0.7244529389940304\n",
      "after 150 epochs, test loss is 0.07142642885446548, test auc_score is 0.7257667448204109\n",
      "after 160 epochs, train loss is 0.07033425569534302, train auc_score is 0.7240811385161058\n",
      "after 160 epochs, test loss is 0.07151065766811371, test auc_score is 0.7277742860200191\n",
      "after 170 epochs, train loss is 0.07034872472286224, train auc_score is 0.7230947502126056\n",
      "after 170 epochs, test loss is 0.071538545191288, test auc_score is 0.730717528278408\n",
      "after 180 epochs, train loss is 0.07035767287015915, train auc_score is 0.7248583556110675\n",
      "after 180 epochs, test loss is 0.0714094415307045, test auc_score is 0.7249511692305795\n",
      "after 190 epochs, train loss is 0.07026022672653198, train auc_score is 0.7247021822694301\n",
      "after 190 epochs, test loss is 0.0714372918009758, test auc_score is 0.7260335261926185\n",
      "after 200 epochs, train loss is 0.07025088369846344, train auc_score is 0.7251077676055458\n",
      "after 200 epochs, test loss is 0.07134272903203964, test auc_score is 0.7291287310643466\n",
      "after 210 epochs, train loss is 0.07029860466718674, train auc_score is 0.7249654774903267\n",
      "after 210 epochs, test loss is 0.07148056477308273, test auc_score is 0.7281798395746953\n",
      "after 220 epochs, train loss is 0.07029066234827042, train auc_score is 0.7253995389675023\n",
      "after 220 epochs, test loss is 0.07144812494516373, test auc_score is 0.7289577851992085\n",
      "after 230 epochs, train loss is 0.07026652991771698, train auc_score is 0.7252180023814767\n",
      "after 230 epochs, test loss is 0.07151953876018524, test auc_score is 0.7288727282653453\n",
      "after 240 epochs, train loss is 0.07027287036180496, train auc_score is 0.7247288674762599\n",
      "after 240 epochs, test loss is 0.07161936163902283, test auc_score is 0.7301049881018138\n",
      "after 250 epochs, train loss is 0.07024534046649933, train auc_score is 0.7259669353942594\n",
      "after 250 epochs, test loss is 0.07140284031629562, test auc_score is 0.7312216719682871\n",
      "after 260 epochs, train loss is 0.07021379470825195, train auc_score is 0.7252986986597573\n",
      "after 260 epochs, test loss is 0.07137268036603928, test auc_score is 0.7276100584560758\n",
      "after 270 epochs, train loss is 0.07017640024423599, train auc_score is 0.7256434517683279\n",
      "after 270 epochs, test loss is 0.07131869345903397, test auc_score is 0.7298635561638451\n",
      "after 280 epochs, train loss is 0.07024820894002914, train auc_score is 0.7252513184656743\n",
      "after 280 epochs, test loss is 0.07138346135616302, test auc_score is 0.7303289574424288\n",
      "after 290 epochs, train loss is 0.07016271352767944, train auc_score is 0.7271944333487805\n",
      "after 290 epochs, test loss is 0.07152742892503738, test auc_score is 0.731748366838939\n",
      "after 300 epochs, train loss is 0.07020192593336105, train auc_score is 0.7266205222491792\n",
      "after 300 epochs, test loss is 0.0713326632976532, test auc_score is 0.7310627074890923\n",
      "after 310 epochs, train loss is 0.07018336653709412, train auc_score is 0.7260283637757358\n",
      "after 310 epochs, test loss is 0.07129723578691483, test auc_score is 0.7295657540641828\n",
      "after 320 epochs, train loss is 0.07021775096654892, train auc_score is 0.7259648547893486\n",
      "after 320 epochs, test loss is 0.07118359208106995, test auc_score is 0.7297368557340794\n",
      "after 330 epochs, train loss is 0.07020847499370575, train auc_score is 0.726865614204504\n",
      "after 330 epochs, test loss is 0.07137470692396164, test auc_score is 0.7306020644878389\n",
      "after 340 epochs, train loss is 0.07020983099937439, train auc_score is 0.726437221925727\n",
      "after 340 epochs, test loss is 0.07152941823005676, test auc_score is 0.730272475101309\n",
      "after 350 epochs, train loss is 0.07016145437955856, train auc_score is 0.7267458798323799\n",
      "after 350 epochs, test loss is 0.07124634087085724, test auc_score is 0.732631465095091\n",
      "after 360 epochs, train loss is 0.07018910348415375, train auc_score is 0.7264801665684149\n",
      "after 360 epochs, test loss is 0.07133134454488754, test auc_score is 0.7285141031039861\n",
      "after 370 epochs, train loss is 0.07025424391031265, train auc_score is 0.7270520458195564\n",
      "after 370 epochs, test loss is 0.07148687541484833, test auc_score is 0.7272540227698059\n",
      "after 380 epochs, train loss is 0.07014033198356628, train auc_score is 0.72628441999874\n",
      "after 380 epochs, test loss is 0.07132691890001297, test auc_score is 0.7293151358776417\n",
      "after 390 epochs, train loss is 0.07017570734024048, train auc_score is 0.727161271643529\n",
      "after 390 epochs, test loss is 0.07129329442977905, test auc_score is 0.7292564785020906\n",
      "after 400 epochs, train loss is 0.07020751386880875, train auc_score is 0.7263377810171401\n",
      "after 400 epochs, test loss is 0.07142534852027893, test auc_score is 0.7335796554633282\n",
      "after 410 epochs, train loss is 0.07017797976732254, train auc_score is 0.7273237890598798\n",
      "after 410 epochs, test loss is 0.07140065729618073, test auc_score is 0.7280383221123785\n",
      "after 420 epochs, train loss is 0.07018564641475677, train auc_score is 0.7274572569276572\n",
      "after 420 epochs, test loss is 0.0713052749633789, test auc_score is 0.7320661711535218\n",
      "after 430 epochs, train loss is 0.07021727412939072, train auc_score is 0.7271275113119096\n",
      "after 430 epochs, test loss is 0.07135825604200363, test auc_score is 0.732787363336635\n",
      "after 440 epochs, train loss is 0.07014243304729462, train auc_score is 0.7271236452121295\n",
      "after 440 epochs, test loss is 0.07126528769731522, test auc_score is 0.7311755568758105\n",
      "after 450 epochs, train loss is 0.07016773521900177, train auc_score is 0.7275332020727252\n",
      "after 450 epochs, test loss is 0.07135814428329468, test auc_score is 0.731123561711741\n",
      "after 460 epochs, train loss is 0.07025221735239029, train auc_score is 0.7271529589158372\n",
      "after 460 epochs, test loss is 0.07149612903594971, test auc_score is 0.7310182875523902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 470 epochs, train loss is 0.07016193121671677, train auc_score is 0.7280061494405425\n",
      "after 470 epochs, test loss is 0.07132524251937866, test auc_score is 0.7304775016993625\n",
      "after 480 epochs, train loss is 0.07016932219266891, train auc_score is 0.7277612592360505\n",
      "after 480 epochs, test loss is 0.07147160172462463, test auc_score is 0.7298221588394613\n",
      "after 490 epochs, train loss is 0.07025783509016037, train auc_score is 0.7271403007323427\n",
      "after 490 epochs, test loss is 0.07126769423484802, test auc_score is 0.7316003710147557\n",
      "after 500 epochs, train loss is 0.07017450034618378, train auc_score is 0.7271435530744427\n",
      "after 500 epochs, test loss is 0.07136232405900955, test auc_score is 0.7306887449072877\n",
      "model saved in E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, path)\n",
    "    for epoch  in range(1, 500+1):\n",
    "        _ = sess.run(train_op, feed_dict = {X_nn:X_tr, y_nn:y_tr.reshape((y_tr.shape[0], 1))})\n",
    "        if epoch%10 == 0:\n",
    "            loss = sess.run(loss_op, feed_dict={X_nn:X_tr, y_nn:y_tr.reshape((y_tr.shape[0], 1))})\n",
    "            preds = sess.run(out, feed_dict={X_nn:X_tr})\n",
    "            print('after {} epochs, train loss is {}, train auc_score is {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op, feed_dict={X_nn:X_ts, y_nn:y_ts.reshape((y_ts.shape[0], 1))})\n",
    "            preds = sess.run(out, feed_dict={X_nn:X_ts})\n",
    "            print('after {} epochs, test loss is {}, test auc_score is {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path = saver.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt')\n",
    "    print('model saved in {}'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt\n",
      "after 10 epochs, train loss is 0.07017677277326584, train auc_score is 0.7258055602436526\n",
      "after 10 epochs, test loss is 0.07129833102226257, test auc_score is 0.729060416909852\n",
      "after 20 epochs, train loss is 0.0702291801571846, train auc_score is 0.726970399136618\n",
      "after 20 epochs, test loss is 0.07128242403268814, test auc_score is 0.7315654146590964\n",
      "after 30 epochs, train loss is 0.07028235495090485, train auc_score is 0.7262550072986675\n",
      "after 30 epochs, test loss is 0.07121148705482483, test auc_score is 0.7302514695037424\n",
      "after 40 epochs, train loss is 0.0701298788189888, train auc_score is 0.7275031586046083\n",
      "after 40 epochs, test loss is 0.07138251513242722, test auc_score is 0.7296786875854706\n",
      "after 50 epochs, train loss is 0.07015950977802277, train auc_score is 0.7265807716979834\n",
      "after 50 epochs, test loss is 0.07127272337675095, test auc_score is 0.7303097591800631\n",
      "after 60 epochs, train loss is 0.07022108137607574, train auc_score is 0.7271779518881091\n",
      "after 60 epochs, test loss is 0.07131784409284592, test auc_score is 0.732013026150333\n",
      "after 70 epochs, train loss is 0.07022900134325027, train auc_score is 0.7266355354780556\n",
      "after 70 epochs, test loss is 0.07124742865562439, test auc_score is 0.7296437966678099\n",
      "after 80 epochs, train loss is 0.0701432079076767, train auc_score is 0.726644727206434\n",
      "after 80 epochs, test loss is 0.07140640169382095, test auc_score is 0.728890620883833\n",
      "after 90 epochs, train loss is 0.07023970782756805, train auc_score is 0.7278022005127491\n",
      "after 90 epochs, test loss is 0.07130249589681625, test auc_score is 0.7319427363914982\n",
      "after 100 epochs, train loss is 0.07016706466674805, train auc_score is 0.7271915832226787\n",
      "after 100 epochs, test loss is 0.07134369760751724, test auc_score is 0.727510091006806\n",
      "after 110 epochs, train loss is 0.0701703280210495, train auc_score is 0.7258802261499848\n",
      "after 110 epochs, test loss is 0.0714162066578865, test auc_score is 0.7288862645827803\n",
      "after 120 epochs, train loss is 0.07018329203128815, train auc_score is 0.7268020671425922\n",
      "after 120 epochs, test loss is 0.0713573694229126, test auc_score is 0.7328888140472075\n",
      "after 130 epochs, train loss is 0.07016259431838989, train auc_score is 0.7280004813300159\n",
      "after 130 epochs, test loss is 0.07127165794372559, test auc_score is 0.7301540697168959\n",
      "after 140 epochs, train loss is 0.07014866173267365, train auc_score is 0.7271095906952982\n",
      "after 140 epochs, test loss is 0.07123401761054993, test auc_score is 0.7301553348515365\n",
      "after 150 epochs, train loss is 0.07016222923994064, train auc_score is 0.7280036058965886\n",
      "after 150 epochs, test loss is 0.07127520442008972, test auc_score is 0.7306040494404646\n",
      "after 160 epochs, train loss is 0.07014535367488861, train auc_score is 0.7274833733751541\n",
      "after 160 epochs, test loss is 0.07116233557462692, test auc_score is 0.7303356975562897\n",
      "after 170 epochs, train loss is 0.07016205042600632, train auc_score is 0.7280843785237137\n",
      "after 170 epochs, test loss is 0.07129908353090286, test auc_score is 0.7314455914513793\n",
      "after 180 epochs, train loss is 0.07012850791215897, train auc_score is 0.7282074456415784\n",
      "after 180 epochs, test loss is 0.07124349474906921, test auc_score is 0.732947552441233\n",
      "after 190 epochs, train loss is 0.07015485316514969, train auc_score is 0.7265222937246404\n",
      "after 190 epochs, test loss is 0.07134508341550827, test auc_score is 0.7303509041007377\n",
      "after 200 epochs, train loss is 0.07015153765678406, train auc_score is 0.7262956578168134\n",
      "after 200 epochs, test loss is 0.071194589138031, test auc_score is 0.7317283085343054\n",
      "after 210 epochs, train loss is 0.07014138251543045, train auc_score is 0.7277356091890079\n",
      "after 210 epochs, test loss is 0.07119905203580856, test auc_score is 0.7318916012696965\n",
      "after 220 epochs, train loss is 0.07015117257833481, train auc_score is 0.7265793959353198\n",
      "after 220 epochs, test loss is 0.07126280665397644, test auc_score is 0.7320649278315474\n",
      "after 230 epochs, train loss is 0.07014019042253494, train auc_score is 0.7280906757210279\n",
      "after 230 epochs, test loss is 0.07137564569711685, test auc_score is 0.7311102809141102\n",
      "after 240 epochs, train loss is 0.07013089209794998, train auc_score is 0.7277524312525558\n",
      "after 240 epochs, test loss is 0.07133442908525467, test auc_score is 0.7314029695015924\n",
      "after 250 epochs, train loss is 0.07013313472270966, train auc_score is 0.7275491424653545\n",
      "after 250 epochs, test loss is 0.07115531712770462, test auc_score is 0.7339090921611946\n",
      "after 260 epochs, train loss is 0.07018814980983734, train auc_score is 0.7271819559498557\n",
      "after 260 epochs, test loss is 0.0712454691529274, test auc_score is 0.7281862898917051\n",
      "after 270 epochs, train loss is 0.0701550617814064, train auc_score is 0.7280447018489256\n",
      "after 270 epochs, test loss is 0.07131890952587128, test auc_score is 0.7324845879490753\n",
      "after 280 epochs, train loss is 0.07012005150318146, train auc_score is 0.7273515427549431\n",
      "after 280 epochs, test loss is 0.07126259058713913, test auc_score is 0.7324000264743445\n",
      "after 290 epochs, train loss is 0.07022205740213394, train auc_score is 0.7272768503440894\n",
      "after 290 epochs, test loss is 0.07131990045309067, test auc_score is 0.7329215268143418\n",
      "after 300 epochs, train loss is 0.07018405199050903, train auc_score is 0.7272642442795602\n",
      "after 300 epochs, test loss is 0.0713702142238617, test auc_score is 0.7303952430189652\n",
      "after 310 epochs, train loss is 0.0701533854007721, train auc_score is 0.7277514670022525\n",
      "after 310 epochs, test loss is 0.07129914313554764, test auc_score is 0.7321667275447794\n",
      "after 320 epochs, train loss is 0.07008983939886093, train auc_score is 0.7273584930711292\n",
      "after 320 epochs, test loss is 0.07151232659816742, test auc_score is 0.731361790303871\n",
      "after 330 epochs, train loss is 0.07010401785373688, train auc_score is 0.7272811028362733\n",
      "after 330 epochs, test loss is 0.0713062733411789, test auc_score is 0.7315592821837945\n",
      "after 340 epochs, train loss is 0.07020001113414764, train auc_score is 0.7279750578570703\n",
      "after 340 epochs, test loss is 0.07120529562234879, test auc_score is 0.7303630786845815\n",
      "after 350 epochs, train loss is 0.07016780972480774, train auc_score is 0.727839407915581\n",
      "after 350 epochs, test loss is 0.07128497958183289, test auc_score is 0.7326720678152053\n",
      "after 360 epochs, train loss is 0.07013344019651413, train auc_score is 0.7275045404000173\n",
      "after 360 epochs, test loss is 0.07126712054014206, test auc_score is 0.7305530763556121\n",
      "after 370 epochs, train loss is 0.07018690556287766, train auc_score is 0.7272398408350892\n",
      "after 370 epochs, test loss is 0.07127603143453598, test auc_score is 0.7319787491034215\n",
      "after 380 epochs, train loss is 0.07024524360895157, train auc_score is 0.7280001554628622\n",
      "after 380 epochs, test loss is 0.07143697887659073, test auc_score is 0.7292789143873417\n",
      "after 390 epochs, train loss is 0.07015718519687653, train auc_score is 0.7279182402733007\n",
      "after 390 epochs, test loss is 0.07148291915655136, test auc_score is 0.7322734849654328\n",
      "after 400 epochs, train loss is 0.0701451227068901, train auc_score is 0.7271553759699309\n",
      "after 400 epochs, test loss is 0.07125595957040787, test auc_score is 0.727143311024377\n",
      "after 410 epochs, train loss is 0.07014688104391098, train auc_score is 0.7276859077724769\n",
      "after 410 epochs, test loss is 0.07131089270114899, test auc_score is 0.7302786013444205\n",
      "after 420 epochs, train loss is 0.07015889137983322, train auc_score is 0.7266489341068855\n",
      "after 420 epochs, test loss is 0.0712800920009613, test auc_score is 0.7277909010394856\n",
      "after 430 epochs, train loss is 0.0701596811413765, train auc_score is 0.7265163046918335\n",
      "after 430 epochs, test loss is 0.07128067314624786, test auc_score is 0.7304396037498591\n",
      "after 440 epochs, train loss is 0.07022033631801605, train auc_score is 0.7271411230647808\n",
      "after 440 epochs, test loss is 0.07148865610361099, test auc_score is 0.7325467228868403\n",
      "after 450 epochs, train loss is 0.07017683982849121, train auc_score is 0.7270293170058943\n",
      "after 450 epochs, test loss is 0.07122935354709625, test auc_score is 0.7302636503197768\n",
      "after 460 epochs, train loss is 0.07014591246843338, train auc_score is 0.7271411711289499\n",
      "after 460 epochs, test loss is 0.07138239592313766, test auc_score is 0.7312542226984724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 470 epochs, train loss is 0.07022029161453247, train auc_score is 0.7275410033027174\n",
      "after 470 epochs, test loss is 0.0714138001203537, test auc_score is 0.7323671423219758\n",
      "after 480 epochs, train loss is 0.07014185190200806, train auc_score is 0.7267700769767347\n",
      "after 480 epochs, test loss is 0.07137764990329742, test auc_score is 0.7295683965128901\n",
      "after 490 epochs, train loss is 0.07014551013708115, train auc_score is 0.7276969281150203\n",
      "after 490 epochs, test loss is 0.07134006917476654, test auc_score is 0.7325647121042785\n",
      "after 500 epochs, train loss is 0.07016048580408096, train auc_score is 0.7260029862901121\n",
      "after 500 epochs, test loss is 0.07139886915683746, test auc_score is 0.7310364263423966\n",
      "model saved in E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, path)\n",
    "    for epoch  in range(1, 500+1):\n",
    "        _ = sess.run(train_op, feed_dict = {X_nn:X_tr, y_nn:y_tr.reshape((y_tr.shape[0], 1))})\n",
    "        if epoch%10 == 0:\n",
    "            loss = sess.run(loss_op, feed_dict={X_nn:X_tr, y_nn:y_tr.reshape((y_tr.shape[0], 1))})\n",
    "            preds = sess.run(out, feed_dict={X_nn:X_tr})\n",
    "            print('after {} epochs, train loss is {}, train auc_score is {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op, feed_dict={X_nn:X_ts, y_nn:y_ts.reshape((y_ts.shape[0], 1))})\n",
    "            preds = sess.run(out, feed_dict={X_nn:X_ts})\n",
    "            print('after {} epochs, test loss is {}, test auc_score is {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path = saver.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt')\n",
    "    print('model saved in {}'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs = pd.read_csv('train_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = pd.read_csv('test_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_probs = pd.read_csv('submission_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>best_rf</th>\n",
       "      <th>simple_xgbc</th>\n",
       "      <th>xgbc_selec_cv</th>\n",
       "      <th>xgbc_less_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>0.277769</td>\n",
       "      <td>0.314071</td>\n",
       "      <td>0.259294</td>\n",
       "      <td>0.380187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.040991</td>\n",
       "      <td>0.034275</td>\n",
       "      <td>0.015042</td>\n",
       "      <td>0.033700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0.060233</td>\n",
       "      <td>0.036301</td>\n",
       "      <td>0.020286</td>\n",
       "      <td>0.024342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0.053465</td>\n",
       "      <td>0.037015</td>\n",
       "      <td>0.022415</td>\n",
       "      <td>0.038694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0.061021</td>\n",
       "      <td>0.091228</td>\n",
       "      <td>0.060749</td>\n",
       "      <td>0.053903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   best_rf  simple_xgbc  xgbc_selec_cv  xgbc_less_cv\n",
       "0      100002  0.277769     0.314071       0.259294      0.380187\n",
       "1      100003  0.040991     0.034275       0.015042      0.033700\n",
       "2      100004  0.060233     0.036301       0.020286      0.024342\n",
       "3      100006  0.053465     0.037015       0.022415      0.038694\n",
       "4      100007  0.061021     0.091228       0.060749      0.053903"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>best_rf</th>\n",
       "      <th>simple_xgbc</th>\n",
       "      <th>xgbc_selec_cv</th>\n",
       "      <th>xgbc_less_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>402543</td>\n",
       "      <td>0.069787</td>\n",
       "      <td>0.087951</td>\n",
       "      <td>0.033092</td>\n",
       "      <td>0.075479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>402544</td>\n",
       "      <td>0.114269</td>\n",
       "      <td>0.192056</td>\n",
       "      <td>0.199578</td>\n",
       "      <td>0.183206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>402545</td>\n",
       "      <td>0.053718</td>\n",
       "      <td>0.030099</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>0.019314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>402546</td>\n",
       "      <td>0.061051</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.068520</td>\n",
       "      <td>0.073169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>402547</td>\n",
       "      <td>0.068829</td>\n",
       "      <td>0.046952</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>0.013551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   best_rf  simple_xgbc  xgbc_selec_cv  xgbc_less_cv\n",
       "0      402543  0.069787     0.087951       0.033092      0.075479\n",
       "1      402544  0.114269     0.192056       0.199578      0.183206\n",
       "2      402545  0.053718     0.030099       0.014147      0.019314\n",
       "3      402546  0.061051     0.073467       0.068520      0.073169\n",
       "4      402547  0.068829     0.046952       0.014268      0.013551"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>best_rf</th>\n",
       "      <th>simple_xgbc</th>\n",
       "      <th>xgbc_selec_cv</th>\n",
       "      <th>xgbc_less_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.097825</td>\n",
       "      <td>0.072495</td>\n",
       "      <td>0.028976</td>\n",
       "      <td>0.065394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.109181</td>\n",
       "      <td>0.118270</td>\n",
       "      <td>0.150033</td>\n",
       "      <td>0.060899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.044355</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.026344</td>\n",
       "      <td>0.058784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.054787</td>\n",
       "      <td>0.033205</td>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.079806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.095779</td>\n",
       "      <td>0.080791</td>\n",
       "      <td>0.077277</td>\n",
       "      <td>0.087801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   best_rf  simple_xgbc  xgbc_selec_cv  xgbc_less_cv\n",
       "0      100001  0.097825     0.072495       0.028976      0.065394\n",
       "1      100005  0.109181     0.118270       0.150033      0.060899\n",
       "2      100013  0.044355     0.041420       0.026344      0.058784\n",
       "3      100028  0.054787     0.033205       0.034920      0.079806\n",
       "4      100038  0.095779     0.080791       0.077277      0.087801"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts = X[:261385, :], X[261385:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt')\n",
    "    preds = sess.run(out, feed_dict={X_nn:X_tr})\n",
    "    train_probs['nn_selec'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt')\n",
    "    preds = sess.run(out, feed_dict={X_nn:X_ts})\n",
    "    test_probs['nn_selec'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'E:/kaggle/home-credit-default-risk/dnn/neural_network_selec.ckpt')\n",
    "    preds = sess.run(out, feed_dict={X_nn:X_sub})\n",
    "    submission_probs['nn_selec'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs.to_csv('train_probs.csv', index=False)\n",
    "test_probs.to_csv('test_probs.csv', index=False)\n",
    "submission_probs.to_csv('submission_probs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.062552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.120657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.032278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.034720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.110403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      100001  0.062552\n",
       "1      100005  0.120657\n",
       "2      100013  0.032278\n",
       "3      100028  0.034720\n",
       "4      100038  0.110403"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100057</td>\n",
       "      <td>-0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100066</td>\n",
       "      <td>-0.001413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100169</td>\n",
       "      <td>-0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100271</td>\n",
       "      <td>-0.016062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>100280</td>\n",
       "      <td>-0.028391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>100312</td>\n",
       "      <td>-0.037546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>100484</td>\n",
       "      <td>-0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>100517</td>\n",
       "      <td>-0.019968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>100553</td>\n",
       "      <td>-0.001901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>100792</td>\n",
       "      <td>-0.084665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>100931</td>\n",
       "      <td>-0.004587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>101099</td>\n",
       "      <td>-0.012155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>101126</td>\n",
       "      <td>-0.019968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>101292</td>\n",
       "      <td>-0.045358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>101345</td>\n",
       "      <td>-0.008249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>101346</td>\n",
       "      <td>-0.004709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>101353</td>\n",
       "      <td>-0.033640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>101368</td>\n",
       "      <td>-0.043405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>101665</td>\n",
       "      <td>-0.065378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>101789</td>\n",
       "      <td>-0.010256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>101827</td>\n",
       "      <td>-0.003732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>101870</td>\n",
       "      <td>-0.082468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>101880</td>\n",
       "      <td>-0.017038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>101962</td>\n",
       "      <td>-0.020944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>101971</td>\n",
       "      <td>-0.004343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>102017</td>\n",
       "      <td>-0.011179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>102029</td>\n",
       "      <td>-0.029978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>102052</td>\n",
       "      <td>-0.029733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>102174</td>\n",
       "      <td>-0.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>102206</td>\n",
       "      <td>-0.016062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48425</th>\n",
       "      <td>453774</td>\n",
       "      <td>-0.019968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48430</th>\n",
       "      <td>453814</td>\n",
       "      <td>-0.049265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48432</th>\n",
       "      <td>453837</td>\n",
       "      <td>-0.012155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48435</th>\n",
       "      <td>453871</td>\n",
       "      <td>-0.027780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48446</th>\n",
       "      <td>453940</td>\n",
       "      <td>-0.006296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48480</th>\n",
       "      <td>454173</td>\n",
       "      <td>-0.043405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48481</th>\n",
       "      <td>454181</td>\n",
       "      <td>-0.008249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48487</th>\n",
       "      <td>454209</td>\n",
       "      <td>-0.028269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48493</th>\n",
       "      <td>454242</td>\n",
       "      <td>-0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48547</th>\n",
       "      <td>454638</td>\n",
       "      <td>-0.008493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48560</th>\n",
       "      <td>454707</td>\n",
       "      <td>-0.059030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48561</th>\n",
       "      <td>454714</td>\n",
       "      <td>-0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48572</th>\n",
       "      <td>454789</td>\n",
       "      <td>-0.015085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48577</th>\n",
       "      <td>454841</td>\n",
       "      <td>-0.012155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48580</th>\n",
       "      <td>454884</td>\n",
       "      <td>-0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48603</th>\n",
       "      <td>455069</td>\n",
       "      <td>-0.031687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48609</th>\n",
       "      <td>455132</td>\n",
       "      <td>-0.015573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48617</th>\n",
       "      <td>455174</td>\n",
       "      <td>-0.047312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48629</th>\n",
       "      <td>455246</td>\n",
       "      <td>-0.052194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48637</th>\n",
       "      <td>455322</td>\n",
       "      <td>-0.031931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48644</th>\n",
       "      <td>455378</td>\n",
       "      <td>-0.005686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48648</th>\n",
       "      <td>455425</td>\n",
       "      <td>-0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48649</th>\n",
       "      <td>455429</td>\n",
       "      <td>-0.010446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48656</th>\n",
       "      <td>455481</td>\n",
       "      <td>-0.010690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48657</th>\n",
       "      <td>455482</td>\n",
       "      <td>-0.031687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48679</th>\n",
       "      <td>455694</td>\n",
       "      <td>-0.018015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48695</th>\n",
       "      <td>455829</td>\n",
       "      <td>-0.050730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48702</th>\n",
       "      <td>455897</td>\n",
       "      <td>-0.023874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48704</th>\n",
       "      <td>455907</td>\n",
       "      <td>-0.012644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48715</th>\n",
       "      <td>455965</td>\n",
       "      <td>-0.024851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4443 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR    TARGET\n",
       "6          100057 -0.000253\n",
       "8          100066 -0.001413\n",
       "22         100169 -0.000437\n",
       "36         100271 -0.016062\n",
       "38         100280 -0.028391\n",
       "41         100312 -0.037546\n",
       "64         100484 -0.000437\n",
       "68         100517 -0.019968\n",
       "72         100553 -0.001901\n",
       "106        100792 -0.084665\n",
       "116        100931 -0.004587\n",
       "147        101099 -0.012155\n",
       "151        101126 -0.019968\n",
       "181        101292 -0.045358\n",
       "195        101345 -0.008249\n",
       "196        101346 -0.004709\n",
       "197        101353 -0.033640\n",
       "206        101368 -0.043405\n",
       "244        101665 -0.065378\n",
       "266        101789 -0.010256\n",
       "269        101827 -0.003732\n",
       "272        101870 -0.082468\n",
       "276        101880 -0.017038\n",
       "285        101962 -0.020944\n",
       "286        101971 -0.004343\n",
       "291        102017 -0.011179\n",
       "293        102029 -0.029978\n",
       "295        102052 -0.029733\n",
       "319        102174 -0.000681\n",
       "323        102206 -0.016062\n",
       "...           ...       ...\n",
       "48425      453774 -0.019968\n",
       "48430      453814 -0.049265\n",
       "48432      453837 -0.012155\n",
       "48435      453871 -0.027780\n",
       "48446      453940 -0.006296\n",
       "48480      454173 -0.043405\n",
       "48481      454181 -0.008249\n",
       "48487      454209 -0.028269\n",
       "48493      454242 -0.009500\n",
       "48547      454638 -0.008493\n",
       "48560      454707 -0.059030\n",
       "48561      454714 -0.000437\n",
       "48572      454789 -0.015085\n",
       "48577      454841 -0.012155\n",
       "48580      454884 -0.000925\n",
       "48603      455069 -0.031687\n",
       "48609      455132 -0.015573\n",
       "48617      455174 -0.047312\n",
       "48629      455246 -0.052194\n",
       "48637      455322 -0.031931\n",
       "48644      455378 -0.005686\n",
       "48648      455425 -0.001169\n",
       "48649      455429 -0.010446\n",
       "48656      455481 -0.010690\n",
       "48657      455482 -0.031687\n",
       "48679      455694 -0.018015\n",
       "48695      455829 -0.050730\n",
       "48702      455897 -0.023874\n",
       "48704      455907 -0.012644\n",
       "48715      455965 -0.024851\n",
       "\n",
       "[4443 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission['TARGET']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in submission[submission['TARGET']<0].index:\n",
    "    submission.loc[i, 'TARGET'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['TARGET'].replace(2.194876, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SK_ID_CURR, TARGET]\n",
       "Index: []"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission['TARGET']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SK_ID_CURR, TARGET]\n",
       "Index: []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission['TARGET']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_neural_network_selec.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = app.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_sub = X1[y.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X1[:y.shape[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler1 = StandardScaler()\n",
    "scaler1.fit(app.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = scaler1.transform(X1)\n",
    "X1_sub = scaler1.transform(X1_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_tr, X1_ts, y_tr, y_ts = train_test_split(X1, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hid_layer1 = 512\n",
    "num_hid_layer2 = 1024\n",
    "num_hid_layer3 = 256\n",
    "n_out = 1\n",
    "n_in = X1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0008\n",
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    X1_nn = tf.placeholder('float', [None, n_in])\n",
    "    y1_nn = tf.placeholder('float', [None, n_out])\n",
    "    weights1 = {'layer1':tf.Variable(tf.random_normal([n_in, num_hid_layer1])),\n",
    "                'layer2':tf.Variable(tf.random_normal([num_hid_layer1, num_hid_layer2])),\n",
    "                'layer3':tf.Variable(tf.random_normal([num_hid_layer2, num_hid_layer3])),\n",
    "                'out':tf.Variable(tf.random_normal([num_hid_layer3, n_out]))\n",
    "        \n",
    "    }\n",
    "    biases1 = {'layer1':tf.Variable(tf.random_normal([num_hid_layer1])),\n",
    "               'layer2':tf.Variable(tf.random_normal([num_hid_layer2])),\n",
    "               'layer3':tf.Variable(tf.random_normal([num_hid_layer3])),\n",
    "               'out':tf.Variable(tf.random_normal([n_out]))\n",
    "    }\n",
    "    h1 = tf.add(tf.matmul(X1_nn, weights1['layer1']), biases1['layer1'])\n",
    "    drop_con = tf.nn.dropout(h1, p1)*p1\n",
    "    h2 = tf.add(tf.matmul(drop_con, weights1['layer2']), biases1['layer2'])\n",
    "    h3 = tf.add(tf.matmul(h2, weights1['layer3']), biases1['layer3'])\n",
    "    s = tf.add(tf.matmul(h3, weights1['out']), biases1['out'])\n",
    "    loss_op1 = tf.losses.mean_squared_error(y1_nn, s)\n",
    "    optimizer1 = tf.train.AdamOptimizer(alpha)\n",
    "    train_op1 = optimizer1.minimize(loss_op1)\n",
    "    init_op1 = tf.global_variables_initializer()\n",
    "with tf.device('/device:CPU:0'):\n",
    "    saver1 = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 10 epochs, loss: 5744420352.0, auc_score: 0.5128429734184383\n",
      "Test:- after 10 epochs, loss: 6050484736.0, auc_score: 0.5113283810382534\n",
      "Training:- after 20 epochs, loss: 2348081152.0, auc_score: 0.4967961580633421\n",
      "Test:- after 20 epochs, loss: 2406549760.0, auc_score: 0.49772066391325065\n",
      "Training:- after 30 epochs, loss: 1629897600.0, auc_score: 0.49401870994900243\n",
      "Test:- after 30 epochs, loss: 1608770688.0, auc_score: 0.4998749779167938\n",
      "Training:- after 40 epochs, loss: 1294450816.0, auc_score: 0.4935843330264938\n",
      "Test:- after 40 epochs, loss: 1303357568.0, auc_score: 0.49135401212371355\n",
      "Training:- after 50 epochs, loss: 1045550720.0, auc_score: 0.49513846560904334\n",
      "Test:- after 50 epochs, loss: 1030818944.0, auc_score: 0.4994326936125184\n",
      "Training:- after 60 epochs, loss: 800469696.0, auc_score: 0.5019441944551677\n",
      "Test:- after 60 epochs, loss: 773733184.0, auc_score: 0.5059915282924624\n",
      "Training:- after 70 epochs, loss: 681014272.0, auc_score: 0.5015406552687284\n",
      "Test:- after 70 epochs, loss: 790802112.0, auc_score: 0.5047905561746833\n",
      "Training:- after 80 epochs, loss: 529016032.0, auc_score: 0.5039857364195407\n",
      "Test:- after 80 epochs, loss: 523204672.0, auc_score: 0.4970516574200788\n",
      "Training:- after 90 epochs, loss: 436863488.0, auc_score: 0.5055839986024396\n",
      "Test:- after 90 epochs, loss: 511035616.0, auc_score: 0.5017573792257097\n",
      "Training:- after 100 epochs, loss: 361548736.0, auc_score: 0.4996170441359866\n",
      "Test:- after 100 epochs, loss: 379130912.0, auc_score: 0.5011508265266851\n",
      "Training:- after 110 epochs, loss: 273851744.0, auc_score: 0.5042028211689769\n",
      "Test:- after 110 epochs, loss: 275430336.0, auc_score: 0.49887863683070044\n",
      "Training:- after 120 epochs, loss: 219693984.0, auc_score: 0.5016447760218734\n",
      "Test:- after 120 epochs, loss: 241903648.0, auc_score: 0.49420407354323703\n",
      "Training:- after 130 epochs, loss: 179006960.0, auc_score: 0.4997572857692692\n",
      "Test:- after 130 epochs, loss: 180184096.0, auc_score: 0.49448366057739046\n",
      "Training:- after 140 epochs, loss: 146504544.0, auc_score: 0.5009822385189778\n",
      "Test:- after 140 epochs, loss: 149836624.0, auc_score: 0.49837573383128614\n",
      "Training:- after 150 epochs, loss: 113471168.0, auc_score: 0.5001148856949877\n",
      "Test:- after 150 epochs, loss: 131633056.0, auc_score: 0.5013063074369293\n",
      "Training:- after 160 epochs, loss: 89560664.0, auc_score: 0.49948967577524683\n",
      "Test:- after 160 epochs, loss: 86870472.0, auc_score: 0.5022738784959384\n",
      "Training:- after 170 epochs, loss: 67020236.0, auc_score: 0.5012472879889189\n",
      "Test:- after 170 epochs, loss: 66885292.0, auc_score: 0.5014896551366177\n",
      "Training:- after 180 epochs, loss: 52885100.0, auc_score: 0.4945579046863205\n",
      "Test:- after 180 epochs, loss: 57424664.0, auc_score: 0.4962780407422003\n",
      "Training:- after 190 epochs, loss: 40519952.0, auc_score: 0.501309022387107\n",
      "Test:- after 190 epochs, loss: 40270420.0, auc_score: 0.5035229448376363\n",
      "Training:- after 200 epochs, loss: 30889494.0, auc_score: 0.5029040318126489\n",
      "Test:- after 200 epochs, loss: 32861680.0, auc_score: 0.5081328789276223\n",
      "Training:- after 210 epochs, loss: 23519114.0, auc_score: 0.5075867590474324\n",
      "Test:- after 210 epochs, loss: 24652112.0, auc_score: 0.5056591082171943\n",
      "Training:- after 220 epochs, loss: 17929266.0, auc_score: 0.50398478995682\n",
      "Test:- after 220 epochs, loss: 18136148.0, auc_score: 0.5011359835334944\n",
      "Training:- after 230 epochs, loss: 13385946.0, auc_score: 0.4990525777108293\n",
      "Test:- after 230 epochs, loss: 13670062.0, auc_score: 0.49340563691274236\n",
      "Training:- after 240 epochs, loss: 10492295.0, auc_score: 0.5013486097547049\n",
      "Test:- after 240 epochs, loss: 9514396.0, auc_score: 0.4961297571093485\n",
      "Training:- after 250 epochs, loss: 7738205.5, auc_score: 0.4993372688688643\n",
      "Test:- after 250 epochs, loss: 9028046.0, auc_score: 0.5059058542940548\n",
      "Training:- after 260 epochs, loss: 5612501.0, auc_score: 0.5107480767737095\n",
      "Test:- after 260 epochs, loss: 5671791.0, auc_score: 0.5104798528837065\n",
      "Training:- after 270 epochs, loss: 4100057.75, auc_score: 0.4979321636162334\n",
      "Test:- after 270 epochs, loss: 3733487.5, auc_score: 0.49597024979469473\n",
      "Training:- after 280 epochs, loss: 2953124.0, auc_score: 0.5016538624581475\n",
      "Test:- after 280 epochs, loss: 2901936.5, auc_score: 0.49792597237316644\n",
      "Training:- after 290 epochs, loss: 2113372.25, auc_score: 0.5046383486275321\n",
      "Test:- after 290 epochs, loss: 2329863.5, auc_score: 0.4992428483265672\n",
      "Training:- after 300 epochs, loss: 1513047.125, auc_score: 0.5062224592958877\n",
      "Test:- after 300 epochs, loss: 1630182.125, auc_score: 0.49904505518546627\n",
      "Training:- after 310 epochs, loss: 1128524.25, auc_score: 0.5028844235291215\n",
      "Test:- after 310 epochs, loss: 1123706.25, auc_score: 0.5053027746073642\n",
      "Training:- after 320 epochs, loss: 822910.3125, auc_score: 0.5017892411157158\n",
      "Test:- after 320 epochs, loss: 856013.1875, auc_score: 0.49939921975279455\n",
      "Training:- after 330 epochs, loss: 607788.8125, auc_score: 0.49860300841113103\n",
      "Test:- after 330 epochs, loss: 620041.25, auc_score: 0.503187366611042\n",
      "Training:- after 340 epochs, loss: 431025.375, auc_score: 0.5022346396729757\n",
      "Test:- after 340 epochs, loss: 412772.4375, auc_score: 0.5013572258686801\n",
      "Training:- after 350 epochs, loss: 342929.03125, auc_score: 0.5057871593628319\n",
      "Test:- after 350 epochs, loss: 306168.34375, auc_score: 0.5071328581022699\n",
      "Training:- after 360 epochs, loss: 221749.484375, auc_score: 0.5000904401543064\n",
      "Test:- after 360 epochs, loss: 237765.203125, auc_score: 0.5102948163840642\n",
      "Training:- after 370 epochs, loss: 166356.90625, auc_score: 0.49518715330685\n",
      "Test:- after 370 epochs, loss: 180067.453125, auc_score: 0.5022368139485538\n",
      "Training:- after 380 epochs, loss: 119655.6171875, auc_score: 0.500639829492371\n",
      "Test:- after 380 epochs, loss: 120522.0390625, auc_score: 0.5070210156556145\n",
      "Training:- after 390 epochs, loss: 87034.953125, auc_score: 0.5025815859068683\n",
      "Test:- after 390 epochs, loss: 82986.3359375, auc_score: 0.5009932370018093\n",
      "Training:- after 400 epochs, loss: 64640.60546875, auc_score: 0.5043025765660578\n",
      "Test:- after 400 epochs, loss: 60325.9921875, auc_score: 0.4929864169724306\n",
      "Training:- after 410 epochs, loss: 48022.578125, auc_score: 0.5058021092366635\n",
      "Test:- after 410 epochs, loss: 46882.54296875, auc_score: 0.508075128966115\n",
      "Training:- after 420 epochs, loss: 33942.6015625, auc_score: 0.4979496056283964\n",
      "Test:- after 420 epochs, loss: 35985.1953125, auc_score: 0.4975152727625649\n",
      "Training:- after 430 epochs, loss: 27364.126953125, auc_score: 0.4976211430576215\n",
      "Test:- after 430 epochs, loss: 26904.494140625, auc_score: 0.5002161377703538\n",
      "Training:- after 440 epochs, loss: 22726.26171875, auc_score: 0.5007953133633469\n",
      "Test:- after 440 epochs, loss: 24785.5078125, auc_score: 0.5034068978833746\n",
      "Training:- after 450 epochs, loss: 17466.859375, auc_score: 0.5007079466262465\n",
      "Test:- after 450 epochs, loss: 17389.466796875, auc_score: 0.5011607017128554\n",
      "Training:- after 460 epochs, loss: 15427.8701171875, auc_score: 0.4988658988030215\n",
      "Test:- after 460 epochs, loss: 16983.7734375, auc_score: 0.5070344433644747\n",
      "Training:- after 470 epochs, loss: 13008.1064453125, auc_score: 0.4936345205794878\n",
      "Test:- after 470 epochs, loss: 11860.4697265625, auc_score: 0.4947118998238724\n",
      "Training:- after 480 epochs, loss: 11050.2353515625, auc_score: 0.5009474148002413\n",
      "Test:- after 480 epochs, loss: 11684.1298828125, auc_score: 0.4952634981454941\n",
      "Training:- after 490 epochs, loss: 10200.125, auc_score: 0.5074346439136805\n",
      "Test:- after 490 epochs, loss: 10734.0576171875, auc_score: 0.5109592748848935\n",
      "Training:- after 500 epochs, loss: 9879.27734375, auc_score: 0.5013737202334851\n",
      "Test:- after 500 epochs, loss: 9721.5068359375, auc_score: 0.5062107319821296\n",
      "Training:- after 510 epochs, loss: 8978.064453125, auc_score: 0.5010820294884734\n",
      "Test:- after 510 epochs, loss: 8740.3916015625, auc_score: 0.5058465491099909\n",
      "Training:- after 520 epochs, loss: 8256.052734375, auc_score: 0.5091070962594969\n",
      "Test:- after 520 epochs, loss: 8643.689453125, auc_score: 0.5094767852215261\n",
      "Training:- after 530 epochs, loss: 7891.412109375, auc_score: 0.4985532965036918\n",
      "Test:- after 530 epochs, loss: 7905.7900390625, auc_score: 0.4946996774920037\n",
      "Training:- after 540 epochs, loss: 7782.3798828125, auc_score: 0.5031878703166575\n",
      "Test:- after 540 epochs, loss: 9015.2080078125, auc_score: 0.4957673425475192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 550 epochs, loss: 7488.0146484375, auc_score: 0.5020407977027457\n",
      "Test:- after 550 epochs, loss: 7325.060546875, auc_score: 0.49547476034084026\n",
      "Training:- after 560 epochs, loss: 7157.1884765625, auc_score: 0.498432134396106\n",
      "Test:- after 560 epochs, loss: 6935.5546875, auc_score: 0.4934693215271947\n",
      "Training:- after 570 epochs, loss: 7021.00732421875, auc_score: 0.5023353221206842\n",
      "Test:- after 570 epochs, loss: 7467.39208984375, auc_score: 0.5015395717378877\n",
      "Training:- after 580 epochs, loss: 6812.71923828125, auc_score: 0.4960323276664543\n",
      "Test:- after 580 epochs, loss: 6714.13232421875, auc_score: 0.4959671711537244\n",
      "Training:- after 590 epochs, loss: 6804.78857421875, auc_score: 0.5026971994075465\n",
      "Test:- after 590 epochs, loss: 6620.64697265625, auc_score: 0.5079720930864499\n",
      "Training:- after 600 epochs, loss: 6382.91650390625, auc_score: 0.506380225418095\n",
      "Test:- after 600 epochs, loss: 6725.77587890625, auc_score: 0.5107777622842131\n",
      "Training:- after 610 epochs, loss: 6121.48828125, auc_score: 0.5025393495275763\n",
      "Test:- after 610 epochs, loss: 6217.09716796875, auc_score: 0.4976128224276909\n",
      "Training:- after 620 epochs, loss: 6348.3876953125, auc_score: 0.49892244179652606\n",
      "Test:- after 620 epochs, loss: 6381.25390625, auc_score: 0.49898728614147353\n",
      "Training:- after 630 epochs, loss: 6304.6376953125, auc_score: 0.49750291513227823\n",
      "Test:- after 630 epochs, loss: 6075.36669921875, auc_score: 0.4963892025802115\n",
      "Training:- after 640 epochs, loss: 5960.59521484375, auc_score: 0.4966404317875464\n",
      "Test:- after 640 epochs, loss: 5935.92626953125, auc_score: 0.4922845090940955\n",
      "Training:- after 650 epochs, loss: 5983.49658203125, auc_score: 0.49261401126640647\n",
      "Test:- after 650 epochs, loss: 6032.216796875, auc_score: 0.4908042489011002\n",
      "Training:- after 660 epochs, loss: 5783.328125, auc_score: 0.5052446994523002\n",
      "Test:- after 660 epochs, loss: 5647.34130859375, auc_score: 0.501460048660592\n",
      "Training:- after 670 epochs, loss: 5540.86083984375, auc_score: 0.5008043649169763\n",
      "Test:- after 670 epochs, loss: 5364.923828125, auc_score: 0.5011430376922467\n",
      "Training:- after 680 epochs, loss: 5277.0615234375, auc_score: 0.5021645962090919\n",
      "Test:- after 680 epochs, loss: 5837.59423828125, auc_score: 0.5153923684026965\n",
      "Training:- after 690 epochs, loss: 5140.73876953125, auc_score: 0.4998130496185018\n",
      "Test:- after 690 epochs, loss: 5064.1298828125, auc_score: 0.5017661158235874\n",
      "Training:- after 700 epochs, loss: 4992.25146484375, auc_score: 0.4994993519647103\n",
      "Test:- after 700 epochs, loss: 4918.5517578125, auc_score: 0.5080992174234591\n",
      "Training:- after 710 epochs, loss: 4948.64306640625, auc_score: 0.49946843047087824\n",
      "Test:- after 710 epochs, loss: 5066.23388671875, auc_score: 0.4968378667954234\n",
      "Training:- after 720 epochs, loss: 4812.29833984375, auc_score: 0.49955777063941126\n",
      "Test:- after 720 epochs, loss: 4746.27685546875, auc_score: 0.49555437246973394\n",
      "Training:- after 730 epochs, loss: 4611.6748046875, auc_score: 0.4943582763356748\n",
      "Test:- after 730 epochs, loss: 4784.96240234375, auc_score: 0.4856417560043963\n",
      "Training:- after 740 epochs, loss: 4521.1640625, auc_score: 0.503977946849052\n",
      "Test:- after 740 epochs, loss: 4398.5244140625, auc_score: 0.5104908030498849\n",
      "Training:- after 750 epochs, loss: 4461.8798828125, auc_score: 0.5058593190404994\n",
      "Test:- after 750 epochs, loss: 4253.8349609375, auc_score: 0.5096859833280396\n",
      "Training:- after 760 epochs, loss: 4317.2841796875, auc_score: 0.5004579478350681\n",
      "Test:- after 760 epochs, loss: 4273.4609375, auc_score: 0.5015357902253734\n",
      "Training:- after 770 epochs, loss: 4040.030517578125, auc_score: 0.5005083553260936\n",
      "Test:- after 770 epochs, loss: 4341.29150390625, auc_score: 0.5051386175271126\n",
      "Training:- after 780 epochs, loss: 3972.62744140625, auc_score: 0.4970461453255107\n",
      "Test:- after 780 epochs, loss: 4060.88720703125, auc_score: 0.5082313890778444\n",
      "Training:- after 790 epochs, loss: 3981.1357421875, auc_score: 0.5076721452583252\n",
      "Test:- after 790 epochs, loss: 3903.200927734375, auc_score: 0.505864597960721\n",
      "Training:- after 800 epochs, loss: 3958.4375, auc_score: 0.506944625723889\n",
      "Test:- after 800 epochs, loss: 3795.22802734375, auc_score: 0.5044648372321884\n",
      "Training:- after 810 epochs, loss: 3835.168212890625, auc_score: 0.5010975492107084\n",
      "Test:- after 810 epochs, loss: 3582.545654296875, auc_score: 0.5017388851169884\n",
      "Training:- after 820 epochs, loss: 3660.1904296875, auc_score: 0.4960997882380071\n",
      "Test:- after 820 epochs, loss: 4018.865234375, auc_score: 0.5021617720749021\n",
      "Training:- after 830 epochs, loss: 3591.591796875, auc_score: 0.5066375266051977\n",
      "Test:- after 830 epochs, loss: 3468.465087890625, auc_score: 0.512796603363405\n",
      "Training:- after 840 epochs, loss: 3390.2060546875, auc_score: 0.49458550247504335\n",
      "Test:- after 840 epochs, loss: 3414.520751953125, auc_score: 0.4862210430122655\n",
      "Training:- after 850 epochs, loss: 3624.676025390625, auc_score: 0.502191854926683\n",
      "Test:- after 850 epochs, loss: 3211.536865234375, auc_score: 0.5101841316081868\n",
      "Training:- after 860 epochs, loss: 3253.504150390625, auc_score: 0.5054403717759961\n",
      "Test:- after 860 epochs, loss: 3463.67919921875, auc_score: 0.5124866592754688\n",
      "Training:- after 870 epochs, loss: 3029.653076171875, auc_score: 0.4989650072945572\n",
      "Test:- after 870 epochs, loss: 3188.03662109375, auc_score: 0.49952233994829387\n",
      "Training:- after 880 epochs, loss: 2956.483642578125, auc_score: 0.5031232771182137\n",
      "Test:- after 880 epochs, loss: 3125.5546875, auc_score: 0.5092162584098262\n",
      "Training:- after 890 epochs, loss: 2897.541259765625, auc_score: 0.5010416299661911\n",
      "Test:- after 890 epochs, loss: 3025.843505859375, auc_score: 0.5018189234213883\n",
      "Training:- after 900 epochs, loss: 2875.822265625, auc_score: 0.49743986159859377\n",
      "Test:- after 900 epochs, loss: 2829.382568359375, auc_score: 0.5013802234439452\n",
      "Training:- after 910 epochs, loss: 2776.2080078125, auc_score: 0.5017913952668391\n",
      "Test:- after 910 epochs, loss: 2695.196044921875, auc_score: 0.4979657911592703\n",
      "Training:- after 920 epochs, loss: 2621.932373046875, auc_score: 0.5067858610120706\n",
      "Test:- after 920 epochs, loss: 2841.362548828125, auc_score: 0.5094049460249994\n",
      "Training:- after 930 epochs, loss: 2511.865234375, auc_score: 0.5041105295739561\n",
      "Test:- after 930 epochs, loss: 2671.177490234375, auc_score: 0.5030620741926267\n",
      "Training:- after 940 epochs, loss: 2459.279052734375, auc_score: 0.5008332314879994\n",
      "Test:- after 940 epochs, loss: 2607.335693359375, auc_score: 0.5036730254045254\n",
      "Training:- after 950 epochs, loss: 2533.80615234375, auc_score: 0.5071083539207369\n",
      "Test:- after 950 epochs, loss: 2500.667724609375, auc_score: 0.5082204897982934\n",
      "Training:- after 960 epochs, loss: 2521.4072265625, auc_score: 0.508409986409692\n",
      "Test:- after 960 epochs, loss: 2901.44140625, auc_score: 0.5008910757360563\n",
      "Training:- after 970 epochs, loss: 2260.400634765625, auc_score: 0.5009075175289206\n",
      "Test:- after 970 epochs, loss: 2354.357666015625, auc_score: 0.5004589655768884\n",
      "Training:- after 980 epochs, loss: 2272.078369140625, auc_score: 0.5003251244790381\n",
      "Test:- after 980 epochs, loss: 2126.37939453125, auc_score: 0.5002626799521304\n",
      "Training:- after 990 epochs, loss: 2235.203369140625, auc_score: 0.5067434770220387\n",
      "Test:- after 990 epochs, loss: 2194.447509765625, auc_score: 0.5017833918336605\n",
      "Training:- after 1000 epochs, loss: 2196.502685546875, auc_score: 0.5040232311240671\n",
      "Test:- after 1000 epochs, loss: 2221.34814453125, auc_score: 0.4975843163749873\n",
      "Training:- after 1010 epochs, loss: 1942.8154296875, auc_score: 0.494572086649274\n",
      "Test:- after 1010 epochs, loss: 1957.272705078125, auc_score: 0.4915614800848886\n",
      "Training:- after 1020 epochs, loss: 1915.642333984375, auc_score: 0.4991703050603661\n",
      "Test:- after 1020 epochs, loss: 1932.7657470703125, auc_score: 0.502642517128407\n",
      "Training:- after 1030 epochs, loss: 1953.8284912109375, auc_score: 0.5086907073512268\n",
      "Test:- after 1030 epochs, loss: 1922.5174560546875, auc_score: 0.5006843710742955\n",
      "Training:- after 1040 epochs, loss: 1790.1964111328125, auc_score: 0.5009600774959143\n",
      "Test:- after 1040 epochs, loss: 1941.668701171875, auc_score: 0.5010241951538807\n",
      "Training:- after 1050 epochs, loss: 1705.4193115234375, auc_score: 0.49919310224827346\n",
      "Test:- after 1050 epochs, loss: 1592.9957275390625, auc_score: 0.5000880879328049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 1060 epochs, loss: 1663.053466796875, auc_score: 0.5017730865096379\n",
      "Test:- after 1060 epochs, loss: 1714.2431640625, auc_score: 0.5097056669116815\n",
      "Training:- after 1070 epochs, loss: 1602.9459228515625, auc_score: 0.5000230230382516\n",
      "Test:- after 1070 epochs, loss: 1619.689697265625, auc_score: 0.4956897468012443\n",
      "Training:- after 1080 epochs, loss: 1524.6817626953125, auc_score: 0.5115149416650782\n",
      "Test:- after 1080 epochs, loss: 1529.6363525390625, auc_score: 0.5155728537295821\n",
      "Training:- after 1090 epochs, loss: 1491.755859375, auc_score: 0.499414226191191\n",
      "Test:- after 1090 epochs, loss: 1528.7738037109375, auc_score: 0.506640339155302\n",
      "Training:- after 1100 epochs, loss: 1425.59765625, auc_score: 0.5082012968486397\n",
      "Test:- after 1100 epochs, loss: 1480.2100830078125, auc_score: 0.5076154827805822\n",
      "Training:- after 1110 epochs, loss: 1452.2637939453125, auc_score: 0.5111362330094138\n",
      "Test:- after 1110 epochs, loss: 1490.1734619140625, auc_score: 0.5031861548732222\n",
      "Training:- after 1120 epochs, loss: 1333.4427490234375, auc_score: 0.511061862718037\n",
      "Test:- after 1120 epochs, loss: 1320.7728271484375, auc_score: 0.5054817810416348\n",
      "Training:- after 1130 epochs, loss: 1350.3177490234375, auc_score: 0.501082622000742\n",
      "Test:- after 1130 epochs, loss: 1339.97802734375, auc_score: 0.4970115237729666\n",
      "Training:- after 1140 epochs, loss: 1240.1275634765625, auc_score: 0.4999522782755459\n",
      "Test:- after 1140 epochs, loss: 1306.8348388671875, auc_score: 0.5046031057406438\n",
      "Training:- after 1150 epochs, loss: 1170.4630126953125, auc_score: 0.5019143649654868\n",
      "Test:- after 1150 epochs, loss: 1217.1005859375, auc_score: 0.5070935418216138\n",
      "Training:- after 1160 epochs, loss: 1160.004638671875, auc_score: 0.5025033297479854\n",
      "Test:- after 1160 epochs, loss: 1223.5465087890625, auc_score: 0.5088928643501301\n",
      "Training:- after 1170 epochs, loss: 1167.576416015625, auc_score: 0.4971265351394998\n",
      "Test:- after 1170 epochs, loss: 1180.1044921875, auc_score: 0.49628357466295275\n",
      "Training:- after 1180 epochs, loss: 1039.12841796875, auc_score: 0.5011488018668309\n",
      "Test:- after 1180 epochs, loss: 1068.8377685546875, auc_score: 0.49666801359329393\n",
      "Training:- after 1190 epochs, loss: 1035.284912109375, auc_score: 0.5025863739932888\n",
      "Test:- after 1190 epochs, loss: 1037.9395751953125, auc_score: 0.49979927769739735\n",
      "Training:- after 1200 epochs, loss: 1008.4619140625, auc_score: 0.4991464907576013\n",
      "Test:- after 1200 epochs, loss: 1004.66259765625, auc_score: 0.5033370782498812\n",
      "Training:- after 1210 epochs, loss: 1019.1867065429688, auc_score: 0.5010505638647981\n",
      "Test:- after 1210 epochs, loss: 953.8678588867188, auc_score: 0.49978343605414\n",
      "Training:- after 1220 epochs, loss: 914.838623046875, auc_score: 0.5025676448706563\n",
      "Test:- after 1220 epochs, loss: 980.5401611328125, auc_score: 0.5040415272791825\n",
      "Training:- after 1230 epochs, loss: 926.468017578125, auc_score: 0.5014817155222036\n",
      "Test:- after 1230 epochs, loss: 876.6388549804688, auc_score: 0.4922876418021077\n",
      "Training:- after 1240 epochs, loss: 859.2188110351562, auc_score: 0.5029615818700792\n",
      "Test:- after 1240 epochs, loss: 902.3065185546875, auc_score: 0.5030258015683844\n",
      "Training:- after 1250 epochs, loss: 834.27685546875, auc_score: 0.5040202525009411\n",
      "Test:- after 1250 epochs, loss: 852.6784057617188, auc_score: 0.5010723307231844\n",
      "Training:- after 1260 epochs, loss: 780.9794921875, auc_score: 0.5031108190870978\n",
      "Test:- after 1260 epochs, loss: 840.1019897460938, auc_score: 0.5040473188134872\n",
      "Training:- after 1270 epochs, loss: 769.51318359375, auc_score: 0.49329112193027763\n",
      "Test:- after 1270 epochs, loss: 775.2640380859375, auc_score: 0.49865363842631427\n",
      "Training:- after 1280 epochs, loss: 748.4298095703125, auc_score: 0.5093305010741062\n",
      "Test:- after 1280 epochs, loss: 809.4183349609375, auc_score: 0.5039031474562291\n",
      "Training:- after 1290 epochs, loss: 719.19384765625, auc_score: 0.4978151682110059\n",
      "Test:- after 1290 epochs, loss: 701.14599609375, auc_score: 0.5041776076626509\n",
      "Training:- after 1300 epochs, loss: 689.2506103515625, auc_score: 0.5113671757270689\n",
      "Test:- after 1300 epochs, loss: 684.3801879882812, auc_score: 0.520137943978988\n",
      "Training:- after 1310 epochs, loss: 656.1142578125, auc_score: 0.5116018192568432\n",
      "Test:- after 1310 epochs, loss: 686.345703125, auc_score: 0.5084266855937782\n",
      "Training:- after 1320 epochs, loss: 625.0159912109375, auc_score: 0.5018791694608217\n",
      "Test:- after 1320 epochs, loss: 609.4057006835938, auc_score: 0.5034687251359191\n",
      "Training:- after 1330 epochs, loss: 577.3103637695312, auc_score: 0.5025766904134344\n",
      "Test:- after 1330 epochs, loss: 591.9172973632812, auc_score: 0.5020391543848505\n",
      "Training:- after 1340 epochs, loss: 571.2323608398438, auc_score: 0.49482476026924543\n",
      "Test:- after 1340 epochs, loss: 617.3308715820312, auc_score: 0.49799528950121225\n",
      "Training:- after 1350 epochs, loss: 540.3514404296875, auc_score: 0.5129358657044268\n",
      "Test:- after 1350 epochs, loss: 578.2774658203125, auc_score: 0.5194397921698533\n",
      "Training:- after 1360 epochs, loss: 518.2008056640625, auc_score: 0.4978510489527103\n",
      "Test:- after 1360 epochs, loss: 513.2406616210938, auc_score: 0.48639173266333624\n",
      "Training:- after 1370 epochs, loss: 513.2377319335938, auc_score: 0.4972657194541989\n",
      "Test:- after 1370 epochs, loss: 490.623291015625, auc_score: 0.499324772616603\n",
      "Training:- after 1380 epochs, loss: 485.63714599609375, auc_score: 0.5039550419585154\n",
      "Test:- after 1380 epochs, loss: 481.6166687011719, auc_score: 0.5045111885891114\n",
      "Training:- after 1390 epochs, loss: 440.5574951171875, auc_score: 0.5060713280695035\n",
      "Test:- after 1390 epochs, loss: 472.3036804199219, auc_score: 0.4962160258452164\n",
      "Training:- after 1400 epochs, loss: 437.89324951171875, auc_score: 0.505227839113166\n",
      "Test:- after 1400 epochs, loss: 424.0987243652344, auc_score: 0.5044042089958067\n",
      "Training:- after 1410 epochs, loss: 420.2042236328125, auc_score: 0.5016907314429155\n",
      "Test:- after 1410 epochs, loss: 410.2495422363281, auc_score: 0.4942413861629311\n",
      "Training:- after 1420 epochs, loss: 402.995361328125, auc_score: 0.5070280590979048\n",
      "Test:- after 1420 epochs, loss: 419.097412109375, auc_score: 0.523051241574558\n",
      "Training:- after 1430 epochs, loss: 380.7955322265625, auc_score: 0.5034513458304258\n",
      "Test:- after 1430 epochs, loss: 369.63519287109375, auc_score: 0.494630446235142\n",
      "Training:- after 1440 epochs, loss: 370.2040100097656, auc_score: 0.5119577893550341\n",
      "Test:- after 1440 epochs, loss: 396.26153564453125, auc_score: 0.5076509825641677\n",
      "Training:- after 1450 epochs, loss: 332.4719543457031, auc_score: 0.48807315076258284\n",
      "Test:- after 1450 epochs, loss: 340.3177185058594, auc_score: 0.48899658732648443\n",
      "Training:- after 1460 epochs, loss: 326.5167236328125, auc_score: 0.5065629907690657\n",
      "Test:- after 1460 epochs, loss: 336.852294921875, auc_score: 0.5018649789997884\n",
      "Training:- after 1470 epochs, loss: 324.1948547363281, auc_score: 0.4970649176080257\n",
      "Test:- after 1470 epochs, loss: 297.87982177734375, auc_score: 0.5003046264353512\n",
      "Training:- after 1480 epochs, loss: 295.1025695800781, auc_score: 0.5009799943036247\n",
      "Test:- after 1480 epochs, loss: 298.7176513671875, auc_score: 0.5015070392807744\n",
      "Training:- after 1490 epochs, loss: 268.5771179199219, auc_score: 0.5016811966562635\n",
      "Test:- after 1490 epochs, loss: 265.4215393066406, auc_score: 0.49965735807341083\n",
      "Training:- after 1500 epochs, loss: 263.6618957519531, auc_score: 0.5020990260995171\n",
      "Test:- after 1500 epochs, loss: 284.98138427734375, auc_score: 0.4998537899972232\n",
      "Training:- after 1510 epochs, loss: 251.7428436279297, auc_score: 0.502454745614189\n",
      "Test:- after 1510 epochs, loss: 252.76268005371094, auc_score: 0.5066264089409942\n",
      "Training:- after 1520 epochs, loss: 248.29579162597656, auc_score: 0.5018814396903504\n",
      "Test:- after 1520 epochs, loss: 269.87548828125, auc_score: 0.5065104096929459\n",
      "Training:- after 1530 epochs, loss: 219.2974395751953, auc_score: 0.5103246881799243\n",
      "Test:- after 1530 epochs, loss: 241.45108032226562, auc_score: 0.5109253939321488\n",
      "Training:- after 1540 epochs, loss: 224.47715759277344, auc_score: 0.5064699081066091\n",
      "Test:- after 1540 epochs, loss: 228.56874084472656, auc_score: 0.5082929618972509\n",
      "Training:- after 1550 epochs, loss: 210.98565673828125, auc_score: 0.4993381206360438\n",
      "Test:- after 1550 epochs, loss: 193.7982940673828, auc_score: 0.5048565656719345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 1560 epochs, loss: 206.4122772216797, auc_score: 0.497789312879367\n",
      "Test:- after 1560 epochs, loss: 217.33262634277344, auc_score: 0.4980576765066605\n",
      "Training:- after 1570 epochs, loss: 190.61170959472656, auc_score: 0.49739362169677326\n",
      "Test:- after 1570 epochs, loss: 202.6968994140625, auc_score: 0.5023525524026355\n",
      "Training:- after 1580 epochs, loss: 189.5396728515625, auc_score: 0.49675510335827666\n",
      "Test:- after 1580 epochs, loss: 181.0598907470703, auc_score: 0.4954818844687054\n",
      "Training:- after 1590 epochs, loss: 173.7119140625, auc_score: 0.5003347692347059\n",
      "Test:- after 1590 epochs, loss: 169.50814819335938, auc_score: 0.5065589300923707\n",
      "Training:- after 1600 epochs, loss: 160.33740234375, auc_score: 0.5105592953489757\n",
      "Test:- after 1600 epochs, loss: 174.5829315185547, auc_score: 0.5100691182885484\n",
      "Training:- after 1610 epochs, loss: 159.84669494628906, auc_score: 0.5106343825082645\n",
      "Test:- after 1610 epochs, loss: 153.7869415283203, auc_score: 0.5123382357043911\n",
      "Training:- after 1620 epochs, loss: 144.52780151367188, auc_score: 0.5059377147299615\n",
      "Test:- after 1620 epochs, loss: 160.8054656982422, auc_score: 0.5027365683378848\n",
      "Training:- after 1630 epochs, loss: 134.9122772216797, auc_score: 0.5050965001417718\n",
      "Test:- after 1630 epochs, loss: 138.20892333984375, auc_score: 0.49626710965850707\n",
      "Training:- after 1640 epochs, loss: 124.92253112792969, auc_score: 0.508838731460223\n",
      "Test:- after 1640 epochs, loss: 126.48628997802734, auc_score: 0.5092734963246434\n",
      "Training:- after 1650 epochs, loss: 129.21742248535156, auc_score: 0.5022127614555352\n",
      "Test:- after 1650 epochs, loss: 119.31974792480469, auc_score: 0.49385800313011285\n",
      "Training:- after 1660 epochs, loss: 118.36649322509766, auc_score: 0.5107815143507393\n",
      "Test:- after 1660 epochs, loss: 132.58946228027344, auc_score: 0.515404908775988\n",
      "Training:- after 1670 epochs, loss: 111.00112915039062, auc_score: 0.5045891867622487\n",
      "Test:- after 1670 epochs, loss: 111.46472930908203, auc_score: 0.5071516893348994\n",
      "Training:- after 1680 epochs, loss: 113.54714965820312, auc_score: 0.5007608225078142\n",
      "Test:- after 1680 epochs, loss: 114.64923095703125, auc_score: 0.4983832396088584\n",
      "Training:- after 1690 epochs, loss: 103.99111938476562, auc_score: 0.5114477334507379\n",
      "Test:- after 1690 epochs, loss: 98.51746368408203, auc_score: 0.5021954526615506\n",
      "Training:- after 1700 epochs, loss: 97.07079315185547, auc_score: 0.49358073607400055\n",
      "Test:- after 1700 epochs, loss: 92.80154418945312, auc_score: 0.4978562767758278\n",
      "Training:- after 1710 epochs, loss: 93.36126708984375, auc_score: 0.4989366518429649\n",
      "Test:- after 1710 epochs, loss: 93.00929260253906, auc_score: 0.5014922249113118\n",
      "Training:- after 1720 epochs, loss: 90.22785186767578, auc_score: 0.5091816667811965\n",
      "Test:- after 1720 epochs, loss: 85.984130859375, auc_score: 0.5054733783872509\n",
      "Training:- after 1730 epochs, loss: 82.37959289550781, auc_score: 0.5131844597301136\n",
      "Test:- after 1730 epochs, loss: 74.82543182373047, auc_score: 0.5044536771586708\n",
      "Training:- after 1740 epochs, loss: 74.49829864501953, auc_score: 0.5005301531360817\n",
      "Test:- after 1740 epochs, loss: 77.6578369140625, auc_score: 0.5000216109146626\n",
      "Training:- after 1750 epochs, loss: 72.25233459472656, auc_score: 0.5030665124129837\n",
      "Test:- after 1750 epochs, loss: 74.19955444335938, auc_score: 0.5065914943536262\n",
      "Training:- after 1760 epochs, loss: 67.53106689453125, auc_score: 0.4993533852419868\n",
      "Test:- after 1760 epochs, loss: 70.53681182861328, auc_score: 0.5057553221083455\n",
      "Training:- after 1770 epochs, loss: 63.78356170654297, auc_score: 0.5017747449133435\n",
      "Test:- after 1770 epochs, loss: 61.06132507324219, auc_score: 0.5103533487274712\n",
      "Training:- after 1780 epochs, loss: 59.9970703125, auc_score: 0.49994005713109124\n",
      "Test:- after 1780 epochs, loss: 57.69664001464844, auc_score: 0.5030043560352615\n",
      "Training:- after 1790 epochs, loss: 57.94818878173828, auc_score: 0.508754780069078\n",
      "Test:- after 1790 epochs, loss: 59.24586486816406, auc_score: 0.5040969968836901\n",
      "Training:- after 1800 epochs, loss: 57.97750473022461, auc_score: 0.5035793683885631\n",
      "Test:- after 1800 epochs, loss: 56.47028732299805, auc_score: 0.4994289947907741\n",
      "Training:- after 1810 epochs, loss: 51.28422164916992, auc_score: 0.5063534003686389\n",
      "Test:- after 1810 epochs, loss: 49.44999694824219, auc_score: 0.5136669332574682\n",
      "Training:- after 1820 epochs, loss: 50.81217956542969, auc_score: 0.49206240126370093\n",
      "Test:- after 1820 epochs, loss: 51.69810485839844, auc_score: 0.49988190167856283\n",
      "Training:- after 1830 epochs, loss: 46.756954193115234, auc_score: 0.5014506385345481\n",
      "Test:- after 1830 epochs, loss: 44.440242767333984, auc_score: 0.4970515111210244\n",
      "Training:- after 1840 epochs, loss: 44.03190612792969, auc_score: 0.5182947325057247\n",
      "Test:- after 1840 epochs, loss: 45.853782653808594, auc_score: 0.516712469296122\n",
      "Training:- after 1850 epochs, loss: 40.918701171875, auc_score: 0.5066385258845784\n",
      "Test:- after 1850 epochs, loss: 47.40882110595703, auc_score: 0.504796417678101\n",
      "Training:- after 1860 epochs, loss: 38.88408660888672, auc_score: 0.5098674297205141\n",
      "Test:- after 1860 epochs, loss: 41.87293243408203, auc_score: 0.5074536060573304\n",
      "Training:- after 1870 epochs, loss: 37.46015167236328, auc_score: 0.5120430697355299\n",
      "Test:- after 1870 epochs, loss: 40.752681732177734, auc_score: 0.5158502939841333\n",
      "Training:- after 1880 epochs, loss: 34.14503479003906, auc_score: 0.49767452907323445\n",
      "Test:- after 1880 epochs, loss: 33.97148132324219, auc_score: 0.49063930307812065\n",
      "Training:- after 1890 epochs, loss: 31.14170265197754, auc_score: 0.5078429499022147\n",
      "Test:- after 1890 epochs, loss: 34.30707550048828, auc_score: 0.49926588406680283\n",
      "Training:- after 1900 epochs, loss: 29.131267547607422, auc_score: 0.5053197983376758\n",
      "Test:- after 1900 epochs, loss: 30.889463424682617, auc_score: 0.4973310758922782\n",
      "Training:- after 1910 epochs, loss: 29.492258071899414, auc_score: 0.5163664881891548\n",
      "Test:- after 1910 epochs, loss: 31.55531120300293, auc_score: 0.5200912777610566\n",
      "Training:- after 1920 epochs, loss: 28.203031539916992, auc_score: 0.5027055266043344\n",
      "Test:- after 1920 epochs, loss: 27.657960891723633, auc_score: 0.5043483386591066\n",
      "Training:- after 1930 epochs, loss: 24.60127067565918, auc_score: 0.4942500768750919\n",
      "Test:- after 1930 epochs, loss: 24.792011260986328, auc_score: 0.49939381622902523\n",
      "Training:- after 1940 epochs, loss: 24.106781005859375, auc_score: 0.5168769742141982\n",
      "Test:- after 1940 epochs, loss: 29.001333236694336, auc_score: 0.5198526067559148\n",
      "Training:- after 1950 epochs, loss: 22.270544052124023, auc_score: 0.5009728038474872\n",
      "Test:- after 1950 epochs, loss: 23.709585189819336, auc_score: 0.5070133508573309\n",
      "Training:- after 1960 epochs, loss: 19.91891098022461, auc_score: 0.4952082416393171\n",
      "Test:- after 1960 epochs, loss: 20.481948852539062, auc_score: 0.49744883708980747\n",
      "Training:- after 1970 epochs, loss: 19.601787567138672, auc_score: 0.5129347153654573\n",
      "Test:- after 1970 epochs, loss: 18.67053985595703, auc_score: 0.5084728524866762\n",
      "Training:- after 1980 epochs, loss: 17.600873947143555, auc_score: 0.5027331137508946\n",
      "Test:- after 1980 epochs, loss: 18.03057861328125, auc_score: 0.49517203579319585\n",
      "Training:- after 1990 epochs, loss: 16.65558624267578, auc_score: 0.5027235018085622\n",
      "Test:- after 1990 epochs, loss: 16.9731388092041, auc_score: 0.495939399776707\n",
      "Training:- after 2000 epochs, loss: 16.03647232055664, auc_score: 0.5058842570768266\n",
      "Test:- after 2000 epochs, loss: 16.73525619506836, auc_score: 0.5069754689434904\n",
      "Training:- after 2010 epochs, loss: 14.514123916625977, auc_score: 0.5107493943325893\n",
      "Test:- after 2010 epochs, loss: 14.472966194152832, auc_score: 0.5048186360518806\n",
      "Training:- after 2020 epochs, loss: 13.878198623657227, auc_score: 0.5028965123363108\n",
      "Test:- after 2020 epochs, loss: 14.23361587524414, auc_score: 0.5031049461763871\n",
      "Training:- after 2030 epochs, loss: 13.540301322937012, auc_score: 0.5004328785453994\n",
      "Test:- after 2030 epochs, loss: 13.416977882385254, auc_score: 0.507460113184836\n",
      "Training:- after 2040 epochs, loss: 12.485783576965332, auc_score: 0.5038320953178872\n",
      "Test:- after 2040 epochs, loss: 12.657833099365234, auc_score: 0.5063732575098835\n",
      "Training:- after 2050 epochs, loss: 11.298807144165039, auc_score: 0.5184734854656983\n",
      "Test:- after 2050 epochs, loss: 11.376269340515137, auc_score: 0.5115648098513661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 2060 epochs, loss: 11.179093360900879, auc_score: 0.5022303805414627\n",
      "Test:- after 2060 epochs, loss: 10.316814422607422, auc_score: 0.5124675100014169\n",
      "Training:- after 2070 epochs, loss: 9.657938003540039, auc_score: 0.503963546229068\n",
      "Test:- after 2070 epochs, loss: 9.852012634277344, auc_score: 0.5024128562367662\n",
      "Training:- after 2080 epochs, loss: 9.78080940246582, auc_score: 0.5261958762176816\n",
      "Test:- after 2080 epochs, loss: 9.2726411819458, auc_score: 0.5241375120532928\n",
      "Training:- after 2090 epochs, loss: 9.079850196838379, auc_score: 0.5113518427353759\n",
      "Test:- after 2090 epochs, loss: 9.76613998413086, auc_score: 0.5142464556159901\n",
      "Training:- after 2100 epochs, loss: 8.110603332519531, auc_score: 0.5130881890501235\n",
      "Test:- after 2100 epochs, loss: 8.417129516601562, auc_score: 0.5150946371053864\n",
      "Training:- after 2110 epochs, loss: 7.6978936195373535, auc_score: 0.4965201061736657\n",
      "Test:- after 2110 epochs, loss: 7.613648414611816, auc_score: 0.5019915372230656\n",
      "Training:- after 2120 epochs, loss: 7.071837902069092, auc_score: 0.5100785881648012\n",
      "Test:- after 2120 epochs, loss: 6.6830573081970215, auc_score: 0.5170897586552843\n",
      "Training:- after 2130 epochs, loss: 6.293115615844727, auc_score: 0.5176064729938412\n",
      "Test:- after 2130 epochs, loss: 6.6958818435668945, auc_score: 0.5105197479997516\n",
      "Training:- after 2140 epochs, loss: 6.1738362312316895, auc_score: 0.5151926370359798\n",
      "Test:- after 2140 epochs, loss: 6.1842427253723145, auc_score: 0.525478800866289\n",
      "Training:- after 2150 epochs, loss: 5.535599708557129, auc_score: 0.509269555378429\n",
      "Test:- after 2150 epochs, loss: 5.930751800537109, auc_score: 0.5163735548150052\n",
      "Training:- after 2160 epochs, loss: 5.429533958435059, auc_score: 0.5182946462844982\n",
      "Test:- after 2160 epochs, loss: 5.8346757888793945, auc_score: 0.5141801407989732\n",
      "Training:- after 2170 epochs, loss: 4.785861015319824, auc_score: 0.5041820327878395\n",
      "Test:- after 2170 epochs, loss: 4.930354595184326, auc_score: 0.5017447370791633\n",
      "Training:- after 2180 epochs, loss: 4.625913619995117, auc_score: 0.5002926680502969\n",
      "Test:- after 2180 epochs, loss: 4.514764308929443, auc_score: 0.4838906390142966\n",
      "Training:- after 2190 epochs, loss: 4.331394672393799, auc_score: 0.5059946789757442\n",
      "Test:- after 2190 epochs, loss: 4.443145751953125, auc_score: 0.4999265864984317\n",
      "Training:- after 2200 epochs, loss: 3.7748401165008545, auc_score: 0.5171917487957435\n",
      "Test:- after 2200 epochs, loss: 3.8223764896392822, auc_score: 0.5139073089646349\n",
      "Training:- after 2210 epochs, loss: 3.707592725753784, auc_score: 0.5231152311110165\n",
      "Test:- after 2210 epochs, loss: 3.7583982944488525, auc_score: 0.5260578747864049\n",
      "Training:- after 2220 epochs, loss: 3.4683544635772705, auc_score: 0.5114317468528787\n",
      "Test:- after 2220 epochs, loss: 3.3928816318511963, auc_score: 0.5111461592052007\n",
      "Training:- after 2230 epochs, loss: 3.1261796951293945, auc_score: 0.5156034505348582\n",
      "Test:- after 2230 epochs, loss: 3.4895241260528564, auc_score: 0.5238550085792946\n",
      "Training:- after 2240 epochs, loss: 2.8891210556030273, auc_score: 0.5091715776166925\n",
      "Test:- after 2240 epochs, loss: 3.006620407104492, auc_score: 0.5050556882261816\n",
      "Training:- after 2250 epochs, loss: 2.8691346645355225, auc_score: 0.5189204967047789\n",
      "Test:- after 2250 epochs, loss: 2.849390745162964, auc_score: 0.5253141699043178\n",
      "Training:- after 2260 epochs, loss: 2.5258781909942627, auc_score: 0.5029350194258444\n",
      "Test:- after 2260 epochs, loss: 2.6119203567504883, auc_score: 0.506873638440817\n",
      "Training:- after 2270 epochs, loss: 2.3159334659576416, auc_score: 0.512084770163678\n",
      "Test:- after 2270 epochs, loss: 2.404503345489502, auc_score: 0.511610184821122\n",
      "Training:- after 2280 epochs, loss: 2.125413656234741, auc_score: 0.515850734589133\n",
      "Test:- after 2280 epochs, loss: 2.2773385047912598, auc_score: 0.514250176700634\n",
      "Training:- after 2290 epochs, loss: 2.0399272441864014, auc_score: 0.5337849857050183\n",
      "Test:- after 2290 epochs, loss: 2.135066509246826, auc_score: 0.5320586040172219\n",
      "Training:- after 2300 epochs, loss: 1.9659324884414673, auc_score: 0.5171640163048301\n",
      "Test:- after 2300 epochs, loss: 1.862699031829834, auc_score: 0.5204638823700646\n",
      "Training:- after 2310 epochs, loss: 1.7311426401138306, auc_score: 0.5229430880180759\n",
      "Test:- after 2310 epochs, loss: 1.7170908451080322, auc_score: 0.5244862508339524\n",
      "Training:- after 2320 epochs, loss: 1.5910441875457764, auc_score: 0.5213673253381411\n",
      "Test:- after 2320 epochs, loss: 1.5190743207931519, auc_score: 0.5190352816453346\n",
      "Training:- after 2330 epochs, loss: 1.4514750242233276, auc_score: 0.5206554858481519\n",
      "Test:- after 2330 epochs, loss: 1.531420350074768, auc_score: 0.5227947570693389\n",
      "Training:- after 2340 epochs, loss: 1.4107096195220947, auc_score: 0.5151377171693817\n",
      "Test:- after 2340 epochs, loss: 1.4608988761901855, auc_score: 0.5205355052984237\n",
      "Training:- after 2350 epochs, loss: 1.3361725807189941, auc_score: 0.5177011127623795\n",
      "Test:- after 2350 epochs, loss: 1.2421190738677979, auc_score: 0.516029697970182\n",
      "Training:- after 2360 epochs, loss: 1.2147778272628784, auc_score: 0.5254977344722377\n",
      "Test:- after 2360 epochs, loss: 1.1990399360656738, auc_score: 0.523958769593403\n",
      "Training:- after 2370 epochs, loss: 1.1344618797302246, auc_score: 0.5215459252677549\n",
      "Test:- after 2370 epochs, loss: 1.1473485231399536, auc_score: 0.5343675974666244\n",
      "Training:- after 2380 epochs, loss: 1.0318580865859985, auc_score: 0.5216559002943728\n",
      "Test:- after 2380 epochs, loss: 1.065218210220337, auc_score: 0.5130145094440683\n",
      "Training:- after 2390 epochs, loss: 0.9496545791625977, auc_score: 0.5285059008334279\n",
      "Test:- after 2390 epochs, loss: 0.935703694820404, auc_score: 0.5277044292980114\n",
      "Training:- after 2400 epochs, loss: 0.9137536883354187, auc_score: 0.516612345799458\n",
      "Test:- after 2400 epochs, loss: 0.8529541492462158, auc_score: 0.5164599157828857\n",
      "Training:- after 2410 epochs, loss: 0.814835786819458, auc_score: 0.5246435925138444\n",
      "Test:- after 2410 epochs, loss: 0.8369210958480835, auc_score: 0.5210340956561482\n",
      "Training:- after 2420 epochs, loss: 0.7932523488998413, auc_score: 0.5180487888712719\n",
      "Test:- after 2420 epochs, loss: 0.889201283454895, auc_score: 0.5216531887284644\n",
      "Training:- after 2430 epochs, loss: 0.7351990938186646, auc_score: 0.5310291515277425\n",
      "Test:- after 2430 epochs, loss: 0.7558804750442505, auc_score: 0.5332185615131485\n",
      "Training:- after 2440 epochs, loss: 0.6844229698181152, auc_score: 0.520671826692079\n",
      "Test:- after 2440 epochs, loss: 0.6607247591018677, auc_score: 0.5201958752241063\n",
      "Training:- after 2450 epochs, loss: 0.6217564940452576, auc_score: 0.5442431833648584\n",
      "Test:- after 2450 epochs, loss: 0.6287420392036438, auc_score: 0.5412785771508636\n",
      "Training:- after 2460 epochs, loss: 0.6097130179405212, auc_score: 0.531211293129726\n",
      "Test:- after 2460 epochs, loss: 0.5543915033340454, auc_score: 0.5429429706058612\n",
      "Training:- after 2470 epochs, loss: 0.5674039125442505, auc_score: 0.5333496973995108\n",
      "Test:- after 2470 epochs, loss: 0.5756095051765442, auc_score: 0.537437339637949\n",
      "Training:- after 2480 epochs, loss: 0.50385981798172, auc_score: 0.5232634121919142\n",
      "Test:- after 2480 epochs, loss: 0.5030413866043091, auc_score: 0.519166779051904\n",
      "Training:- after 2490 epochs, loss: 0.45749422907829285, auc_score: 0.5488596115019144\n",
      "Test:- after 2490 epochs, loss: 0.47382012009620667, auc_score: 0.5520922526725116\n",
      "Training:- after 2500 epochs, loss: 0.43927887082099915, auc_score: 0.5324200702846469\n",
      "Test:- after 2500 epochs, loss: 0.4764192998409271, auc_score: 0.5404884891077111\n",
      "Training:- after 2510 epochs, loss: 0.41068875789642334, auc_score: 0.5377547989855225\n",
      "Test:- after 2510 epochs, loss: 0.4215126037597656, auc_score: 0.5324367616294677\n",
      "Training:- after 2520 epochs, loss: 0.38371148705482483, auc_score: 0.5426537863006624\n",
      "Test:- after 2520 epochs, loss: 0.3685305714607239, auc_score: 0.5412803295591018\n",
      "Training:- after 2530 epochs, loss: 0.35682135820388794, auc_score: 0.5409894574724625\n",
      "Test:- after 2530 epochs, loss: 0.3710569143295288, auc_score: 0.5411611085514431\n",
      "Training:- after 2540 epochs, loss: 0.3391580879688263, auc_score: 0.5371122935804344\n",
      "Test:- after 2540 epochs, loss: 0.3444882929325104, auc_score: 0.5373858646337086\n",
      "Training:- after 2550 epochs, loss: 0.3148792088031769, auc_score: 0.5517345598602035\n",
      "Test:- after 2550 epochs, loss: 0.36362117528915405, auc_score: 0.5523904355886418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 2560 epochs, loss: 0.2971014380455017, auc_score: 0.5455494833290554\n",
      "Test:- after 2560 epochs, loss: 0.29461658000946045, auc_score: 0.5546406677048132\n",
      "Training:- after 2570 epochs, loss: 0.279206246137619, auc_score: 0.5471486126511468\n",
      "Test:- after 2570 epochs, loss: 0.2932046055793762, auc_score: 0.5382861731122617\n",
      "Training:- after 2580 epochs, loss: 0.26527124643325806, auc_score: 0.5525570746902471\n",
      "Test:- after 2580 epochs, loss: 0.27551308274269104, auc_score: 0.5562137864519519\n",
      "Training:- after 2590 epochs, loss: 0.24414238333702087, auc_score: 0.5555144887740441\n",
      "Test:- after 2590 epochs, loss: 0.24270936846733093, auc_score: 0.5553196861419671\n",
      "Training:- after 2600 epochs, loss: 0.22753281891345978, auc_score: 0.5606558880036601\n",
      "Test:- after 2600 epochs, loss: 0.2360028475522995, auc_score: 0.5557296478964684\n",
      "Training:- after 2610 epochs, loss: 0.21945121884346008, auc_score: 0.563445818093982\n",
      "Test:- after 2610 epochs, loss: 0.22430112957954407, auc_score: 0.5675524974756098\n",
      "Training:- after 2620 epochs, loss: 0.20802809298038483, auc_score: 0.5613622436265656\n",
      "Test:- after 2620 epochs, loss: 0.22663922607898712, auc_score: 0.5698499428409594\n",
      "Training:- after 2630 epochs, loss: 0.19738362729549408, auc_score: 0.5658894138747732\n",
      "Test:- after 2630 epochs, loss: 0.21027839183807373, auc_score: 0.5667842652390153\n",
      "Training:- after 2640 epochs, loss: 0.18542428314685822, auc_score: 0.5572432596425605\n",
      "Test:- after 2640 epochs, loss: 0.19340768456459045, auc_score: 0.5601993956882209\n",
      "Training:- after 2650 epochs, loss: 0.1806478649377823, auc_score: 0.5592595554405773\n",
      "Test:- after 2650 epochs, loss: 0.17434944212436676, auc_score: 0.5724045946655574\n",
      "Training:- after 2660 epochs, loss: 0.16939468681812286, auc_score: 0.5681697256704754\n",
      "Test:- after 2660 epochs, loss: 0.1695796698331833, auc_score: 0.5714636023282311\n",
      "Training:- after 2670 epochs, loss: 0.1568710058927536, auc_score: 0.5715133530069545\n",
      "Test:- after 2670 epochs, loss: 0.18188641965389252, auc_score: 0.5770494242604262\n",
      "Training:- after 2680 epochs, loss: 0.15719980001449585, auc_score: 0.5735824329471538\n",
      "Test:- after 2680 epochs, loss: 0.15750175714492798, auc_score: 0.5828592268644551\n",
      "Training:- after 2690 epochs, loss: 0.15072576701641083, auc_score: 0.5808088993060598\n",
      "Test:- after 2690 epochs, loss: 0.14645393192768097, auc_score: 0.5918224483380828\n",
      "Training:- after 2700 epochs, loss: 0.14659734070301056, auc_score: 0.5830175591932147\n",
      "Test:- after 2700 epochs, loss: 0.14953377842903137, auc_score: 0.5893646496678954\n",
      "Training:- after 2710 epochs, loss: 0.13572709262371063, auc_score: 0.5799341355952079\n",
      "Test:- after 2710 epochs, loss: 0.1420479267835617, auc_score: 0.5781851374587115\n",
      "Training:- after 2720 epochs, loss: 0.13538847863674164, auc_score: 0.5875629668567172\n",
      "Test:- after 2720 epochs, loss: 0.14049799740314484, auc_score: 0.5783918993679282\n",
      "Training:- after 2730 epochs, loss: 0.1355946809053421, auc_score: 0.584494622710728\n",
      "Test:- after 2730 epochs, loss: 0.14205524325370789, auc_score: 0.593305313290329\n",
      "Training:- after 2740 epochs, loss: 0.12553033232688904, auc_score: 0.5904078633238302\n",
      "Test:- after 2740 epochs, loss: 0.12649546563625336, auc_score: 0.5948893885644746\n",
      "Training:- after 2750 epochs, loss: 0.12379243224859238, auc_score: 0.5919486664003755\n",
      "Test:- after 2750 epochs, loss: 0.12000112980604172, auc_score: 0.5863031670323147\n",
      "Training:- after 2760 epochs, loss: 0.11866536736488342, auc_score: 0.5877366587785018\n",
      "Test:- after 2760 epochs, loss: 0.1184973269701004, auc_score: 0.5907864824711533\n",
      "Training:- after 2770 epochs, loss: 0.11845232546329498, auc_score: 0.6029983140833475\n",
      "Test:- after 2770 epochs, loss: 0.11335005611181259, auc_score: 0.5951690837327117\n",
      "Training:- after 2780 epochs, loss: 0.1137935221195221, auc_score: 0.5990868963209863\n",
      "Test:- after 2780 epochs, loss: 0.11874477565288544, auc_score: 0.609478785065991\n",
      "Training:- after 2790 epochs, loss: 0.11218341439962387, auc_score: 0.6029222489290036\n",
      "Test:- after 2790 epochs, loss: 0.11090103536844254, auc_score: 0.607091187679004\n",
      "Training:- after 2800 epochs, loss: 0.10778369754552841, auc_score: 0.6022145090366235\n",
      "Test:- after 2800 epochs, loss: 0.10727423429489136, auc_score: 0.608146026123948\n",
      "Training:- after 2810 epochs, loss: 0.10427477955818176, auc_score: 0.6115836795917846\n",
      "Test:- after 2810 epochs, loss: 0.10434675961732864, auc_score: 0.6032297545357572\n",
      "Training:- after 2820 epochs, loss: 0.1024184301495552, auc_score: 0.6096035811398159\n",
      "Test:- after 2820 epochs, loss: 0.10029937326908112, auc_score: 0.6123927219248203\n",
      "Training:- after 2830 epochs, loss: 0.10110197216272354, auc_score: 0.6141379145489843\n",
      "Test:- after 2830 epochs, loss: 0.10133112221956253, auc_score: 0.6142412422809915\n",
      "Training:- after 2840 epochs, loss: 0.10019998997449875, auc_score: 0.6193266586916597\n",
      "Test:- after 2840 epochs, loss: 0.09910903871059418, auc_score: 0.6259024059617349\n",
      "Training:- after 2850 epochs, loss: 0.09952294826507568, auc_score: 0.6173917532680138\n",
      "Test:- after 2850 epochs, loss: 0.10090070962905884, auc_score: 0.6144071803932093\n",
      "Training:- after 2860 epochs, loss: 0.09565993398427963, auc_score: 0.6187628711970747\n",
      "Test:- after 2860 epochs, loss: 0.0960216224193573, auc_score: 0.6197131481364561\n",
      "Training:- after 2870 epochs, loss: 0.0976952463388443, auc_score: 0.6221231986490144\n",
      "Test:- after 2870 epochs, loss: 0.09570921957492828, auc_score: 0.6252083091807376\n",
      "Training:- after 2880 epochs, loss: 0.0944635272026062, auc_score: 0.6227915858926099\n",
      "Test:- after 2880 epochs, loss: 0.0974237248301506, auc_score: 0.6228000518229415\n",
      "Training:- after 2890 epochs, loss: 0.09314753115177155, auc_score: 0.6271326374246354\n",
      "Test:- after 2890 epochs, loss: 0.09277132153511047, auc_score: 0.626608925440697\n",
      "Training:- after 2900 epochs, loss: 0.09279685467481613, auc_score: 0.6278392741780088\n",
      "Test:- after 2900 epochs, loss: 0.09301547706127167, auc_score: 0.627085637728964\n",
      "Training:- after 2910 epochs, loss: 0.09107855707406998, auc_score: 0.6299971164567157\n",
      "Test:- after 2910 epochs, loss: 0.08958929032087326, auc_score: 0.6313740955490319\n",
      "Training:- after 2920 epochs, loss: 0.09124868363142014, auc_score: 0.6364943642795995\n",
      "Test:- after 2920 epochs, loss: 0.09207600355148315, auc_score: 0.633689764687894\n",
      "Training:- after 2930 epochs, loss: 0.0898393765091896, auc_score: 0.6328731754429409\n",
      "Test:- after 2930 epochs, loss: 0.08913826197385788, auc_score: 0.6330079729295354\n",
      "Training:- after 2940 epochs, loss: 0.09020255506038666, auc_score: 0.6354690180049797\n",
      "Test:- after 2940 epochs, loss: 0.08986225724220276, auc_score: 0.6376823199488315\n",
      "Training:- after 2950 epochs, loss: 0.0889190286397934, auc_score: 0.6334819340570462\n",
      "Test:- after 2950 epochs, loss: 0.08741363137960434, auc_score: 0.6335659543425077\n",
      "Training:- after 2960 epochs, loss: 0.08797914534807205, auc_score: 0.6341900828843863\n",
      "Test:- after 2960 epochs, loss: 0.08696556836366653, auc_score: 0.639800679369555\n",
      "Training:- after 2970 epochs, loss: 0.08749975264072418, auc_score: 0.6381366312145118\n",
      "Test:- after 2970 epochs, loss: 0.08766654133796692, auc_score: 0.63295132339135\n",
      "Training:- after 2980 epochs, loss: 0.08650347590446472, auc_score: 0.6385452727267902\n",
      "Test:- after 2980 epochs, loss: 0.0861179381608963, auc_score: 0.6442113159825115\n",
      "Training:- after 2990 epochs, loss: 0.08641545474529266, auc_score: 0.6416521222871576\n",
      "Test:- after 2990 epochs, loss: 0.08642975986003876, auc_score: 0.6345397208484281\n",
      "Training:- after 3000 epochs, loss: 0.08644217997789383, auc_score: 0.6411511757786164\n",
      "Test:- after 3000 epochs, loss: 0.08562258630990982, auc_score: 0.6467581249056291\n",
      "Training:- after 3010 epochs, loss: 0.08602752536535263, auc_score: 0.642872432984569\n",
      "Test:- after 3010 epochs, loss: 0.08598269522190094, auc_score: 0.6381440429448535\n",
      "Training:- after 3020 epochs, loss: 0.08518177270889282, auc_score: 0.6430653751993483\n",
      "Test:- after 3020 epochs, loss: 0.0863434448838234, auc_score: 0.6433907373081786\n",
      "Training:- after 3030 epochs, loss: 0.08491866290569305, auc_score: 0.6432331454472955\n",
      "Test:- after 3030 epochs, loss: 0.0848805382847786, auc_score: 0.6450675343786558\n",
      "Training:- after 3040 epochs, loss: 0.08564536273479462, auc_score: 0.6473563071699758\n",
      "Test:- after 3040 epochs, loss: 0.08465418964624405, auc_score: 0.6467116813166935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 3050 epochs, loss: 0.08471889793872833, auc_score: 0.6464478609152723\n",
      "Test:- after 3050 epochs, loss: 0.08453268557786942, auc_score: 0.6470825017133209\n",
      "Training:- after 3060 epochs, loss: 0.0841589868068695, auc_score: 0.6468602203853768\n",
      "Test:- after 3060 epochs, loss: 0.08446966856718063, auc_score: 0.6500041129116765\n",
      "Training:- after 3070 epochs, loss: 0.0847562700510025, auc_score: 0.6446331071849758\n",
      "Test:- after 3070 epochs, loss: 0.08513066917657852, auc_score: 0.6463672647189665\n",
      "Training:- after 3080 epochs, loss: 0.08420484513044357, auc_score: 0.6495312043029039\n",
      "Test:- after 3080 epochs, loss: 0.0839005708694458, auc_score: 0.6517036372222095\n",
      "Training:- after 3090 epochs, loss: 0.08356330543756485, auc_score: 0.641402683293451\n",
      "Test:- after 3090 epochs, loss: 0.08389488607645035, auc_score: 0.6479538620615931\n",
      "Training:- after 3100 epochs, loss: 0.08404377847909927, auc_score: 0.6497588219359102\n",
      "Test:- after 3100 epochs, loss: 0.08355533331632614, auc_score: 0.6526420025373854\n",
      "Training:- after 3110 epochs, loss: 0.08328579366207123, auc_score: 0.6473641858193088\n",
      "Test:- after 3110 epochs, loss: 0.08293367922306061, auc_score: 0.6500332073410118\n",
      "Training:- after 3120 epochs, loss: 0.08440105617046356, auc_score: 0.6503070064431901\n",
      "Test:- after 3120 epochs, loss: 0.0828569307923317, auc_score: 0.6514060140589829\n",
      "Training:- after 3130 epochs, loss: 0.08318197727203369, auc_score: 0.6493902614693379\n",
      "Test:- after 3130 epochs, loss: 0.08302250504493713, auc_score: 0.6568151385376351\n",
      "Training:- after 3140 epochs, loss: 0.08306977152824402, auc_score: 0.6510935689925459\n",
      "Test:- after 3140 epochs, loss: 0.08241801708936691, auc_score: 0.6539454889468965\n",
      "Training:- after 3150 epochs, loss: 0.08345349133014679, auc_score: 0.6509346399184353\n",
      "Test:- after 3150 epochs, loss: 0.08186245709657669, auc_score: 0.6482338848124954\n",
      "Training:- after 3160 epochs, loss: 0.08292373269796371, auc_score: 0.650905828528997\n",
      "Test:- after 3160 epochs, loss: 0.0828070268034935, auc_score: 0.6547909925275149\n",
      "Training:- after 3170 epochs, loss: 0.08311188220977783, auc_score: 0.6476551092446736\n",
      "Test:- after 3170 epochs, loss: 0.08262040466070175, auc_score: 0.6490672773757431\n",
      "Training:- after 3180 epochs, loss: 0.08312272280454636, auc_score: 0.6513286619566221\n",
      "Test:- after 3180 epochs, loss: 0.08317694067955017, auc_score: 0.6551749321328229\n",
      "Training:- after 3190 epochs, loss: 0.08247241377830505, auc_score: 0.6501372647345812\n",
      "Test:- after 3190 epochs, loss: 0.08257792145013809, auc_score: 0.6521204654910235\n",
      "Training:- after 3200 epochs, loss: 0.08303225040435791, auc_score: 0.6502773986652346\n",
      "Test:- after 3200 epochs, loss: 0.08266313374042511, auc_score: 0.6459383572369238\n",
      "Training:- after 3210 epochs, loss: 0.08292357623577118, auc_score: 0.6486718661114383\n",
      "Test:- after 3210 epochs, loss: 0.08315946906805038, auc_score: 0.6516222854067342\n",
      "Training:- after 3220 epochs, loss: 0.08275951445102692, auc_score: 0.6508159504385491\n",
      "Test:- after 3220 epochs, loss: 0.08498100936412811, auc_score: 0.6503057911030405\n",
      "Training:- after 3230 epochs, loss: 0.08290696889162064, auc_score: 0.6541554114668242\n",
      "Test:- after 3230 epochs, loss: 0.08279266953468323, auc_score: 0.6533715704782401\n",
      "Training:- after 3240 epochs, loss: 0.08215200155973434, auc_score: 0.6557968607288935\n",
      "Test:- after 3240 epochs, loss: 0.08307456970214844, auc_score: 0.6547972006960833\n",
      "Training:- after 3250 epochs, loss: 0.08312585204839706, auc_score: 0.6512956815984392\n",
      "Test:- after 3250 epochs, loss: 0.0836244523525238, auc_score: 0.6538048287669433\n",
      "Training:- after 3260 epochs, loss: 0.08325188606977463, auc_score: 0.6529849515176614\n",
      "Test:- after 3260 epochs, loss: 0.08153755217790604, auc_score: 0.6586023818529227\n",
      "Training:- after 3270 epochs, loss: 0.08270823955535889, auc_score: 0.6556954722525129\n",
      "Test:- after 3270 epochs, loss: 0.08136877417564392, auc_score: 0.6532323542063452\n",
      "Training:- after 3280 epochs, loss: 0.08279291540384293, auc_score: 0.6521369780721595\n",
      "Test:- after 3280 epochs, loss: 0.08264043927192688, auc_score: 0.6458175269396669\n",
      "Training:- after 3290 epochs, loss: 0.08236484229564667, auc_score: 0.6502176556324942\n",
      "Test:- after 3290 epochs, loss: 0.08223382383584976, auc_score: 0.6570807794554094\n",
      "Training:- after 3300 epochs, loss: 0.0830933004617691, auc_score: 0.6546583635303636\n",
      "Test:- after 3300 epochs, loss: 0.0820215567946434, auc_score: 0.6542380043648768\n",
      "Training:- after 3310 epochs, loss: 0.08211636543273926, auc_score: 0.6520806948262584\n",
      "Test:- after 3310 epochs, loss: 0.08204613626003265, auc_score: 0.6544893652227786\n",
      "Training:- after 3320 epochs, loss: 0.08303172141313553, auc_score: 0.6531018911500727\n",
      "Test:- after 3320 epochs, loss: 0.08253733813762665, auc_score: 0.6478092931525568\n",
      "Training:- after 3330 epochs, loss: 0.08214309811592102, auc_score: 0.6526889912945896\n",
      "Test:- after 3330 epochs, loss: 0.08190523833036423, auc_score: 0.6648660772731505\n",
      "Training:- after 3340 epochs, loss: 0.0822560116648674, auc_score: 0.6509217760070543\n",
      "Test:- after 3340 epochs, loss: 0.08221611380577087, auc_score: 0.6484960272746217\n",
      "Training:- after 3350 epochs, loss: 0.0826582983136177, auc_score: 0.6514342228505964\n",
      "Test:- after 3350 epochs, loss: 0.08285065740346909, auc_score: 0.6583946499173672\n",
      "Training:- after 3360 epochs, loss: 0.08256194740533829, auc_score: 0.6519503360177673\n",
      "Test:- after 3360 epochs, loss: 0.0816584974527359, auc_score: 0.6552953966824437\n",
      "Training:- after 3370 epochs, loss: 0.08223758637905121, auc_score: 0.6539296789747145\n",
      "Test:- after 3370 epochs, loss: 0.08294006437063217, auc_score: 0.6510110765812832\n",
      "Training:- after 3380 epochs, loss: 0.08225041627883911, auc_score: 0.655016557446429\n",
      "Test:- after 3380 epochs, loss: 0.08316951990127563, auc_score: 0.6571823109991459\n",
      "Training:- after 3390 epochs, loss: 0.08271120488643646, auc_score: 0.6506567709779967\n",
      "Test:- after 3390 epochs, loss: 0.08522301912307739, auc_score: 0.6547601202466277\n",
      "Training:- after 3400 epochs, loss: 0.08310042321681976, auc_score: 0.6489352731409181\n",
      "Test:- after 3400 epochs, loss: 0.08199748396873474, auc_score: 0.6450883088443771\n",
      "Training:- after 3410 epochs, loss: 0.08208884298801422, auc_score: 0.6517864866185095\n",
      "Test:- after 3410 epochs, loss: 0.08401606976985931, auc_score: 0.6589778329326625\n",
      "Training:- after 3420 epochs, loss: 0.08231967687606812, auc_score: 0.655478691691564\n",
      "Test:- after 3420 epochs, loss: 0.0816289409995079, auc_score: 0.6630935624561414\n",
      "Training:- after 3430 epochs, loss: 0.08204444497823715, auc_score: 0.6516000631226092\n",
      "Test:- after 3430 epochs, loss: 0.0833447277545929, auc_score: 0.6600585853927163\n",
      "Training:- after 3440 epochs, loss: 0.08302030712366104, auc_score: 0.6509406391421071\n",
      "Test:- after 3440 epochs, loss: 0.08390353620052338, auc_score: 0.6522533050323962\n",
      "Training:- after 3450 epochs, loss: 0.08261023461818695, auc_score: 0.6464869998339537\n",
      "Test:- after 3450 epochs, loss: 0.08245102316141129, auc_score: 0.6449864051921764\n",
      "Training:- after 3460 epochs, loss: 0.08206740766763687, auc_score: 0.6509418129332504\n",
      "Test:- after 3460 epochs, loss: 0.0816558301448822, auc_score: 0.6494882815284354\n",
      "Training:- after 3470 epochs, loss: 0.08218115568161011, auc_score: 0.6553474454449404\n",
      "Test:- after 3470 epochs, loss: 0.08179795742034912, auc_score: 0.6536356657147009\n",
      "Training:- after 3480 epochs, loss: 0.08213956654071808, auc_score: 0.655145660184092\n",
      "Test:- after 3480 epochs, loss: 0.08224073052406311, auc_score: 0.6546709128080153\n",
      "Training:- after 3490 epochs, loss: 0.08281947672367096, auc_score: 0.6538120711524325\n",
      "Test:- after 3490 epochs, loss: 0.08155470341444016, auc_score: 0.6493182883880799\n",
      "Training:- after 3500 epochs, loss: 0.08233974874019623, auc_score: 0.6554321486851804\n",
      "Test:- after 3500 epochs, loss: 0.08279132843017578, auc_score: 0.6480734265539883\n",
      "Training:- after 3510 epochs, loss: 0.0823078453540802, auc_score: 0.6505093230238709\n",
      "Test:- after 3510 epochs, loss: 0.08213219046592712, auc_score: 0.6577417554026619\n",
      "Training:- after 3520 epochs, loss: 0.08311253041028976, auc_score: 0.6497540544440455\n",
      "Test:- after 3520 epochs, loss: 0.08211244642734528, auc_score: 0.6576440117322682\n",
      "Training:- after 3530 epochs, loss: 0.08328631520271301, auc_score: 0.6550923235362899\n",
      "Test:- after 3530 epochs, loss: 0.08143956959247589, auc_score: 0.6583465715955196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 3540 epochs, loss: 0.08210450410842896, auc_score: 0.6547525926887867\n",
      "Test:- after 3540 epochs, loss: 0.0822102427482605, auc_score: 0.6579133133068162\n",
      "Training:- after 3550 epochs, loss: 0.08214688301086426, auc_score: 0.6498092613534241\n",
      "Test:- after 3550 epochs, loss: 0.08094549924135208, auc_score: 0.6563507948802912\n",
      "Training:- after 3560 epochs, loss: 0.08254511654376984, auc_score: 0.6577858992873975\n",
      "Test:- after 3560 epochs, loss: 0.081987664103508, auc_score: 0.6602378621621959\n",
      "Training:- after 3570 epochs, loss: 0.08169401437044144, auc_score: 0.6510142680294746\n",
      "Test:- after 3570 epochs, loss: 0.08273236453533173, auc_score: 0.6498911096138287\n",
      "Training:- after 3580 epochs, loss: 0.08213067054748535, auc_score: 0.6532084279697926\n",
      "Test:- after 3580 epochs, loss: 0.08231893926858902, auc_score: 0.6532044905973152\n",
      "Training:- after 3590 epochs, loss: 0.08298224955797195, auc_score: 0.6571585873434234\n",
      "Test:- after 3590 epochs, loss: 0.08203102648258209, auc_score: 0.653759221626949\n",
      "Training:- after 3600 epochs, loss: 0.08257519453763962, auc_score: 0.6528622249136034\n",
      "Test:- after 3600 epochs, loss: 0.08263905346393585, auc_score: 0.6475088107969416\n",
      "Training:- after 3610 epochs, loss: 0.08242931216955185, auc_score: 0.6480208135715309\n",
      "Test:- after 3610 epochs, loss: 0.08229382336139679, auc_score: 0.6514860587242115\n",
      "Training:- after 3620 epochs, loss: 0.08251283317804337, auc_score: 0.653118536379564\n",
      "Test:- after 3620 epochs, loss: 0.0829206183552742, auc_score: 0.6609245485780476\n",
      "Training:- after 3630 epochs, loss: 0.08369733393192291, auc_score: 0.6559454835580866\n",
      "Test:- after 3630 epochs, loss: 0.08343873918056488, auc_score: 0.6564954592017544\n",
      "Training:- after 3640 epochs, loss: 0.08236938714981079, auc_score: 0.6488026464678232\n",
      "Test:- after 3640 epochs, loss: 0.08139930665493011, auc_score: 0.6565040176964353\n",
      "Training:- after 3650 epochs, loss: 0.0827907919883728, auc_score: 0.6515800987207818\n",
      "Test:- after 3650 epochs, loss: 0.08320741355419159, auc_score: 0.6509542393986585\n",
      "Training:- after 3660 epochs, loss: 0.08395528048276901, auc_score: 0.6541160944889928\n",
      "Test:- after 3660 epochs, loss: 0.08374834060668945, auc_score: 0.6590671516857729\n",
      "Training:- after 3670 epochs, loss: 0.08185195922851562, auc_score: 0.6503733010081447\n",
      "Test:- after 3670 epochs, loss: 0.0820392444729805, auc_score: 0.6540887093603014\n",
      "Training:- after 3680 epochs, loss: 0.08214487135410309, auc_score: 0.6556131763089174\n",
      "Test:- after 3680 epochs, loss: 0.08298046141862869, auc_score: 0.6518062342047113\n",
      "Training:- after 3690 epochs, loss: 0.08209848403930664, auc_score: 0.6497655032433878\n",
      "Test:- after 3690 epochs, loss: 0.08235286921262741, auc_score: 0.6585540999845648\n",
      "Training:- after 3700 epochs, loss: 0.08223875612020493, auc_score: 0.6567971386006916\n",
      "Test:- after 3700 epochs, loss: 0.0822254866361618, auc_score: 0.651982492761091\n",
      "Training:- after 3710 epochs, loss: 0.08252838253974915, auc_score: 0.6555589335006592\n",
      "Test:- after 3710 epochs, loss: 0.0821186751127243, auc_score: 0.6542932926857737\n",
      "Training:- after 3720 epochs, loss: 0.08207587152719498, auc_score: 0.6553942169622089\n",
      "Test:- after 3720 epochs, loss: 0.08223851770162582, auc_score: 0.6485215564596103\n",
      "Training:- after 3730 epochs, loss: 0.08285430073738098, auc_score: 0.6552833400122924\n",
      "Test:- after 3730 epochs, loss: 0.08354630321264267, auc_score: 0.6550069521946722\n",
      "Training:- after 3740 epochs, loss: 0.08257892727851868, auc_score: 0.6521163848958791\n",
      "Test:- after 3740 epochs, loss: 0.08245449513196945, auc_score: 0.6591874667559251\n",
      "Training:- after 3750 epochs, loss: 0.08252084255218506, auc_score: 0.6568232739788742\n",
      "Test:- after 3750 epochs, loss: 0.0821644738316536, auc_score: 0.6502883783351556\n",
      "Training:- after 3760 epochs, loss: 0.08316102623939514, auc_score: 0.6523233463864748\n",
      "Test:- after 3760 epochs, loss: 0.08133105933666229, auc_score: 0.6526584071139607\n",
      "Training:- after 3770 epochs, loss: 0.08269645273685455, auc_score: 0.6536234357618217\n",
      "Test:- after 3770 epochs, loss: 0.08218889683485031, auc_score: 0.6528530071191792\n",
      "Training:- after 3780 epochs, loss: 0.08268289268016815, auc_score: 0.6554438483636571\n",
      "Test:- after 3780 epochs, loss: 0.0832972526550293, auc_score: 0.6594009584216434\n",
      "Training:- after 3790 epochs, loss: 0.0824514627456665, auc_score: 0.6532461854766174\n",
      "Test:- after 3790 epochs, loss: 0.08219368755817413, auc_score: 0.6630022177791695\n",
      "Training:- after 3800 epochs, loss: 0.08199889212846756, auc_score: 0.6519509170010263\n",
      "Test:- after 3800 epochs, loss: 0.08157546818256378, auc_score: 0.6537117762075324\n",
      "Training:- after 3810 epochs, loss: 0.08337625116109848, auc_score: 0.6554630354934448\n",
      "Test:- after 3810 epochs, loss: 0.08172163367271423, auc_score: 0.6526064264238585\n",
      "Training:- after 3820 epochs, loss: 0.08253472298383713, auc_score: 0.6512401151219116\n",
      "Test:- after 3820 epochs, loss: 0.08176732063293457, auc_score: 0.6536831747424021\n",
      "Training:- after 3830 epochs, loss: 0.08325634151697159, auc_score: 0.6507970850371095\n",
      "Test:- after 3830 epochs, loss: 0.08224823325872421, auc_score: 0.6560913653114994\n",
      "Training:- after 3840 epochs, loss: 0.08282642811536789, auc_score: 0.6509916569808779\n",
      "Test:- after 3840 epochs, loss: 0.0825190469622612, auc_score: 0.6526380810866452\n",
      "Training:- after 3850 epochs, loss: 0.0824047327041626, auc_score: 0.6516002245287453\n",
      "Test:- after 3850 epochs, loss: 0.0832899957895279, auc_score: 0.6569021165058753\n",
      "Training:- after 3860 epochs, loss: 0.08226880431175232, auc_score: 0.6537106327170098\n",
      "Test:- after 3860 epochs, loss: 0.08173055946826935, auc_score: 0.6597252748014648\n",
      "Training:- after 3870 epochs, loss: 0.0825188085436821, auc_score: 0.6546677471588882\n",
      "Test:- after 3870 epochs, loss: 0.08302576839923859, auc_score: 0.6542417031866212\n",
      "Training:- after 3880 epochs, loss: 0.0825076475739479, auc_score: 0.6506892516472198\n",
      "Test:- after 3880 epochs, loss: 0.0828758180141449, auc_score: 0.6539589230165853\n",
      "Training:- after 3890 epochs, loss: 0.0829658955335617, auc_score: 0.6575001392817693\n",
      "Test:- after 3890 epochs, loss: 0.08282677084207535, auc_score: 0.6530064430230763\n",
      "Training:- after 3900 epochs, loss: 0.08290202915668488, auc_score: 0.6549332189650314\n",
      "Test:- after 3900 epochs, loss: 0.08269494026899338, auc_score: 0.6556066383793842\n",
      "Training:- after 3910 epochs, loss: 0.08299549669027328, auc_score: 0.6541447512714544\n",
      "Test:- after 3910 epochs, loss: 0.08348400145769119, auc_score: 0.6579111474447286\n",
      "Training:- after 3920 epochs, loss: 0.08316393196582794, auc_score: 0.6516024009495798\n",
      "Test:- after 3920 epochs, loss: 0.08456069976091385, auc_score: 0.6605093327792458\n",
      "Training:- after 3930 epochs, loss: 0.08193820714950562, auc_score: 0.6501000076064858\n",
      "Test:- after 3930 epochs, loss: 0.08193545043468475, auc_score: 0.6530927721868146\n",
      "Training:- after 3940 epochs, loss: 0.08254940807819366, auc_score: 0.6518240292127685\n",
      "Test:- after 3940 epochs, loss: 0.08286366611719131, auc_score: 0.6472845407074129\n",
      "Training:- after 3950 epochs, loss: 0.08324329555034637, auc_score: 0.6510766946609384\n",
      "Test:- after 3950 epochs, loss: 0.0818251520395279, auc_score: 0.6490016399869563\n",
      "Training:- after 3960 epochs, loss: 0.08207662403583527, auc_score: 0.656718312002174\n",
      "Test:- after 3960 epochs, loss: 0.08199702203273773, auc_score: 0.6548690907792375\n",
      "Training:- after 3970 epochs, loss: 0.08274044096469879, auc_score: 0.6547059133050572\n",
      "Test:- after 3970 epochs, loss: 0.08289968967437744, auc_score: 0.6569601558850773\n",
      "Training:- after 3980 epochs, loss: 0.08303532004356384, auc_score: 0.6492927742324764\n",
      "Test:- after 3980 epochs, loss: 0.0839783102273941, auc_score: 0.6537729101297758\n",
      "Training:- after 3990 epochs, loss: 0.08242529630661011, auc_score: 0.6590871417607931\n",
      "Test:- after 3990 epochs, loss: 0.08379511535167694, auc_score: 0.6554878053822608\n",
      "Training:- after 4000 epochs, loss: 0.08288713544607162, auc_score: 0.6540037317749008\n",
      "Test:- after 4000 epochs, loss: 0.08243102580308914, auc_score: 0.6615980680790056\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op1)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        _ = sess.run(train_op1, feed_dict = {X1_nn:X1_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "        if epoch%10 == 0:\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X1_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X1_tr})\n",
    "            print('Training:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X1_ts, y1_nn:y_ts.reshape(y_ts.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X1_ts})\n",
    "            print('Test:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path1 = saver1.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/nn.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/nn.ckpt\n",
      "Training:- after 10 epochs, loss: 0.08289831131696701, auc_score: 0.655565164486988\n",
      "Test:- after 10 epochs, loss: 0.08353843539953232, auc_score: 0.6561553934106881\n",
      "Training:- after 20 epochs, loss: 0.08227206766605377, auc_score: 0.6511637012396584\n",
      "Test:- after 20 epochs, loss: 0.08246727287769318, auc_score: 0.6573637059244998\n",
      "Training:- after 30 epochs, loss: 0.08302966505289078, auc_score: 0.6509390527700778\n",
      "Test:- after 30 epochs, loss: 0.08253052085638046, auc_score: 0.6522874785832495\n",
      "Training:- after 40 epochs, loss: 0.08298968523740768, auc_score: 0.6526799251572557\n",
      "Test:- after 40 epochs, loss: 0.0811304897069931, auc_score: 0.6548682384282251\n",
      "Training:- after 50 epochs, loss: 0.08292673528194427, auc_score: 0.6469326151760117\n",
      "Test:- after 50 epochs, loss: 0.08313561230897903, auc_score: 0.6546226754654565\n",
      "Training:- after 60 epochs, loss: 0.08220931142568588, auc_score: 0.6537922971270731\n",
      "Test:- after 60 epochs, loss: 0.08321349322795868, auc_score: 0.6551818527141775\n",
      "Training:- after 70 epochs, loss: 0.08229917287826538, auc_score: 0.6458029763955637\n",
      "Test:- after 70 epochs, loss: 0.0817728117108345, auc_score: 0.6381592548660941\n",
      "Training:- after 80 epochs, loss: 0.0825790986418724, auc_score: 0.6596183977402659\n",
      "Test:- after 80 epochs, loss: 0.08369338512420654, auc_score: 0.6578132765577658\n",
      "Training:- after 90 epochs, loss: 0.08295640349388123, auc_score: 0.6492014695009798\n",
      "Test:- after 90 epochs, loss: 0.0835212767124176, auc_score: 0.6458862715931519\n",
      "Training:- after 100 epochs, loss: 0.08260804414749146, auc_score: 0.6508348492445554\n",
      "Test:- after 100 epochs, loss: 0.08290616422891617, auc_score: 0.6546426898121778\n",
      "Training:- after 110 epochs, loss: 0.08179527521133423, auc_score: 0.6533702872846039\n",
      "Test:- after 110 epochs, loss: 0.08242971450090408, auc_score: 0.6511449879222497\n",
      "Training:- after 120 epochs, loss: 0.08275076746940613, auc_score: 0.651530159977613\n",
      "Test:- after 120 epochs, loss: 0.0821283757686615, auc_score: 0.6588798062054029\n",
      "Training:- after 130 epochs, loss: 0.08283809572458267, auc_score: 0.6457408007417729\n",
      "Test:- after 130 epochs, loss: 0.0822218731045723, auc_score: 0.6410074112174966\n",
      "Training:- after 140 epochs, loss: 0.08248628675937653, auc_score: 0.6519339810828284\n",
      "Test:- after 140 epochs, loss: 0.08287160843610764, auc_score: 0.6499401229774585\n",
      "Training:- after 150 epochs, loss: 0.08315781503915787, auc_score: 0.6476341741396434\n",
      "Test:- after 150 epochs, loss: 0.08187784254550934, auc_score: 0.6531208743269115\n",
      "Training:- after 160 epochs, loss: 0.08266042172908783, auc_score: 0.6497811302740979\n",
      "Test:- after 160 epochs, loss: 0.08237246423959732, auc_score: 0.653136970403307\n",
      "Training:- after 170 epochs, loss: 0.08258930593729019, auc_score: 0.6487403187690581\n",
      "Test:- after 170 epochs, loss: 0.08305120468139648, auc_score: 0.6494557109063516\n",
      "Training:- after 180 epochs, loss: 0.08310384303331375, auc_score: 0.6489059088517063\n",
      "Test:- after 180 epochs, loss: 0.0840836763381958, auc_score: 0.6479282819899771\n",
      "Training:- after 190 epochs, loss: 0.08285001665353775, auc_score: 0.6555102552625527\n",
      "Test:- after 190 epochs, loss: 0.08265740424394608, auc_score: 0.656303184079335\n",
      "Training:- after 200 epochs, loss: 0.082779161632061, auc_score: 0.6547289633428701\n",
      "Test:- after 200 epochs, loss: 0.08234750479459763, auc_score: 0.6544635752438237\n",
      "Training:- after 210 epochs, loss: 0.0826653391122818, auc_score: 0.6524408528125947\n",
      "Test:- after 210 epochs, loss: 0.08364753425121307, auc_score: 0.6542150767587249\n",
      "Training:- after 220 epochs, loss: 0.08279488980770111, auc_score: 0.6493731542911496\n",
      "Test:- after 220 epochs, loss: 0.0828537791967392, auc_score: 0.655469238124012\n",
      "Training:- after 230 epochs, loss: 0.08287544548511505, auc_score: 0.6456288360248627\n",
      "Test:- after 230 epochs, loss: 0.0827755257487297, auc_score: 0.6441522429686861\n",
      "Training:- after 240 epochs, loss: 0.08299797773361206, auc_score: 0.6442699352987147\n",
      "Test:- after 240 epochs, loss: 0.08367887139320374, auc_score: 0.6531969053093873\n",
      "Training:- after 250 epochs, loss: 0.0843452662229538, auc_score: 0.6531719095851662\n",
      "Test:- after 250 epochs, loss: 0.08215887099504471, auc_score: 0.6533631169372285\n",
      "Training:- after 260 epochs, loss: 0.08314661681652069, auc_score: 0.6455799186337086\n",
      "Test:- after 260 epochs, loss: 0.08577131479978561, auc_score: 0.6428918193677888\n",
      "Training:- after 270 epochs, loss: 0.08353245258331299, auc_score: 0.6493302103065687\n",
      "Test:- after 270 epochs, loss: 0.08374137431383133, auc_score: 0.6509516314589935\n",
      "Training:- after 280 epochs, loss: 0.08265107870101929, auc_score: 0.6493015391374796\n",
      "Test:- after 280 epochs, loss: 0.08342636376619339, auc_score: 0.6522920456580775\n",
      "Training:- after 290 epochs, loss: 0.08240442723035812, auc_score: 0.654957523595594\n",
      "Test:- after 290 epochs, loss: 0.08343974500894547, auc_score: 0.6517548832366258\n",
      "Training:- after 300 epochs, loss: 0.0824725329875946, auc_score: 0.6587039028940797\n",
      "Test:- after 300 epochs, loss: 0.08212503045797348, auc_score: 0.6561223234635708\n",
      "Training:- after 310 epochs, loss: 0.08319471031427383, auc_score: 0.6537179930535982\n",
      "Test:- after 310 epochs, loss: 0.0835939422249794, auc_score: 0.6534507627924562\n",
      "Training:- after 320 epochs, loss: 0.08373522013425827, auc_score: 0.6482593344944965\n",
      "Test:- after 320 epochs, loss: 0.08304861932992935, auc_score: 0.646015520446864\n",
      "Training:- after 330 epochs, loss: 0.08260323852300644, auc_score: 0.6412897597965018\n",
      "Test:- after 330 epochs, loss: 0.08353562653064728, auc_score: 0.6407720701060489\n",
      "Training:- after 340 epochs, loss: 0.08318696171045303, auc_score: 0.6509214630486365\n",
      "Test:- after 340 epochs, loss: 0.08380517363548279, auc_score: 0.6528340645720518\n",
      "Training:- after 350 epochs, loss: 0.0824275016784668, auc_score: 0.6597555019062888\n",
      "Test:- after 350 epochs, loss: 0.08235760033130646, auc_score: 0.6541378912858851\n",
      "Training:- after 360 epochs, loss: 0.08381138741970062, auc_score: 0.6467641396877009\n",
      "Test:- after 360 epochs, loss: 0.08513869345188141, auc_score: 0.6430499177589407\n",
      "Training:- after 370 epochs, loss: 0.08387862145900726, auc_score: 0.6505453722664865\n",
      "Test:- after 370 epochs, loss: 0.08174468576908112, auc_score: 0.6503870093411183\n",
      "Training:- after 380 epochs, loss: 0.0850573480129242, auc_score: 0.6476962121350874\n",
      "Test:- after 380 epochs, loss: 0.0838339626789093, auc_score: 0.6471409450051295\n",
      "Training:- after 390 epochs, loss: 0.0837903842329979, auc_score: 0.642587875740416\n",
      "Test:- after 390 epochs, loss: 0.08254941552877426, auc_score: 0.6376563900316505\n",
      "Training:- after 400 epochs, loss: 0.08306138962507248, auc_score: 0.6489119409872522\n",
      "Test:- after 400 epochs, loss: 0.0829775482416153, auc_score: 0.6525186438108191\n",
      "Training:- after 410 epochs, loss: 0.08373510092496872, auc_score: 0.6625056656830158\n",
      "Test:- after 410 epochs, loss: 0.0834139883518219, auc_score: 0.6594065909352369\n",
      "Training:- after 420 epochs, loss: 0.08337625116109848, auc_score: 0.6456770721205194\n",
      "Test:- after 420 epochs, loss: 0.08455898612737656, auc_score: 0.6434885859322417\n",
      "Training:- after 430 epochs, loss: 0.08278564363718033, auc_score: 0.6482392350948629\n",
      "Test:- after 430 epochs, loss: 0.08273905515670776, auc_score: 0.647561287631663\n",
      "Training:- after 440 epochs, loss: 0.08300726860761642, auc_score: 0.6517330171407493\n",
      "Test:- after 440 epochs, loss: 0.08149617910385132, auc_score: 0.6618145461536814\n",
      "Training:- after 450 epochs, loss: 0.08294994384050369, auc_score: 0.6526083169012837\n",
      "Test:- after 450 epochs, loss: 0.08400775492191315, auc_score: 0.6512336960358287\n",
      "Training:- after 460 epochs, loss: 0.0830112174153328, auc_score: 0.6506080253395258\n",
      "Test:- after 460 epochs, loss: 0.08347778022289276, auc_score: 0.6522229225352996\n",
      "Training:- after 470 epochs, loss: 0.0834144577383995, auc_score: 0.6581866286472379\n",
      "Test:- after 470 epochs, loss: 0.08431390672922134, auc_score: 0.6649756043782499\n",
      "Training:- after 480 epochs, loss: 0.08350030332803726, auc_score: 0.6514323918073608\n",
      "Test:- after 480 epochs, loss: 0.08293981850147247, auc_score: 0.6468541765956549\n",
      "Training:- after 490 epochs, loss: 0.08491801470518112, auc_score: 0.6544983893564491\n",
      "Test:- after 490 epochs, loss: 0.08477615565061569, auc_score: 0.6485402064086289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 500 epochs, loss: 0.08385375887155533, auc_score: 0.6415748147588434\n",
      "Test:- after 500 epochs, loss: 0.08353904634714127, auc_score: 0.6476697461175824\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver1.restore(sess, path1)\n",
    "    for epoch in range(1, 500+1):\n",
    "        _ = sess.run(train_op1, feed_dict = {X1_nn:X1_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "        if epoch%10 == 0:\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X1_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X1_tr})\n",
    "            print('Training:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X1_ts, y1_nn:y_ts.reshape(y_ts.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X1_ts})\n",
    "            print('Test:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path1 = saver1.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/nn.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/nn.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver1.restore(sess, 'E:/kaggle/home-credit-default-risk/dnn/nn.ckpt')\n",
    "    preds = sess.run(s, feed_dict={X1_nn:X1_sub})\n",
    "    submission['TARGET'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>-0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100065</td>\n",
       "      <td>-0.075987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100117</td>\n",
       "      <td>-0.003722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100141</td>\n",
       "      <td>-0.044737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100212</td>\n",
       "      <td>-0.033018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>100223</td>\n",
       "      <td>-0.014464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100271</td>\n",
       "      <td>-0.181456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>100280</td>\n",
       "      <td>-0.130675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>100367</td>\n",
       "      <td>-0.126768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>100399</td>\n",
       "      <td>-0.056456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>100426</td>\n",
       "      <td>-0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>100438</td>\n",
       "      <td>-0.001768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>100445</td>\n",
       "      <td>-0.087706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>100446</td>\n",
       "      <td>-0.087706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>100466</td>\n",
       "      <td>-0.020323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>100512</td>\n",
       "      <td>-0.185362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>100517</td>\n",
       "      <td>-0.037901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>100553</td>\n",
       "      <td>-0.038878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>100569</td>\n",
       "      <td>-0.044737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>100607</td>\n",
       "      <td>-0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>100752</td>\n",
       "      <td>-0.008116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>100772</td>\n",
       "      <td>-0.005675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>100791</td>\n",
       "      <td>-0.099425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>100797</td>\n",
       "      <td>-0.048643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>100872</td>\n",
       "      <td>-0.044737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>100913</td>\n",
       "      <td>-0.009581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>100918</td>\n",
       "      <td>-0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>100984</td>\n",
       "      <td>-0.320128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>100997</td>\n",
       "      <td>-0.108214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>101002</td>\n",
       "      <td>-0.099425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48617</th>\n",
       "      <td>455174</td>\n",
       "      <td>-0.132628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48636</th>\n",
       "      <td>455297</td>\n",
       "      <td>-0.087706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48640</th>\n",
       "      <td>455328</td>\n",
       "      <td>-0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48641</th>\n",
       "      <td>455368</td>\n",
       "      <td>-0.072081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48647</th>\n",
       "      <td>455424</td>\n",
       "      <td>-0.072081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48649</th>\n",
       "      <td>455429</td>\n",
       "      <td>-0.001768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48652</th>\n",
       "      <td>455438</td>\n",
       "      <td>-0.033018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48657</th>\n",
       "      <td>455482</td>\n",
       "      <td>-0.144347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48658</th>\n",
       "      <td>455483</td>\n",
       "      <td>-0.072081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48662</th>\n",
       "      <td>455513</td>\n",
       "      <td>-0.033018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48665</th>\n",
       "      <td>455537</td>\n",
       "      <td>-0.048643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48669</th>\n",
       "      <td>455583</td>\n",
       "      <td>-0.001768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48670</th>\n",
       "      <td>455607</td>\n",
       "      <td>-0.044737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48674</th>\n",
       "      <td>455644</td>\n",
       "      <td>-0.064268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48675</th>\n",
       "      <td>455645</td>\n",
       "      <td>-0.048643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48683</th>\n",
       "      <td>455742</td>\n",
       "      <td>-0.048643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48687</th>\n",
       "      <td>455751</td>\n",
       "      <td>-0.126768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48690</th>\n",
       "      <td>455798</td>\n",
       "      <td>-0.048643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48693</th>\n",
       "      <td>455804</td>\n",
       "      <td>-0.048033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48694</th>\n",
       "      <td>455805</td>\n",
       "      <td>-0.056456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48702</th>\n",
       "      <td>455897</td>\n",
       "      <td>-0.095518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48704</th>\n",
       "      <td>455907</td>\n",
       "      <td>-0.072081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48715</th>\n",
       "      <td>455965</td>\n",
       "      <td>-0.079405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48718</th>\n",
       "      <td>456009</td>\n",
       "      <td>-0.001768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48721</th>\n",
       "      <td>456013</td>\n",
       "      <td>-0.005675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48726</th>\n",
       "      <td>456115</td>\n",
       "      <td>-0.005675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48727</th>\n",
       "      <td>456116</td>\n",
       "      <td>-0.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48728</th>\n",
       "      <td>456119</td>\n",
       "      <td>-0.017393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48735</th>\n",
       "      <td>456169</td>\n",
       "      <td>-0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48741</th>\n",
       "      <td>456223</td>\n",
       "      <td>-0.087706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR    TARGET\n",
       "0          100001 -0.021300\n",
       "7          100065 -0.075987\n",
       "17         100117 -0.003722\n",
       "19         100141 -0.044737\n",
       "28         100212 -0.033018\n",
       "30         100223 -0.014464\n",
       "36         100271 -0.181456\n",
       "38         100280 -0.130675\n",
       "46         100367 -0.126768\n",
       "51         100399 -0.056456\n",
       "55         100426 -0.021300\n",
       "56         100438 -0.001768\n",
       "58         100445 -0.087706\n",
       "59         100446 -0.087706\n",
       "62         100466 -0.020323\n",
       "67         100512 -0.185362\n",
       "68         100517 -0.037901\n",
       "72         100553 -0.038878\n",
       "75         100569 -0.044737\n",
       "79         100607 -0.025206\n",
       "95         100752 -0.008116\n",
       "103        100772 -0.005675\n",
       "105        100791 -0.099425\n",
       "107        100797 -0.048643\n",
       "112        100872 -0.044737\n",
       "114        100913 -0.009581\n",
       "115        100918 -0.021300\n",
       "123        100984 -0.320128\n",
       "125        100997 -0.108214\n",
       "127        101002 -0.099425\n",
       "...           ...       ...\n",
       "48617      455174 -0.132628\n",
       "48636      455297 -0.087706\n",
       "48640      455328 -0.021300\n",
       "48641      455368 -0.072081\n",
       "48647      455424 -0.072081\n",
       "48649      455429 -0.001768\n",
       "48652      455438 -0.033018\n",
       "48657      455482 -0.144347\n",
       "48658      455483 -0.072081\n",
       "48662      455513 -0.033018\n",
       "48665      455537 -0.048643\n",
       "48669      455583 -0.001768\n",
       "48670      455607 -0.044737\n",
       "48674      455644 -0.064268\n",
       "48675      455645 -0.048643\n",
       "48683      455742 -0.048643\n",
       "48687      455751 -0.126768\n",
       "48690      455798 -0.048643\n",
       "48693      455804 -0.048033\n",
       "48694      455805 -0.056456\n",
       "48702      455897 -0.095518\n",
       "48704      455907 -0.072081\n",
       "48715      455965 -0.079405\n",
       "48718      456009 -0.001768\n",
       "48721      456013 -0.005675\n",
       "48726      456115 -0.005675\n",
       "48727      456116 -0.039000\n",
       "48728      456119 -0.017393\n",
       "48735      456169 -0.025206\n",
       "48741      456223 -0.087706\n",
       "\n",
       "[10572 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission['TARGET']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in submission[submission['TARGET']<0].index:\n",
    "    submission.loc[i, 'TARGET'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in submission[submission['TARGET']>1].index:\n",
    "    submission.loc[i, 'TARGET'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('neural_network_full_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/nn.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver1.restore(sess, 'E:/kaggle/home-credit-default-risk/dnn/nn.ckpt')\n",
    "    preds = sess.run(s, feed_dict={X1_nn:X1_tr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs = pd.DataFrame({'SK_ID_CURR':app.loc[:y_tr.shape[0], 'SK_ID_CURR']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261384, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261384,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-c40401356df6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nn_full'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3117\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3119\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3193\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3194\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3195\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3390\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3391\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3393\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m   3999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4000\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4001\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Length of values does not match length of '\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4003\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "train_probs['nn_full'] = preds.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feats = ['CREDIT_INCOME_RATIO', 'AMT_CREDIT_SUM_DEBT', 'AMT_CREDIT_SUM', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_ENDDATE_FACT', 'CNT_INSTALMENT', 'DAYS_REGISTRATION','DAYS_LAST_DUE','DAYS_FIRST_DUE','AMT_ANNUITY_x','NAME_EDUCATION_TYPE_Higher education','ENTIRE_INCOME_PER_CHILD','AMT_CREDIT','LATE_PAYMENT_DAYS','ANNUITY_INCOME_RATIO','ENTIRE_INCOME_PER_FAM_MEMBER', 'DAYS_EMPLOYED', 'DAYS_ID_PUBLISH','HC','SCOFR','MONTHS_BALANCE_x', 'CNT_INSTALMENT_FUTURE','SK_DPD_DEF_x','DAYS_INSTALMENT','Closed','PERCENT_COMPLETION','AMT_GOODS_PRICE','ENTIRE_INCOME', 'AMT_INSTALMENT','CNT_DRAWINGS_CURRENT', 'DAYS_ENTRY_PAYMENT', 'DAYS_LAST_PHONE_CHANGE','DAYS_CREDIT_ENDDATE', 'CREDIT_GOODS_PRICE_DIFF','Active_x','DAYS_CREDIT_UPDATE', 'CNT_DRAWINGS_ATM_CURRENT','AMT_PAYMENT','ANNUITY_ENTIRE_INCOME_RATIO', 'DAYS_BIRTH', 'XAP', 'CREDIT_ENTIRE_INCOME_RATIO', 'YOKIAN_SCORE', 'DAYS_CREDIT', 'EXT_SOURCE_1', 'EXT_SOURCE_3', 'EXT_SOURCE_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = app[selected_feats].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_sub = X2[y.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X2[:y.shape[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(app[selected_feats].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = scaler2.transform(X2)\n",
    "X2_sub = scaler2.transform(X2_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_tr, X2_ts, y_tr, y_ts = train_test_split(X2, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hid_layer1 = 512\n",
    "num_hid_layer2 = 1024\n",
    "num_hid_layer3 = 256\n",
    "n_out = 1\n",
    "n_in = X2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0005\n",
    "epochs = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    X1_nn = tf.placeholder('float', [None, n_in])\n",
    "    y1_nn = tf.placeholder('float', [None, n_out])\n",
    "    weights1 = {'layer1':tf.Variable(tf.random_normal([n_in, num_hid_layer1])),\n",
    "                'layer2':tf.Variable(tf.random_normal([num_hid_layer1, num_hid_layer2])),\n",
    "                'layer3':tf.Variable(tf.random_normal([num_hid_layer2, num_hid_layer3])),\n",
    "                'out':tf.Variable(tf.random_normal([num_hid_layer3, n_out]))\n",
    "        \n",
    "    }\n",
    "    biases1 = {'layer1':tf.Variable(tf.random_normal([num_hid_layer1])),\n",
    "               'layer2':tf.Variable(tf.random_normal([num_hid_layer2])),\n",
    "               'layer3':tf.Variable(tf.random_normal([num_hid_layer3])),\n",
    "               'out':tf.Variable(tf.random_normal([n_out]))\n",
    "    }\n",
    "    h1 = tf.add(tf.matmul(X1_nn, weights1['layer1']), biases1['layer1'])\n",
    "    drop_con = tf.nn.dropout(h1, p1)*p1\n",
    "    h2 = tf.add(tf.matmul(drop_con, weights1['layer2']), biases1['layer2'])\n",
    "    h3 = tf.add(tf.matmul(h2, weights1['layer3']), biases1['layer3'])\n",
    "    s = tf.add(tf.matmul(h3, weights1['out']), biases1['out'])\n",
    "    loss_op1 = tf.losses.mean_squared_error(y1_nn, s)\n",
    "    optimizer1 = tf.train.AdamOptimizer(alpha)\n",
    "    train_op1 = optimizer1.minimize(loss_op1)\n",
    "    init_op1 = tf.global_variables_initializer()\n",
    "with tf.device('/device:CPU:0'):\n",
    "    saver2 = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 10 epochs, loss: 1321499648.0, auc_score: 0.47742863121824825\n",
      "Test:- after 10 epochs, loss: 1281996544.0, auc_score: 0.47239963479824376\n",
      "Training:- after 20 epochs, loss: 649375872.0, auc_score: 0.4553461685500275\n",
      "Test:- after 20 epochs, loss: 661080192.0, auc_score: 0.4574080809437301\n",
      "Training:- after 30 epochs, loss: 531540480.0, auc_score: 0.5364131452615724\n",
      "Test:- after 30 epochs, loss: 776686976.0, auc_score: 0.5362133694680389\n",
      "Training:- after 40 epochs, loss: 437820224.0, auc_score: 0.5268900222521387\n",
      "Test:- after 40 epochs, loss: 434826848.0, auc_score: 0.5330834461765726\n",
      "Training:- after 50 epochs, loss: 413029376.0, auc_score: 0.4846247438662141\n",
      "Test:- after 50 epochs, loss: 406691680.0, auc_score: 0.48500643175377667\n",
      "Training:- after 60 epochs, loss: 365507296.0, auc_score: 0.48965103858542075\n",
      "Test:- after 60 epochs, loss: 364945376.0, auc_score: 0.49207572185478227\n",
      "Training:- after 70 epochs, loss: 336625280.0, auc_score: 0.49895893023554405\n",
      "Test:- after 70 epochs, loss: 344294304.0, auc_score: 0.48274707695598057\n",
      "Training:- after 80 epochs, loss: 318307840.0, auc_score: 0.4968063362453782\n",
      "Test:- after 80 epochs, loss: 310243296.0, auc_score: 0.4978784165389021\n",
      "Training:- after 90 epochs, loss: 300434112.0, auc_score: 0.49753178844611634\n",
      "Test:- after 90 epochs, loss: 297761536.0, auc_score: 0.4957796162210758\n",
      "Training:- after 100 epochs, loss: 272856608.0, auc_score: 0.49531788178977365\n",
      "Test:- after 100 epochs, loss: 269651776.0, auc_score: 0.49578283676090784\n",
      "Training:- after 110 epochs, loss: 261754064.0, auc_score: 0.5000035347443199\n",
      "Test:- after 110 epochs, loss: 301056672.0, auc_score: 0.5055488471337817\n",
      "Training:- after 120 epochs, loss: 242957744.0, auc_score: 0.49813226102795627\n",
      "Test:- after 120 epochs, loss: 259992592.0, auc_score: 0.4903463230512315\n",
      "Training:- after 130 epochs, loss: 217133056.0, auc_score: 0.4927759642966484\n",
      "Test:- after 130 epochs, loss: 227080272.0, auc_score: 0.5004361531086914\n",
      "Training:- after 140 epochs, loss: 204781488.0, auc_score: 0.49898916453840525\n",
      "Test:- after 140 epochs, loss: 211850240.0, auc_score: 0.5033621814121383\n",
      "Training:- after 150 epochs, loss: 190946864.0, auc_score: 0.5014288448503351\n",
      "Test:- after 150 epochs, loss: 212017120.0, auc_score: 0.4945951601130546\n",
      "Training:- after 160 epochs, loss: 177110832.0, auc_score: 0.4983110828189971\n",
      "Test:- after 160 epochs, loss: 181623280.0, auc_score: 0.5047266768878393\n",
      "Training:- after 170 epochs, loss: 162008352.0, auc_score: 0.49722123306843646\n",
      "Test:- after 170 epochs, loss: 164613440.0, auc_score: 0.49710203640080425\n",
      "Training:- after 180 epochs, loss: 155749360.0, auc_score: 0.49751130560900636\n",
      "Test:- after 180 epochs, loss: 151375648.0, auc_score: 0.5017368470790698\n",
      "Training:- after 190 epochs, loss: 139291936.0, auc_score: 0.49932606002419516\n",
      "Test:- after 190 epochs, loss: 137282960.0, auc_score: 0.502324325147691\n",
      "Training:- after 200 epochs, loss: 126045568.0, auc_score: 0.49494476145741945\n",
      "Test:- after 200 epochs, loss: 133856944.0, auc_score: 0.49500267652972535\n",
      "Training:- after 210 epochs, loss: 118090384.0, auc_score: 0.49954396841359766\n",
      "Test:- after 210 epochs, loss: 118426320.0, auc_score: 0.49224624570853737\n",
      "Training:- after 220 epochs, loss: 110842024.0, auc_score: 0.4996199343491936\n",
      "Test:- after 220 epochs, loss: 106369176.0, auc_score: 0.5012862916913803\n",
      "Training:- after 230 epochs, loss: 99298840.0, auc_score: 0.49535031751627934\n",
      "Test:- after 230 epochs, loss: 98122592.0, auc_score: 0.5043986108157914\n",
      "Training:- after 240 epochs, loss: 94850912.0, auc_score: 0.4985603229580501\n",
      "Test:- after 240 epochs, loss: 89744888.0, auc_score: 0.5043706922171116\n",
      "Training:- after 250 epochs, loss: 85041864.0, auc_score: 0.4943685396595052\n",
      "Test:- after 250 epochs, loss: 89847304.0, auc_score: 0.49753955730633553\n",
      "Training:- after 260 epochs, loss: 79582416.0, auc_score: 0.5025432087641357\n",
      "Test:- after 260 epochs, loss: 79912816.0, auc_score: 0.4888514516676552\n",
      "Training:- after 270 epochs, loss: 71383352.0, auc_score: 0.50252137222463\n",
      "Test:- after 270 epochs, loss: 81327464.0, auc_score: 0.5001567028884139\n",
      "Training:- after 280 epochs, loss: 64389508.0, auc_score: 0.4977571855345847\n",
      "Test:- after 280 epochs, loss: 61943916.0, auc_score: 0.5005064516490034\n",
      "Training:- after 290 epochs, loss: 60659808.0, auc_score: 0.5019982780513724\n",
      "Test:- after 290 epochs, loss: 57835932.0, auc_score: 0.4995131886701657\n",
      "Training:- after 300 epochs, loss: 55985584.0, auc_score: 0.4988560354965266\n",
      "Test:- after 300 epochs, loss: 55239784.0, auc_score: 0.49757410971968863\n",
      "Training:- after 310 epochs, loss: 50438508.0, auc_score: 0.5018548760289546\n",
      "Test:- after 310 epochs, loss: 48831800.0, auc_score: 0.49110528554002486\n",
      "Training:- after 320 epochs, loss: 45154368.0, auc_score: 0.5003979706950343\n",
      "Test:- after 320 epochs, loss: 46366692.0, auc_score: 0.49929641463144714\n",
      "Training:- after 330 epochs, loss: 40586872.0, auc_score: 0.4985227398578323\n",
      "Test:- after 330 epochs, loss: 43445452.0, auc_score: 0.4959818543097413\n",
      "Training:- after 340 epochs, loss: 42280740.0, auc_score: 0.5021498478007423\n",
      "Test:- after 340 epochs, loss: 36773160.0, auc_score: 0.4995291017429463\n",
      "Training:- after 350 epochs, loss: 35477704.0, auc_score: 0.5017254633859491\n",
      "Test:- after 350 epochs, loss: 33311426.0, auc_score: 0.5106636083972778\n",
      "Training:- after 360 epochs, loss: 32786318.0, auc_score: 0.4993645042026142\n",
      "Test:- after 360 epochs, loss: 32756424.0, auc_score: 0.5009895979050326\n",
      "Training:- after 370 epochs, loss: 34488792.0, auc_score: 0.4965055702276181\n",
      "Test:- after 370 epochs, loss: 30128146.0, auc_score: 0.49883515623348545\n",
      "Training:- after 380 epochs, loss: 26136934.0, auc_score: 0.5001002099915752\n",
      "Test:- after 380 epochs, loss: 24589494.0, auc_score: 0.4998396631240728\n",
      "Training:- after 390 epochs, loss: 23887270.0, auc_score: 0.49901921342697847\n",
      "Test:- after 390 epochs, loss: 23034004.0, auc_score: 0.5049621959605228\n",
      "Training:- after 400 epochs, loss: 24043864.0, auc_score: 0.49654584163713217\n",
      "Test:- after 400 epochs, loss: 21309436.0, auc_score: 0.5014193410203516\n",
      "Training:- after 410 epochs, loss: 19047088.0, auc_score: 0.4995820013957619\n",
      "Test:- after 410 epochs, loss: 20615712.0, auc_score: 0.4986288831441421\n",
      "Training:- after 420 epochs, loss: 17383310.0, auc_score: 0.49977384344510944\n",
      "Test:- after 420 epochs, loss: 17436180.0, auc_score: 0.5012619169299676\n",
      "Training:- after 430 epochs, loss: 19677352.0, auc_score: 0.49788943084091336\n",
      "Test:- after 430 epochs, loss: 17883822.0, auc_score: 0.5045341967861748\n",
      "Training:- after 440 epochs, loss: 15042546.0, auc_score: 0.4968892611531999\n",
      "Test:- after 440 epochs, loss: 14607994.0, auc_score: 0.49777261745333645\n",
      "Training:- after 450 epochs, loss: 13580992.0, auc_score: 0.49766188823012014\n",
      "Test:- after 450 epochs, loss: 13683818.0, auc_score: 0.4983820082490584\n",
      "Training:- after 460 epochs, loss: 12664186.0, auc_score: 0.5013275955889189\n",
      "Test:- after 460 epochs, loss: 15414513.0, auc_score: 0.49603119136348206\n",
      "Training:- after 470 epochs, loss: 11338514.0, auc_score: 0.4994964415075134\n",
      "Test:- after 470 epochs, loss: 10392103.0, auc_score: 0.4955913669637273\n",
      "Training:- after 480 epochs, loss: 9804395.0, auc_score: 0.4972550896778614\n",
      "Test:- after 480 epochs, loss: 11406785.0, auc_score: 0.48985008946634784\n",
      "Training:- after 490 epochs, loss: 8709877.0, auc_score: 0.5010186200913627\n",
      "Test:- after 490 epochs, loss: 8666254.0, auc_score: 0.4979209177170725\n",
      "Training:- after 500 epochs, loss: 7771329.0, auc_score: 0.5006003331748325\n",
      "Test:- after 500 epochs, loss: 7827922.5, auc_score: 0.5023257240308227\n",
      "Training:- after 510 epochs, loss: 8100956.0, auc_score: 0.49505031492255697\n",
      "Test:- after 510 epochs, loss: 7095098.0, auc_score: 0.4925501546232155\n",
      "Training:- after 520 epochs, loss: 6992888.5, auc_score: 0.5019022162345258\n",
      "Test:- after 520 epochs, loss: 6481774.0, auc_score: 0.4940517655148574\n",
      "Training:- after 530 epochs, loss: 5751656.0, auc_score: 0.5015748619661615\n",
      "Test:- after 530 epochs, loss: 6301055.5, auc_score: 0.4980139807488812\n",
      "Training:- after 540 epochs, loss: 5449748.5, auc_score: 0.4974004593277854\n",
      "Test:- after 540 epochs, loss: 5959035.5, auc_score: 0.4966609157026808\n",
      "Training:- after 550 epochs, loss: 4738172.5, auc_score: 0.5014412647383644\n",
      "Test:- after 550 epochs, loss: 4670169.0, auc_score: 0.4950058753091532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 560 epochs, loss: 4235633.5, auc_score: 0.49707384632081186\n",
      "Test:- after 560 epochs, loss: 4238235.5, auc_score: 0.5012036954140259\n",
      "Training:- after 570 epochs, loss: 3780153.0, auc_score: 0.4986627508963146\n",
      "Test:- after 570 epochs, loss: 3790275.25, auc_score: 0.5020328196634474\n",
      "Training:- after 580 epochs, loss: 3732931.5, auc_score: 0.5047499385815171\n",
      "Test:- after 580 epochs, loss: 3421900.25, auc_score: 0.4972014130584808\n",
      "Training:- after 590 epochs, loss: 3163461.5, auc_score: 0.4955357923558646\n",
      "Test:- after 590 epochs, loss: 3096285.0, auc_score: 0.5008880887277376\n",
      "Training:- after 600 epochs, loss: 2938027.5, auc_score: 0.5004258269656577\n",
      "Test:- after 600 epochs, loss: 2730048.5, auc_score: 0.5060083429389975\n",
      "Training:- after 610 epochs, loss: 2549189.0, auc_score: 0.495459905473639\n",
      "Test:- after 610 epochs, loss: 2535229.25, auc_score: 0.5032284544020055\n",
      "Training:- after 620 epochs, loss: 2211470.5, auc_score: 0.49915887441436624\n",
      "Test:- after 620 epochs, loss: 2410934.0, auc_score: 0.5030833000710011\n",
      "Training:- after 630 epochs, loss: 2091451.25, auc_score: 0.5001079966990913\n",
      "Test:- after 630 epochs, loss: 1958528.25, auc_score: 0.49618055166976904\n",
      "Training:- after 640 epochs, loss: 1882607.875, auc_score: 0.4983406291893371\n",
      "Test:- after 640 epochs, loss: 1779300.5, auc_score: 0.5011304934140582\n",
      "Training:- after 650 epochs, loss: 1631202.625, auc_score: 0.4915085132836796\n",
      "Test:- after 650 epochs, loss: 1659903.75, auc_score: 0.49521718437777057\n",
      "Training:- after 660 epochs, loss: 1519156.25, auc_score: 0.5021318121552018\n",
      "Test:- after 660 epochs, loss: 1451241.625, auc_score: 0.5032506717747661\n",
      "Training:- after 670 epochs, loss: 1406248.5, auc_score: 0.4995912103713629\n",
      "Test:- after 670 epochs, loss: 1311186.5, auc_score: 0.5072858496443107\n",
      "Training:- after 680 epochs, loss: 1191500.0, auc_score: 0.4945236054675033\n",
      "Test:- after 680 epochs, loss: 1266145.875, auc_score: 0.4941002259351689\n",
      "Training:- after 690 epochs, loss: 1062293.75, auc_score: 0.4965113553710747\n",
      "Test:- after 690 epochs, loss: 1078476.375, auc_score: 0.4955542126277491\n",
      "Training:- after 700 epochs, loss: 991601.4375, auc_score: 0.49927498036664036\n",
      "Test:- after 700 epochs, loss: 1012733.5625, auc_score: 0.4967200418297143\n",
      "Training:- after 710 epochs, loss: 1011744.4375, auc_score: 0.49998904729899196\n",
      "Test:- after 710 epochs, loss: 857566.0, auc_score: 0.4967590644518306\n",
      "Training:- after 720 epochs, loss: 848187.4375, auc_score: 0.4962444624857845\n",
      "Test:- after 720 epochs, loss: 766496.0625, auc_score: 0.5043101889673507\n",
      "Training:- after 730 epochs, loss: 869670.625, auc_score: 0.49728192043135794\n",
      "Test:- after 730 epochs, loss: 678168.375, auc_score: 0.4974356482673123\n",
      "Training:- after 740 epochs, loss: 656751.25, auc_score: 0.5058103779058316\n",
      "Test:- after 740 epochs, loss: 672438.4375, auc_score: 0.49264300626823987\n",
      "Training:- after 750 epochs, loss: 551903.125, auc_score: 0.5070671549328668\n",
      "Test:- after 750 epochs, loss: 541706.25, auc_score: 0.4969751577007584\n",
      "Training:- after 760 epochs, loss: 529132.875, auc_score: 0.5010858921350202\n",
      "Test:- after 760 epochs, loss: 500674.875, auc_score: 0.49892941919615824\n",
      "Training:- after 770 epochs, loss: 434515.5625, auc_score: 0.5035957134650533\n",
      "Test:- after 770 epochs, loss: 522332.34375, auc_score: 0.5013068801424498\n",
      "Training:- after 780 epochs, loss: 413072.75, auc_score: 0.49791192394883715\n",
      "Test:- after 780 epochs, loss: 385436.78125, auc_score: 0.503234335928417\n",
      "Training:- after 790 epochs, loss: 404778.34375, auc_score: 0.4960340031203523\n",
      "Test:- after 790 epochs, loss: 363490.59375, auc_score: 0.5031279399860484\n",
      "Training:- after 800 epochs, loss: 315264.9375, auc_score: 0.49746952832677915\n",
      "Test:- after 800 epochs, loss: 317870.15625, auc_score: 0.4918574681085733\n",
      "Training:- after 810 epochs, loss: 283940.03125, auc_score: 0.4982413932658866\n",
      "Test:- after 810 epochs, loss: 276375.375, auc_score: 0.5000894508046997\n",
      "Training:- after 820 epochs, loss: 305916.5625, auc_score: 0.4985945988768416\n",
      "Test:- after 820 epochs, loss: 278997.75, auc_score: 0.4893331151075648\n",
      "Training:- after 830 epochs, loss: 226666.046875, auc_score: 0.49941105783209666\n",
      "Test:- after 830 epochs, loss: 228425.296875, auc_score: 0.5058003694294919\n",
      "Training:- after 840 epochs, loss: 219614.546875, auc_score: 0.4930765966459436\n",
      "Test:- after 840 epochs, loss: 234210.890625, auc_score: 0.49605216528457013\n",
      "Training:- after 850 epochs, loss: 189278.5625, auc_score: 0.49939242824740376\n",
      "Test:- after 850 epochs, loss: 187800.9375, auc_score: 0.49744159507493657\n",
      "Training:- after 860 epochs, loss: 220469.578125, auc_score: 0.49804787763986746\n",
      "Test:- after 860 epochs, loss: 212010.03125, auc_score: 0.4951936986843038\n",
      "Training:- after 870 epochs, loss: 144244.5, auc_score: 0.49630251377993495\n",
      "Test:- after 870 epochs, loss: 150761.359375, auc_score: 0.507772800862458\n",
      "Training:- after 880 epochs, loss: 138963.453125, auc_score: 0.4946870969400464\n",
      "Test:- after 880 epochs, loss: 124210.6328125, auc_score: 0.4934085093128313\n",
      "Training:- after 890 epochs, loss: 143737.828125, auc_score: 0.5091140530826761\n",
      "Test:- after 890 epochs, loss: 112747.0, auc_score: 0.5151004491347442\n",
      "Training:- after 900 epochs, loss: 101333.71875, auc_score: 0.4873804284008999\n",
      "Test:- after 900 epochs, loss: 113633.8828125, auc_score: 0.4920068688270396\n",
      "Training:- after 910 epochs, loss: 102740.078125, auc_score: 0.5052423012764611\n",
      "Test:- after 910 epochs, loss: 91477.3046875, auc_score: 0.5112158035246881\n",
      "Training:- after 920 epochs, loss: 91210.2578125, auc_score: 0.4974273392546551\n",
      "Test:- after 920 epochs, loss: 80623.796875, auc_score: 0.4965030626214696\n",
      "Training:- after 930 epochs, loss: 72752.421875, auc_score: 0.5020416037506797\n",
      "Test:- after 930 epochs, loss: 77453.9296875, auc_score: 0.5003975532601438\n",
      "Training:- after 940 epochs, loss: 69838.7421875, auc_score: 0.4846945566990486\n",
      "Test:- after 940 epochs, loss: 70418.8984375, auc_score: 0.48787645499388843\n",
      "Training:- after 950 epochs, loss: 67671.0625, auc_score: 0.4971505894331596\n",
      "Test:- after 950 epochs, loss: 58844.08203125, auc_score: 0.5030918456926212\n",
      "Training:- after 960 epochs, loss: 49721.14453125, auc_score: 0.4921962034010373\n",
      "Test:- after 960 epochs, loss: 47716.0859375, auc_score: 0.4910552490447183\n",
      "Training:- after 970 epochs, loss: 45969.26953125, auc_score: 0.4932395424622441\n",
      "Test:- after 970 epochs, loss: 52396.97265625, auc_score: 0.4955466058121418\n",
      "Training:- after 980 epochs, loss: 39625.625, auc_score: 0.4951708854609221\n",
      "Test:- after 980 epochs, loss: 40803.48046875, auc_score: 0.49746783190522914\n",
      "Training:- after 990 epochs, loss: 36521.60546875, auc_score: 0.5027536344898358\n",
      "Test:- after 990 epochs, loss: 34295.796875, auc_score: 0.5005804059372331\n",
      "Training:- after 1000 epochs, loss: 32929.2578125, auc_score: 0.5052128249559162\n",
      "Test:- after 1000 epochs, loss: 32905.13671875, auc_score: 0.5101999718979923\n",
      "Training:- after 1010 epochs, loss: 28229.654296875, auc_score: 0.49627282493543556\n",
      "Test:- after 1010 epochs, loss: 27136.822265625, auc_score: 0.5000915864329475\n",
      "Training:- after 1020 epochs, loss: 26823.09375, auc_score: 0.5010627425576186\n",
      "Test:- after 1020 epochs, loss: 28017.271484375, auc_score: 0.49936705201234\n",
      "Training:- after 1030 epochs, loss: 23328.55859375, auc_score: 0.4999403533910252\n",
      "Test:- after 1030 epochs, loss: 21690.04296875, auc_score: 0.4884505317621078\n",
      "Training:- after 1040 epochs, loss: 18889.005859375, auc_score: 0.4966588727200121\n",
      "Test:- after 1040 epochs, loss: 20001.408203125, auc_score: 0.4957142510752749\n",
      "Training:- after 1050 epochs, loss: 18266.4453125, auc_score: 0.49943052524399945\n",
      "Test:- after 1050 epochs, loss: 17219.791015625, auc_score: 0.48647636571405833\n",
      "Training:- after 1060 epochs, loss: 19012.091796875, auc_score: 0.49871640053046096\n",
      "Test:- after 1060 epochs, loss: 15129.060546875, auc_score: 0.49646400891306164\n",
      "Training:- after 1070 epochs, loss: 15454.5595703125, auc_score: 0.49233699082474824\n",
      "Test:- after 1070 epochs, loss: 13613.5087890625, auc_score: 0.49941209915781015\n",
      "Training:- after 1080 epochs, loss: 11886.9833984375, auc_score: 0.49228199599707967\n",
      "Test:- after 1080 epochs, loss: 11813.2841796875, auc_score: 0.4951788798489952\n",
      "Training:- after 1090 epochs, loss: 14168.791015625, auc_score: 0.49038382622656307\n",
      "Test:- after 1090 epochs, loss: 11569.93359375, auc_score: 0.5027166807798432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 1100 epochs, loss: 9758.4765625, auc_score: 0.502113631858813\n",
      "Test:- after 1100 epochs, loss: 11178.23828125, auc_score: 0.5007181461876393\n",
      "Training:- after 1110 epochs, loss: 10519.8583984375, auc_score: 0.49924091182690317\n",
      "Test:- after 1110 epochs, loss: 9239.9140625, auc_score: 0.49569959078005454\n",
      "Training:- after 1120 epochs, loss: 8100.9931640625, auc_score: 0.5102507164780602\n",
      "Test:- after 1120 epochs, loss: 7273.7734375, auc_score: 0.507029440583527\n",
      "Training:- after 1130 epochs, loss: 7100.4921875, auc_score: 0.4891120248047115\n",
      "Test:- after 1130 epochs, loss: 6895.8486328125, auc_score: 0.4929207778287593\n",
      "Training:- after 1140 epochs, loss: 6506.7314453125, auc_score: 0.49440368714417915\n",
      "Test:- after 1140 epochs, loss: 5657.142578125, auc_score: 0.4956628343486116\n",
      "Training:- after 1150 epochs, loss: 5085.73193359375, auc_score: 0.5082618417212117\n",
      "Test:- after 1150 epochs, loss: 5022.77783203125, auc_score: 0.5011975154592129\n",
      "Training:- after 1160 epochs, loss: 4551.666015625, auc_score: 0.5107594825000152\n",
      "Test:- after 1160 epochs, loss: 7768.60400390625, auc_score: 0.5066747428852805\n",
      "Training:- after 1170 epochs, loss: 3979.283203125, auc_score: 0.4992567778086642\n",
      "Test:- after 1170 epochs, loss: 4130.8505859375, auc_score: 0.5021425760339611\n",
      "Training:- after 1180 epochs, loss: 3796.533203125, auc_score: 0.49652446289480406\n",
      "Test:- after 1180 epochs, loss: 3530.766845703125, auc_score: 0.5015123916176436\n",
      "Training:- after 1190 epochs, loss: 3527.965087890625, auc_score: 0.4890214873244575\n",
      "Test:- after 1190 epochs, loss: 3528.994873046875, auc_score: 0.49166361399281033\n",
      "Training:- after 1200 epochs, loss: 2962.9853515625, auc_score: 0.4997404117846531\n",
      "Test:- after 1200 epochs, loss: 3119.812255859375, auc_score: 0.5088127274739404\n",
      "Training:- after 1210 epochs, loss: 2802.750732421875, auc_score: 0.49898332369151\n",
      "Test:- after 1210 epochs, loss: 2502.59326171875, auc_score: 0.49990518991859123\n",
      "Training:- after 1220 epochs, loss: 2328.23779296875, auc_score: 0.5023615193838147\n",
      "Test:- after 1220 epochs, loss: 2543.07373046875, auc_score: 0.4997832943511234\n",
      "Training:- after 1230 epochs, loss: 2136.4814453125, auc_score: 0.4994721398682279\n",
      "Test:- after 1230 epochs, loss: 1997.65087890625, auc_score: 0.5078258713798459\n",
      "Training:- after 1240 epochs, loss: 2106.358642578125, auc_score: 0.4937865883226329\n",
      "Test:- after 1240 epochs, loss: 1790.5948486328125, auc_score: 0.4937893816687867\n",
      "Training:- after 1250 epochs, loss: 1625.9169921875, auc_score: 0.49344382309935425\n",
      "Test:- after 1250 epochs, loss: 1641.7664794921875, auc_score: 0.4952313628354677\n",
      "Training:- after 1260 epochs, loss: 1535.7886962890625, auc_score: 0.505653088214721\n",
      "Test:- after 1260 epochs, loss: 1633.7427978515625, auc_score: 0.5078768653329404\n",
      "Training:- after 1270 epochs, loss: 1280.3665771484375, auc_score: 0.49240107105147257\n",
      "Test:- after 1270 epochs, loss: 1461.2655029296875, auc_score: 0.4909716082679588\n",
      "Training:- after 1280 epochs, loss: 1197.8360595703125, auc_score: 0.5043191563843816\n",
      "Test:- after 1280 epochs, loss: 1104.8885498046875, auc_score: 0.4984606938709024\n",
      "Training:- after 1290 epochs, loss: 1033.7325439453125, auc_score: 0.49473278424748707\n",
      "Test:- after 1290 epochs, loss: 1065.64404296875, auc_score: 0.4929287732230143\n",
      "Training:- after 1300 epochs, loss: 996.2437744140625, auc_score: 0.5019524487644742\n",
      "Test:- after 1300 epochs, loss: 1206.7003173828125, auc_score: 0.4983155581916731\n",
      "Training:- after 1310 epochs, loss: 868.9581909179688, auc_score: 0.5008769311228316\n",
      "Test:- after 1310 epochs, loss: 885.4772338867188, auc_score: 0.49509531678796537\n",
      "Training:- after 1320 epochs, loss: 789.7421264648438, auc_score: 0.5021661362579624\n",
      "Test:- after 1320 epochs, loss: 752.5537109375, auc_score: 0.5011169926375225\n",
      "Training:- after 1330 epochs, loss: 693.0695190429688, auc_score: 0.49919671535323656\n",
      "Test:- after 1330 epochs, loss: 799.9400024414062, auc_score: 0.49617019993459444\n",
      "Training:- after 1340 epochs, loss: 670.7798461914062, auc_score: 0.5058067480797984\n",
      "Test:- after 1340 epochs, loss: 631.9175415039062, auc_score: 0.5159184071881454\n",
      "Training:- after 1350 epochs, loss: 596.8326416015625, auc_score: 0.5074817622563482\n",
      "Test:- after 1350 epochs, loss: 630.7509765625, auc_score: 0.506617587629148\n",
      "Training:- after 1360 epochs, loss: 583.9068603515625, auc_score: 0.49622938110130443\n",
      "Test:- after 1360 epochs, loss: 615.520263671875, auc_score: 0.49722561062803017\n",
      "Training:- after 1370 epochs, loss: 502.37884521484375, auc_score: 0.5043078469043326\n",
      "Test:- after 1370 epochs, loss: 491.7173156738281, auc_score: 0.5072277400390195\n",
      "Training:- after 1380 epochs, loss: 459.6583251953125, auc_score: 0.5038458548521052\n",
      "Test:- after 1380 epochs, loss: 601.8270263671875, auc_score: 0.5077031582429032\n",
      "Training:- after 1390 epochs, loss: 467.91357421875, auc_score: 0.5022790437642971\n",
      "Test:- after 1390 epochs, loss: 437.7109680175781, auc_score: 0.5006853066289652\n",
      "Training:- after 1400 epochs, loss: 426.83758544921875, auc_score: 0.5048064246387213\n",
      "Test:- after 1400 epochs, loss: 429.330078125, auc_score: 0.5040956655761596\n",
      "Training:- after 1410 epochs, loss: 413.5207214355469, auc_score: 0.5102227820445298\n",
      "Test:- after 1410 epochs, loss: 446.7764587402344, auc_score: 0.5034088574792996\n",
      "Training:- after 1420 epochs, loss: 377.91168212890625, auc_score: 0.4959718676659046\n",
      "Test:- after 1420 epochs, loss: 392.0456237792969, auc_score: 0.5011694196686698\n",
      "Training:- after 1430 epochs, loss: 370.4058532714844, auc_score: 0.49914647461123585\n",
      "Test:- after 1430 epochs, loss: 343.9111328125, auc_score: 0.4972786562763845\n",
      "Training:- after 1440 epochs, loss: 348.4649658203125, auc_score: 0.5052949124322896\n",
      "Test:- after 1440 epochs, loss: 366.1407470703125, auc_score: 0.507648520976408\n",
      "Training:- after 1450 epochs, loss: 360.66943359375, auc_score: 0.49937571602849984\n",
      "Test:- after 1450 epochs, loss: 326.5927429199219, auc_score: 0.49786153357381685\n",
      "Training:- after 1460 epochs, loss: 305.2966003417969, auc_score: 0.49761295172032094\n",
      "Test:- after 1460 epochs, loss: 311.2611083984375, auc_score: 0.49879309958928786\n",
      "Training:- after 1470 epochs, loss: 304.4329528808594, auc_score: 0.4961734620714667\n",
      "Test:- after 1470 epochs, loss: 293.2730407714844, auc_score: 0.4949746833239453\n",
      "Training:- after 1480 epochs, loss: 280.8503723144531, auc_score: 0.49982372790277113\n",
      "Test:- after 1480 epochs, loss: 259.5699462890625, auc_score: 0.5045694828360149\n",
      "Training:- after 1490 epochs, loss: 268.2159729003906, auc_score: 0.5083476794340713\n",
      "Test:- after 1490 epochs, loss: 263.1455383300781, auc_score: 0.5125154436697741\n",
      "Training:- after 1500 epochs, loss: 299.4544982910156, auc_score: 0.5017976413887709\n",
      "Test:- after 1500 epochs, loss: 256.7283020019531, auc_score: 0.5112176127468718\n",
      "Training:- after 1510 epochs, loss: 265.6753845214844, auc_score: 0.5040507086508861\n",
      "Test:- after 1510 epochs, loss: 237.73997497558594, auc_score: 0.5077655888427568\n",
      "Training:- after 1520 epochs, loss: 245.15805053710938, auc_score: 0.5004420541787772\n",
      "Test:- after 1520 epochs, loss: 234.7069549560547, auc_score: 0.5032935117935173\n",
      "Training:- after 1530 epochs, loss: 251.3585662841797, auc_score: 0.49740233385238614\n",
      "Test:- after 1530 epochs, loss: 243.64016723632812, auc_score: 0.49313741819642304\n",
      "Training:- after 1540 epochs, loss: 230.44845581054688, auc_score: 0.5008586860204883\n",
      "Test:- after 1540 epochs, loss: 227.25909423828125, auc_score: 0.49541576982714775\n",
      "Training:- after 1550 epochs, loss: 234.45370483398438, auc_score: 0.497580698538832\n",
      "Test:- after 1550 epochs, loss: 260.56573486328125, auc_score: 0.49209581914244116\n",
      "Training:- after 1560 epochs, loss: 227.18008422851562, auc_score: 0.5015212699153212\n",
      "Test:- after 1560 epochs, loss: 212.98707580566406, auc_score: 0.5092198490947051\n",
      "Training:- after 1570 epochs, loss: 204.54383850097656, auc_score: 0.49942375821612733\n",
      "Test:- after 1570 epochs, loss: 208.18431091308594, auc_score: 0.49081272001323034\n",
      "Training:- after 1580 epochs, loss: 224.0517578125, auc_score: 0.49778601290512137\n",
      "Test:- after 1580 epochs, loss: 208.66160583496094, auc_score: 0.4878994277635402\n",
      "Training:- after 1590 epochs, loss: 266.5998840332031, auc_score: 0.5056784039929887\n",
      "Test:- after 1590 epochs, loss: 252.97950744628906, auc_score: 0.4992801005455022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 1600 epochs, loss: 195.36502075195312, auc_score: 0.5086208872885984\n",
      "Test:- after 1600 epochs, loss: 196.47018432617188, auc_score: 0.5029275328799708\n",
      "Training:- after 1610 epochs, loss: 196.5669403076172, auc_score: 0.49856743479317617\n",
      "Test:- after 1610 epochs, loss: 194.56005859375, auc_score: 0.4898906601857965\n",
      "Training:- after 1620 epochs, loss: 190.29708862304688, auc_score: 0.5116128616548852\n",
      "Test:- after 1620 epochs, loss: 310.39556884765625, auc_score: 0.5130053605201608\n",
      "Training:- after 1630 epochs, loss: 193.91151428222656, auc_score: 0.4980262234474978\n",
      "Test:- after 1630 epochs, loss: 211.28570556640625, auc_score: 0.50366110097698\n",
      "Training:- after 1640 epochs, loss: 179.0573272705078, auc_score: 0.5052255870787493\n",
      "Test:- after 1640 epochs, loss: 191.2914276123047, auc_score: 0.5000185864938766\n",
      "Training:- after 1650 epochs, loss: 210.81704711914062, auc_score: 0.5137371353440054\n",
      "Test:- after 1650 epochs, loss: 198.27923583984375, auc_score: 0.5148447737104475\n",
      "Training:- after 1660 epochs, loss: 197.57733154296875, auc_score: 0.5093715631541026\n",
      "Test:- after 1660 epochs, loss: 168.764404296875, auc_score: 0.5065678713226471\n",
      "Training:- after 1670 epochs, loss: 182.0950927734375, auc_score: 0.510959729634307\n",
      "Test:- after 1670 epochs, loss: 175.22042846679688, auc_score: 0.5127829754057693\n",
      "Training:- after 1680 epochs, loss: 182.42184448242188, auc_score: 0.500114959925754\n",
      "Test:- after 1680 epochs, loss: 164.48426818847656, auc_score: 0.5110752903770518\n",
      "Training:- after 1690 epochs, loss: 168.97869873046875, auc_score: 0.5079866511012987\n",
      "Test:- after 1690 epochs, loss: 167.27706909179688, auc_score: 0.5208721383514069\n",
      "Training:- after 1700 epochs, loss: 170.5239715576172, auc_score: 0.5066696750810997\n",
      "Test:- after 1700 epochs, loss: 172.42958068847656, auc_score: 0.4971337630702314\n",
      "Training:- after 1710 epochs, loss: 171.28797912597656, auc_score: 0.5060203482089235\n",
      "Test:- after 1710 epochs, loss: 187.36729431152344, auc_score: 0.5067379817287211\n",
      "Training:- after 1720 epochs, loss: 157.4924774169922, auc_score: 0.5048921310576853\n",
      "Test:- after 1720 epochs, loss: 165.17269897460938, auc_score: 0.5059836169024873\n",
      "Training:- after 1730 epochs, loss: 149.55467224121094, auc_score: 0.5074594050925182\n",
      "Test:- after 1730 epochs, loss: 163.78273010253906, auc_score: 0.5063827648894013\n",
      "Training:- after 1740 epochs, loss: 159.34788513183594, auc_score: 0.5046538019657368\n",
      "Test:- after 1740 epochs, loss: 156.9304656982422, auc_score: 0.5092218510518979\n",
      "Training:- after 1750 epochs, loss: 153.0084228515625, auc_score: 0.5021171475076379\n",
      "Test:- after 1750 epochs, loss: 166.67210388183594, auc_score: 0.49566551709559536\n",
      "Training:- after 1760 epochs, loss: 141.86070251464844, auc_score: 0.49981849316469584\n",
      "Test:- after 1760 epochs, loss: 180.00010681152344, auc_score: 0.5024411754099971\n",
      "Training:- after 1770 epochs, loss: 141.84466552734375, auc_score: 0.5056745689645897\n",
      "Test:- after 1770 epochs, loss: 147.88575744628906, auc_score: 0.5032324458818745\n",
      "Training:- after 1780 epochs, loss: 148.2747802734375, auc_score: 0.5051601544358545\n",
      "Test:- after 1780 epochs, loss: 140.45834350585938, auc_score: 0.5103322720473308\n",
      "Training:- after 1790 epochs, loss: 139.95541381835938, auc_score: 0.5117089116978255\n",
      "Test:- after 1790 epochs, loss: 141.0685577392578, auc_score: 0.5083616342934024\n",
      "Training:- after 1800 epochs, loss: 141.10861206054688, auc_score: 0.5111587319006308\n",
      "Test:- after 1800 epochs, loss: 132.48233032226562, auc_score: 0.5031310672670051\n",
      "Training:- after 1810 epochs, loss: 128.32142639160156, auc_score: 0.5007542348502192\n",
      "Test:- after 1810 epochs, loss: 130.57737731933594, auc_score: 0.5119969740603546\n",
      "Training:- after 1820 epochs, loss: 130.00672912597656, auc_score: 0.5090557814482803\n",
      "Test:- after 1820 epochs, loss: 124.72510528564453, auc_score: 0.5087704998551379\n",
      "Training:- after 1830 epochs, loss: 166.62374877929688, auc_score: 0.5018935324345071\n",
      "Test:- after 1830 epochs, loss: 125.96830749511719, auc_score: 0.5111389706458364\n",
      "Training:- after 1840 epochs, loss: 128.3096923828125, auc_score: 0.5011156660682538\n",
      "Test:- after 1840 epochs, loss: 120.14591979980469, auc_score: 0.504512713049901\n",
      "Training:- after 1850 epochs, loss: 123.33858489990234, auc_score: 0.500834218359231\n",
      "Test:- after 1850 epochs, loss: 117.24236297607422, auc_score: 0.5090901633025082\n",
      "Training:- after 1860 epochs, loss: 147.8992919921875, auc_score: 0.512033374532276\n",
      "Test:- after 1860 epochs, loss: 148.20643615722656, auc_score: 0.5126732407956598\n",
      "Training:- after 1870 epochs, loss: 132.00791931152344, auc_score: 0.5056605969986859\n",
      "Test:- after 1870 epochs, loss: 142.6397705078125, auc_score: 0.5050102864539617\n",
      "Training:- after 1880 epochs, loss: 119.51985168457031, auc_score: 0.5098157406925576\n",
      "Test:- after 1880 epochs, loss: 110.34474182128906, auc_score: 0.5103685404239922\n",
      "Training:- after 1890 epochs, loss: 114.14557647705078, auc_score: 0.5127846571991829\n",
      "Test:- after 1890 epochs, loss: 145.0637664794922, auc_score: 0.5125762422393072\n",
      "Training:- after 1900 epochs, loss: 108.64816284179688, auc_score: 0.49997135843951296\n",
      "Test:- after 1900 epochs, loss: 108.90699768066406, auc_score: 0.502261117390542\n",
      "Training:- after 1910 epochs, loss: 108.07247924804688, auc_score: 0.49877694551816343\n",
      "Test:- after 1910 epochs, loss: 108.37779235839844, auc_score: 0.5037946290348452\n",
      "Training:- after 1920 epochs, loss: 104.52606201171875, auc_score: 0.5032719563723941\n",
      "Test:- after 1920 epochs, loss: 101.56411743164062, auc_score: 0.5075743055633272\n",
      "Training:- after 1930 epochs, loss: 106.53749084472656, auc_score: 0.4983501848520593\n",
      "Test:- after 1930 epochs, loss: 104.97955322265625, auc_score: 0.4943575986709988\n",
      "Training:- after 1940 epochs, loss: 107.6659927368164, auc_score: 0.49742578203188026\n",
      "Test:- after 1940 epochs, loss: 102.87052154541016, auc_score: 0.493968793093372\n",
      "Training:- after 1950 epochs, loss: 108.23827362060547, auc_score: 0.5062020913138753\n",
      "Test:- after 1950 epochs, loss: 100.15220642089844, auc_score: 0.5076552946793947\n",
      "Training:- after 1960 epochs, loss: 104.10639953613281, auc_score: 0.5061086219330886\n",
      "Test:- after 1960 epochs, loss: 101.81786346435547, auc_score: 0.506119840141853\n",
      "Training:- after 1970 epochs, loss: 100.61042785644531, auc_score: 0.5034634481727662\n",
      "Test:- after 1970 epochs, loss: 127.52140808105469, auc_score: 0.4991980358437379\n",
      "Training:- after 1980 epochs, loss: 99.61730194091797, auc_score: 0.5140795138093054\n",
      "Test:- after 1980 epochs, loss: 97.4294662475586, auc_score: 0.5069226467366232\n",
      "Training:- after 1990 epochs, loss: 95.93257141113281, auc_score: 0.5093789904111873\n",
      "Test:- after 1990 epochs, loss: 92.21640014648438, auc_score: 0.5029012836151616\n",
      "Training:- after 2000 epochs, loss: 114.26287841796875, auc_score: 0.5041841172983027\n",
      "Test:- after 2000 epochs, loss: 98.35931396484375, auc_score: 0.5157788266292637\n",
      "Training:- after 2010 epochs, loss: 99.24632263183594, auc_score: 0.5002321207804503\n",
      "Test:- after 2010 epochs, loss: 91.73683166503906, auc_score: 0.504015257773749\n",
      "Training:- after 2020 epochs, loss: 92.60273742675781, auc_score: 0.5045940169391585\n",
      "Test:- after 2020 epochs, loss: 89.30392456054688, auc_score: 0.5035100899885976\n",
      "Training:- after 2030 epochs, loss: 84.89860534667969, auc_score: 0.5054760530892161\n",
      "Test:- after 2030 epochs, loss: 84.47238159179688, auc_score: 0.49636906516059803\n",
      "Training:- after 2040 epochs, loss: 83.52828979492188, auc_score: 0.5001777072275642\n",
      "Test:- after 2040 epochs, loss: 86.51561737060547, auc_score: 0.5037648110637356\n",
      "Training:- after 2050 epochs, loss: 82.61927032470703, auc_score: 0.49179026909307216\n",
      "Test:- after 2050 epochs, loss: 83.35911560058594, auc_score: 0.47977063290446686\n",
      "Training:- after 2060 epochs, loss: 80.71891784667969, auc_score: 0.4989570017884316\n",
      "Test:- after 2060 epochs, loss: 85.39599609375, auc_score: 0.4990443794119219\n",
      "Training:- after 2070 epochs, loss: 76.26493835449219, auc_score: 0.49705892373565524\n",
      "Test:- after 2070 epochs, loss: 81.45751953125, auc_score: 0.49495377468407004\n",
      "Training:- after 2080 epochs, loss: 90.37503051757812, auc_score: 0.5057074240004618\n",
      "Test:- after 2080 epochs, loss: 82.78568267822266, auc_score: 0.503381041465383\n",
      "Training:- after 2090 epochs, loss: 88.493896484375, auc_score: 0.5007276772711354\n",
      "Test:- after 2090 epochs, loss: 73.34312438964844, auc_score: 0.5015385445149482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 2100 epochs, loss: 73.16285705566406, auc_score: 0.5027265649931818\n",
      "Test:- after 2100 epochs, loss: 70.72850799560547, auc_score: 0.513392170357853\n",
      "Training:- after 2110 epochs, loss: 77.56034088134766, auc_score: 0.5072184409212025\n",
      "Test:- after 2110 epochs, loss: 72.73726654052734, auc_score: 0.5136027613331293\n",
      "Training:- after 2120 epochs, loss: 70.17839050292969, auc_score: 0.4924109311537702\n",
      "Test:- after 2120 epochs, loss: 71.16422271728516, auc_score: 0.4947167759038961\n",
      "Training:- after 2130 epochs, loss: 69.99182891845703, auc_score: 0.5017767298429575\n",
      "Test:- after 2130 epochs, loss: 92.24687194824219, auc_score: 0.4986774212801833\n",
      "Training:- after 2140 epochs, loss: 68.07141876220703, auc_score: 0.5120238198589575\n",
      "Test:- after 2140 epochs, loss: 66.11894989013672, auc_score: 0.5073731617121334\n",
      "Training:- after 2150 epochs, loss: 63.68440246582031, auc_score: 0.5011802461418208\n",
      "Test:- after 2150 epochs, loss: 70.05059051513672, auc_score: 0.5023175172497834\n",
      "Training:- after 2160 epochs, loss: 65.31095886230469, auc_score: 0.49294247147223336\n",
      "Test:- after 2160 epochs, loss: 61.7247428894043, auc_score: 0.5043477474251226\n",
      "Training:- after 2170 epochs, loss: 60.381568908691406, auc_score: 0.5030696326772282\n",
      "Test:- after 2170 epochs, loss: 84.72146606445312, auc_score: 0.501548557409542\n",
      "Training:- after 2180 epochs, loss: 61.28904724121094, auc_score: 0.5011381757981629\n",
      "Test:- after 2180 epochs, loss: 59.2800407409668, auc_score: 0.5014255551700856\n",
      "Training:- after 2190 epochs, loss: 63.49447250366211, auc_score: 0.5097270438003509\n",
      "Test:- after 2190 epochs, loss: 59.08700942993164, auc_score: 0.5120813826685219\n",
      "Training:- after 2200 epochs, loss: 77.92890930175781, auc_score: 0.5001672097512837\n",
      "Test:- after 2200 epochs, loss: 58.45592498779297, auc_score: 0.5049536845338237\n",
      "Training:- after 2210 epochs, loss: 61.34061050415039, auc_score: 0.5004985279673733\n",
      "Test:- after 2210 epochs, loss: 78.66365814208984, auc_score: 0.4969253294836069\n",
      "Training:- after 2220 epochs, loss: 80.58190155029297, auc_score: 0.5175009481333755\n",
      "Test:- after 2220 epochs, loss: 65.17333984375, auc_score: 0.5133739071614112\n",
      "Training:- after 2230 epochs, loss: 63.210289001464844, auc_score: 0.5141611003504919\n",
      "Test:- after 2230 epochs, loss: 80.64126586914062, auc_score: 0.5211746452743241\n",
      "Training:- after 2240 epochs, loss: 61.72703552246094, auc_score: 0.4998982679094879\n",
      "Test:- after 2240 epochs, loss: 74.8720474243164, auc_score: 0.5078203504544194\n",
      "Training:- after 2250 epochs, loss: 55.12882995605469, auc_score: 0.4880944923650398\n",
      "Test:- after 2250 epochs, loss: 53.63639450073242, auc_score: 0.48537249149168193\n",
      "Training:- after 2260 epochs, loss: 52.125709533691406, auc_score: 0.4872970640988127\n",
      "Test:- after 2260 epochs, loss: 51.7034912109375, auc_score: 0.5003602932307734\n",
      "Training:- after 2270 epochs, loss: 52.92681121826172, auc_score: 0.5071489689380064\n",
      "Test:- after 2270 epochs, loss: 58.758785247802734, auc_score: 0.49997959806668135\n",
      "Training:- after 2280 epochs, loss: 51.430389404296875, auc_score: 0.5113452284976081\n",
      "Test:- after 2280 epochs, loss: 51.205848693847656, auc_score: 0.5124134433290682\n",
      "Training:- after 2290 epochs, loss: 46.86052703857422, auc_score: 0.5011460549160018\n",
      "Test:- after 2290 epochs, loss: 49.882781982421875, auc_score: 0.4960799533208242\n",
      "Training:- after 2300 epochs, loss: 48.802677154541016, auc_score: 0.505265407122211\n",
      "Test:- after 2300 epochs, loss: 47.581905364990234, auc_score: 0.5052929447795547\n",
      "Training:- after 2310 epochs, loss: 91.22509765625, auc_score: 0.5002417710301841\n",
      "Test:- after 2310 epochs, loss: 48.670833587646484, auc_score: 0.5022367674981628\n",
      "Training:- after 2320 epochs, loss: 45.47963333129883, auc_score: 0.4981440865810718\n",
      "Test:- after 2320 epochs, loss: 44.39531326293945, auc_score: 0.48863883386615237\n",
      "Training:- after 2330 epochs, loss: 48.943946838378906, auc_score: 0.4970486144439937\n",
      "Test:- after 2330 epochs, loss: 43.992958068847656, auc_score: 0.5038072966987602\n",
      "Training:- after 2340 epochs, loss: 50.17818832397461, auc_score: 0.4897451440539654\n",
      "Test:- after 2340 epochs, loss: 45.269901275634766, auc_score: 0.4938460426528793\n",
      "Training:- after 2350 epochs, loss: 42.63799285888672, auc_score: 0.4898131169913352\n",
      "Test:- after 2350 epochs, loss: 41.095428466796875, auc_score: 0.4850210298764134\n",
      "Training:- after 2360 epochs, loss: 50.9910774230957, auc_score: 0.5082450333322501\n",
      "Test:- after 2360 epochs, loss: 43.81875228881836, auc_score: 0.5110849457792899\n",
      "Training:- after 2370 epochs, loss: 42.05564498901367, auc_score: 0.5116344572745448\n",
      "Test:- after 2370 epochs, loss: 39.348609924316406, auc_score: 0.510665510878337\n",
      "Training:- after 2380 epochs, loss: 40.09918212890625, auc_score: 0.5034819908877981\n",
      "Test:- after 2380 epochs, loss: 41.64094543457031, auc_score: 0.4987000085798165\n",
      "Training:- after 2390 epochs, loss: 37.245304107666016, auc_score: 0.4950604844114496\n",
      "Test:- after 2390 epochs, loss: 39.33843994140625, auc_score: 0.4932770671451469\n",
      "Training:- after 2400 epochs, loss: 36.083763122558594, auc_score: 0.5058154801627267\n",
      "Test:- after 2400 epochs, loss: 39.719146728515625, auc_score: 0.5050682654968273\n",
      "Training:- after 2410 epochs, loss: 36.64430618286133, auc_score: 0.5019893593668713\n",
      "Test:- after 2410 epochs, loss: 35.08489227294922, auc_score: 0.5043213023166748\n",
      "Training:- after 2420 epochs, loss: 33.989810943603516, auc_score: 0.4854018848015389\n",
      "Test:- after 2420 epochs, loss: 35.730159759521484, auc_score: 0.4913308849769899\n",
      "Training:- after 2430 epochs, loss: 32.969364166259766, auc_score: 0.49160587280266205\n",
      "Test:- after 2430 epochs, loss: 38.5284538269043, auc_score: 0.5054687626288061\n",
      "Training:- after 2440 epochs, loss: 32.81272888183594, auc_score: 0.5005356390229976\n",
      "Test:- after 2440 epochs, loss: 31.793254852294922, auc_score: 0.4964990680329714\n",
      "Training:- after 2450 epochs, loss: 30.444671630859375, auc_score: 0.5019504968684898\n",
      "Test:- after 2450 epochs, loss: 33.481285095214844, auc_score: 0.49913846829136066\n",
      "Training:- after 2460 epochs, loss: 29.75670623779297, auc_score: 0.5036377584799718\n",
      "Test:- after 2460 epochs, loss: 33.57929229736328, auc_score: 0.5041030827653868\n",
      "Training:- after 2470 epochs, loss: 30.43564224243164, auc_score: 0.5019409082586179\n",
      "Test:- after 2470 epochs, loss: 32.24772262573242, auc_score: 0.5012849736326073\n",
      "Training:- after 2480 epochs, loss: 29.723730087280273, auc_score: 0.49721916857828974\n",
      "Test:- after 2480 epochs, loss: 29.8907413482666, auc_score: 0.4943125266564952\n",
      "Training:- after 2490 epochs, loss: 27.84456443786621, auc_score: 0.5017801872158936\n",
      "Test:- after 2490 epochs, loss: 35.21826171875, auc_score: 0.502499552357398\n",
      "Training:- after 2500 epochs, loss: 27.279321670532227, auc_score: 0.49715637022323905\n",
      "Test:- after 2500 epochs, loss: 26.61185646057129, auc_score: 0.49850897709935055\n",
      "Training:- after 2510 epochs, loss: 27.319353103637695, auc_score: 0.513047365400741\n",
      "Test:- after 2510 epochs, loss: 31.281023025512695, auc_score: 0.5142186957932787\n",
      "Training:- after 2520 epochs, loss: 26.203065872192383, auc_score: 0.5018215124394857\n",
      "Test:- after 2520 epochs, loss: 26.683677673339844, auc_score: 0.5049661377023251\n",
      "Training:- after 2530 epochs, loss: 25.589736938476562, auc_score: 0.49108934085067235\n",
      "Test:- after 2530 epochs, loss: 25.891897201538086, auc_score: 0.4968036111080025\n",
      "Training:- after 2540 epochs, loss: 24.980920791625977, auc_score: 0.49384128415244744\n",
      "Test:- after 2540 epochs, loss: 31.865989685058594, auc_score: 0.49061210462899757\n",
      "Training:- after 2550 epochs, loss: 25.834884643554688, auc_score: 0.5020544413650293\n",
      "Test:- after 2550 epochs, loss: 30.594982147216797, auc_score: 0.508297972676393\n",
      "Training:- after 2560 epochs, loss: 29.447925567626953, auc_score: 0.5021027782960743\n",
      "Test:- after 2560 epochs, loss: 33.10904312133789, auc_score: 0.4967548367161436\n",
      "Training:- after 2570 epochs, loss: 22.69529151916504, auc_score: 0.5026306087457297\n",
      "Test:- after 2570 epochs, loss: 22.8801326751709, auc_score: 0.49704091453383614\n",
      "Training:- after 2580 epochs, loss: 23.212087631225586, auc_score: 0.49768762153682733\n",
      "Test:- after 2580 epochs, loss: 29.364709854125977, auc_score: 0.49981222947154547\n",
      "Training:- after 2590 epochs, loss: 21.780086517333984, auc_score: 0.5088302225922768\n",
      "Test:- after 2590 epochs, loss: 23.003955841064453, auc_score: 0.5107074649377714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 2600 epochs, loss: 28.883373260498047, auc_score: 0.5044606772531927\n",
      "Test:- after 2600 epochs, loss: 21.343685150146484, auc_score: 0.5017702306478508\n",
      "Training:- after 2610 epochs, loss: 25.777231216430664, auc_score: 0.5018384825959825\n",
      "Test:- after 2610 epochs, loss: 25.76521110534668, auc_score: 0.5020687647426738\n",
      "Training:- after 2620 epochs, loss: 23.325000762939453, auc_score: 0.5242352120937369\n",
      "Test:- after 2620 epochs, loss: 26.18640899658203, auc_score: 0.5234942297625133\n",
      "Training:- after 2630 epochs, loss: 20.133329391479492, auc_score: 0.5179609083457845\n",
      "Test:- after 2630 epochs, loss: 25.420957565307617, auc_score: 0.5149587422735021\n",
      "Training:- after 2640 epochs, loss: 20.66240119934082, auc_score: 0.5057281580472183\n",
      "Test:- after 2640 epochs, loss: 22.515050888061523, auc_score: 0.5096351868223966\n",
      "Training:- after 2650 epochs, loss: 18.06232261657715, auc_score: 0.5040071242224627\n",
      "Test:- after 2650 epochs, loss: 19.724681854248047, auc_score: 0.5125891243986357\n",
      "Training:- after 2660 epochs, loss: 20.698850631713867, auc_score: 0.5140174599806783\n",
      "Test:- after 2660 epochs, loss: 17.21543312072754, auc_score: 0.5068751033619203\n",
      "Training:- after 2670 epochs, loss: 16.823671340942383, auc_score: 0.5122491731168338\n",
      "Test:- after 2670 epochs, loss: 17.970121383666992, auc_score: 0.5075317732988649\n",
      "Training:- after 2680 epochs, loss: 17.147729873657227, auc_score: 0.5064650211419038\n",
      "Test:- after 2680 epochs, loss: 17.09163475036621, auc_score: 0.5072500973000934\n",
      "Training:- after 2690 epochs, loss: 16.396501541137695, auc_score: 0.5064572833109395\n",
      "Test:- after 2690 epochs, loss: 21.30449676513672, auc_score: 0.5093369946767834\n",
      "Training:- after 2700 epochs, loss: 15.892183303833008, auc_score: 0.5099811669443981\n",
      "Test:- after 2700 epochs, loss: 16.119964599609375, auc_score: 0.5153111271516377\n",
      "Training:- after 2710 epochs, loss: 15.201868057250977, auc_score: 0.5141625024347374\n",
      "Test:- after 2710 epochs, loss: 18.2127685546875, auc_score: 0.5207606131708888\n",
      "Training:- after 2720 epochs, loss: 14.323823928833008, auc_score: 0.5066429066600481\n",
      "Test:- after 2720 epochs, loss: 17.17191505432129, auc_score: 0.5096081697261794\n",
      "Training:- after 2730 epochs, loss: 19.580272674560547, auc_score: 0.498305863416682\n",
      "Test:- after 2730 epochs, loss: 13.515942573547363, auc_score: 0.4989015192492536\n",
      "Training:- after 2740 epochs, loss: 14.12972640991211, auc_score: 0.49605268603391456\n",
      "Test:- after 2740 epochs, loss: 14.126547813415527, auc_score: 0.5023191119765535\n",
      "Training:- after 2750 epochs, loss: 13.826688766479492, auc_score: 0.5052092353986211\n",
      "Test:- after 2750 epochs, loss: 13.65857982635498, auc_score: 0.5067525736340994\n",
      "Training:- after 2760 epochs, loss: 13.219072341918945, auc_score: 0.4965559257404695\n",
      "Test:- after 2760 epochs, loss: 13.103282928466797, auc_score: 0.5009050680603273\n",
      "Training:- after 2770 epochs, loss: 12.596957206726074, auc_score: 0.49411685153735974\n",
      "Test:- after 2770 epochs, loss: 13.466068267822266, auc_score: 0.4922938543644532\n",
      "Training:- after 2780 epochs, loss: 12.605405807495117, auc_score: 0.5082458094206576\n",
      "Test:- after 2780 epochs, loss: 12.59196662902832, auc_score: 0.5146882417966384\n",
      "Training:- after 2790 epochs, loss: 13.12105655670166, auc_score: 0.5076107057240316\n",
      "Test:- after 2790 epochs, loss: 12.275809288024902, auc_score: 0.5062888687449718\n",
      "Training:- after 2800 epochs, loss: 11.604452133178711, auc_score: 0.5022286292829742\n",
      "Test:- after 2800 epochs, loss: 11.736336708068848, auc_score: 0.493590308164628\n",
      "Training:- after 2810 epochs, loss: 13.376424789428711, auc_score: 0.4960935394107938\n",
      "Test:- after 2810 epochs, loss: 11.912972450256348, auc_score: 0.49847555622701945\n",
      "Training:- after 2820 epochs, loss: 10.635777473449707, auc_score: 0.49900327254734334\n",
      "Test:- after 2820 epochs, loss: 12.155157089233398, auc_score: 0.49750951551392475\n",
      "Training:- after 2830 epochs, loss: 10.33535099029541, auc_score: 0.49540122966775635\n",
      "Test:- after 2830 epochs, loss: 10.914042472839355, auc_score: 0.49679310083273964\n",
      "Training:- after 2840 epochs, loss: 10.030517578125, auc_score: 0.48912629843986\n",
      "Test:- after 2840 epochs, loss: 10.006318092346191, auc_score: 0.49348546653685027\n",
      "Training:- after 2850 epochs, loss: 10.771347045898438, auc_score: 0.4976691751897339\n",
      "Test:- after 2850 epochs, loss: 10.313647270202637, auc_score: 0.497671804608978\n",
      "Training:- after 2860 epochs, loss: 10.358449935913086, auc_score: 0.5042893356523444\n",
      "Test:- after 2860 epochs, loss: 9.082235336303711, auc_score: 0.48729205757678623\n",
      "Training:- after 2870 epochs, loss: 9.003362655639648, auc_score: 0.5026688573190007\n",
      "Test:- after 2870 epochs, loss: 9.864972114562988, auc_score: 0.5039569056953817\n",
      "Training:- after 2880 epochs, loss: 9.020483016967773, auc_score: 0.5106094816483858\n",
      "Test:- after 2880 epochs, loss: 9.968537330627441, auc_score: 0.5149117149312433\n",
      "Training:- after 2890 epochs, loss: 8.473176956176758, auc_score: 0.5083818667022747\n",
      "Test:- after 2890 epochs, loss: 8.20952320098877, auc_score: 0.5092602830344697\n",
      "Training:- after 2900 epochs, loss: 8.339347839355469, auc_score: 0.49945607056396846\n",
      "Test:- after 2900 epochs, loss: 7.634488105773926, auc_score: 0.5040260851291885\n",
      "Training:- after 2910 epochs, loss: 7.84151554107666, auc_score: 0.4990053129949755\n",
      "Test:- after 2910 epochs, loss: 8.12424087524414, auc_score: 0.5039173670408212\n",
      "Training:- after 2920 epochs, loss: 7.89785623550415, auc_score: 0.5192372444035223\n",
      "Test:- after 2920 epochs, loss: 8.133668899536133, auc_score: 0.5151294029069413\n",
      "Training:- after 2930 epochs, loss: 7.61256217956543, auc_score: 0.4958071126256598\n",
      "Test:- after 2930 epochs, loss: 8.89808464050293, auc_score: 0.48428565877447893\n",
      "Training:- after 2940 epochs, loss: 7.1116414070129395, auc_score: 0.5157024692142158\n",
      "Test:- after 2940 epochs, loss: 6.970008850097656, auc_score: 0.5116276937826173\n",
      "Training:- after 2950 epochs, loss: 7.410017013549805, auc_score: 0.5247697920588159\n",
      "Test:- after 2950 epochs, loss: 6.733403205871582, auc_score: 0.5297208948375617\n",
      "Training:- after 2960 epochs, loss: 8.777521133422852, auc_score: 0.5049503124584466\n",
      "Test:- after 2960 epochs, loss: 6.767443656921387, auc_score: 0.5016394381836653\n",
      "Training:- after 2970 epochs, loss: 6.484228134155273, auc_score: 0.5224460205109659\n",
      "Test:- after 2970 epochs, loss: 6.684013843536377, auc_score: 0.5201599078851001\n",
      "Training:- after 2980 epochs, loss: 6.556936264038086, auc_score: 0.5192768809125632\n",
      "Test:- after 2980 epochs, loss: 6.312705993652344, auc_score: 0.5207666905409388\n",
      "Training:- after 2990 epochs, loss: 6.410547256469727, auc_score: 0.5120494840063332\n",
      "Test:- after 2990 epochs, loss: 6.582226753234863, auc_score: 0.5091419872595941\n",
      "Training:- after 3000 epochs, loss: 6.907068729400635, auc_score: 0.5091878812132974\n",
      "Test:- after 3000 epochs, loss: 6.649954795837402, auc_score: 0.5064538778905588\n",
      "E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op1)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        _ = sess.run(train_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "        if epoch%10 == 0:\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_tr})\n",
    "            print('Training:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_ts, y1_nn:y_ts.reshape(y_ts.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_ts})\n",
    "            print('Test:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path2 = saver2.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')\n",
    "    print(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt\n",
      "Training:- after 10 epochs, loss: 5.76368522644043, auc_score: 0.5052466397135569\n",
      "Test:- after 10 epochs, loss: 7.012258052825928, auc_score: 0.5131985524979079\n",
      "Training:- after 20 epochs, loss: 5.201040267944336, auc_score: 0.5043132394523275\n",
      "Test:- after 20 epochs, loss: 5.558500289916992, auc_score: 0.5082231510806217\n",
      "Training:- after 30 epochs, loss: 6.306885719299316, auc_score: 0.5034599028418247\n",
      "Test:- after 30 epochs, loss: 5.514899730682373, auc_score: 0.49970173013865726\n",
      "Training:- after 40 epochs, loss: 5.267034530639648, auc_score: 0.5152563226630891\n",
      "Test:- after 40 epochs, loss: 5.807692527770996, auc_score: 0.5132979664591346\n",
      "Training:- after 50 epochs, loss: 5.426302909851074, auc_score: 0.5207203218447728\n",
      "Test:- after 50 epochs, loss: 5.3357672691345215, auc_score: 0.5138592170233508\n",
      "Training:- after 60 epochs, loss: 5.849006652832031, auc_score: 0.49786889645586074\n",
      "Test:- after 60 epochs, loss: 4.969325065612793, auc_score: 0.4897803100671091\n",
      "Training:- after 70 epochs, loss: 4.7794342041015625, auc_score: 0.5020870152123172\n",
      "Test:- after 70 epochs, loss: 4.509517669677734, auc_score: 0.4933404023560923\n",
      "Training:- after 80 epochs, loss: 5.030663967132568, auc_score: 0.49209340532677937\n",
      "Test:- after 80 epochs, loss: 5.4619975090026855, auc_score: 0.4920407342333436\n",
      "Training:- after 90 epochs, loss: 4.410909175872803, auc_score: 0.5110421367870758\n",
      "Test:- after 90 epochs, loss: 5.356788158416748, auc_score: 0.5226668028246249\n",
      "Training:- after 100 epochs, loss: 4.529910087585449, auc_score: 0.5114683451679312\n",
      "Test:- after 100 epochs, loss: 3.960259199142456, auc_score: 0.5107239935191299\n",
      "Training:- after 110 epochs, loss: 4.7578887939453125, auc_score: 0.49689960843797076\n",
      "Test:- after 110 epochs, loss: 3.7635176181793213, auc_score: 0.4985943245135306\n",
      "Training:- after 120 epochs, loss: 4.636947154998779, auc_score: 0.5152833464492834\n",
      "Test:- after 120 epochs, loss: 4.029584884643555, auc_score: 0.521603465126776\n",
      "Training:- after 130 epochs, loss: 3.8619329929351807, auc_score: 0.4931963529049114\n",
      "Test:- after 130 epochs, loss: 3.8454065322875977, auc_score: 0.48980449520214175\n",
      "Training:- after 140 epochs, loss: 4.275277614593506, auc_score: 0.48890472806879803\n",
      "Test:- after 140 epochs, loss: 3.5438930988311768, auc_score: 0.49559196382053006\n",
      "Training:- after 150 epochs, loss: 3.3367693424224854, auc_score: 0.5063838503482299\n",
      "Test:- after 150 epochs, loss: 3.897038221359253, auc_score: 0.5054147284363719\n",
      "Training:- after 160 epochs, loss: 4.245073318481445, auc_score: 0.508148770963236\n",
      "Test:- after 160 epochs, loss: 3.1834771633148193, auc_score: 0.5082110927080263\n",
      "Training:- after 170 epochs, loss: 3.9146337509155273, auc_score: 0.5072185229427846\n",
      "Test:- after 170 epochs, loss: 3.144716739654541, auc_score: 0.5030126875591416\n",
      "Training:- after 180 epochs, loss: 3.1130785942077637, auc_score: 0.5016141319010631\n",
      "Test:- after 180 epochs, loss: 3.2028326988220215, auc_score: 0.49701622890950536\n",
      "Training:- after 190 epochs, loss: 3.081904649734497, auc_score: 0.5003153038237457\n",
      "Test:- after 190 epochs, loss: 3.4762814044952393, auc_score: 0.49950135411887153\n",
      "Training:- after 200 epochs, loss: 2.828230619430542, auc_score: 0.5147345708140825\n",
      "Test:- after 200 epochs, loss: 2.683504819869995, auc_score: 0.5116944205079997\n",
      "Training:- after 210 epochs, loss: 3.1831369400024414, auc_score: 0.4856477757095004\n",
      "Test:- after 210 epochs, loss: 2.784836530685425, auc_score: 0.48741898912352816\n",
      "Training:- after 220 epochs, loss: 2.626509189605713, auc_score: 0.518154673598404\n",
      "Test:- after 220 epochs, loss: 2.6180248260498047, auc_score: 0.5253294338688881\n",
      "Training:- after 230 epochs, loss: 2.519076108932495, auc_score: 0.5157209011160124\n",
      "Test:- after 230 epochs, loss: 2.5677497386932373, auc_score: 0.5097802603290422\n",
      "Training:- after 240 epochs, loss: 2.526763439178467, auc_score: 0.511351252582103\n",
      "Test:- after 240 epochs, loss: 2.377291440963745, auc_score: 0.5076496121052507\n",
      "Training:- after 250 epochs, loss: 2.500796318054199, auc_score: 0.5195508997814551\n",
      "Test:- after 250 epochs, loss: 2.3775670528411865, auc_score: 0.5247774594541497\n",
      "Training:- after 260 epochs, loss: 2.3904547691345215, auc_score: 0.5154928738951964\n",
      "Test:- after 260 epochs, loss: 2.2429540157318115, auc_score: 0.5118934194050582\n",
      "Training:- after 270 epochs, loss: 2.4779341220855713, auc_score: 0.5282908158203444\n",
      "Test:- after 270 epochs, loss: 2.7909698486328125, auc_score: 0.5251522730918302\n",
      "Training:- after 280 epochs, loss: 2.114945411682129, auc_score: 0.5095818907309375\n",
      "Test:- after 280 epochs, loss: 2.1332192420959473, auc_score: 0.514061927623652\n",
      "Training:- after 290 epochs, loss: 1.9747148752212524, auc_score: 0.5369109396849052\n",
      "Test:- after 290 epochs, loss: 1.9924941062927246, auc_score: 0.5378409979694434\n",
      "Training:- after 300 epochs, loss: 1.9341130256652832, auc_score: 0.5354900376700193\n",
      "Test:- after 300 epochs, loss: 1.906803846359253, auc_score: 0.5330583315614147\n",
      "Training:- after 310 epochs, loss: 2.0233688354492188, auc_score: 0.5183699755022114\n",
      "Test:- after 310 epochs, loss: 1.7952617406845093, auc_score: 0.5133520255206021\n",
      "Training:- after 320 epochs, loss: 1.8332465887069702, auc_score: 0.5119200897662399\n",
      "Test:- after 320 epochs, loss: 1.7926995754241943, auc_score: 0.5175571956683117\n",
      "Training:- after 330 epochs, loss: 2.0947489738464355, auc_score: 0.5277643882464578\n",
      "Test:- after 330 epochs, loss: 1.7901337146759033, auc_score: 0.5334817050955406\n",
      "Training:- after 340 epochs, loss: 1.5822750329971313, auc_score: 0.5198590762364337\n",
      "Test:- after 340 epochs, loss: 1.609542727470398, auc_score: 0.5229251982994555\n",
      "Training:- after 350 epochs, loss: 1.7328063249588013, auc_score: 0.5231824219497986\n",
      "Test:- after 350 epochs, loss: 2.3103387355804443, auc_score: 0.5315037713889231\n",
      "Training:- after 360 epochs, loss: 2.288123607635498, auc_score: 0.5230670248064677\n",
      "Test:- after 360 epochs, loss: 1.6292445659637451, auc_score: 0.5226299375911605\n",
      "Training:- after 370 epochs, loss: 1.485128402709961, auc_score: 0.5417614333620727\n",
      "Test:- after 370 epochs, loss: 1.8084663152694702, auc_score: 0.538347881717903\n",
      "Training:- after 380 epochs, loss: 1.756147027015686, auc_score: 0.5313560786963737\n",
      "Test:- after 380 epochs, loss: 1.4976840019226074, auc_score: 0.5204084085932459\n",
      "Training:- after 390 epochs, loss: 2.3970236778259277, auc_score: 0.5241916566548475\n",
      "Test:- after 390 epochs, loss: 1.3916420936584473, auc_score: 0.5195860611554401\n",
      "Training:- after 400 epochs, loss: 1.363364338874817, auc_score: 0.5352049866509875\n",
      "Test:- after 400 epochs, loss: 2.025676965713501, auc_score: 0.5344054124964406\n",
      "Training:- after 410 epochs, loss: 1.2976984977722168, auc_score: 0.5353850853666824\n",
      "Test:- after 410 epochs, loss: 1.3408881425857544, auc_score: 0.5366325494613989\n",
      "Training:- after 420 epochs, loss: 1.170802116394043, auc_score: 0.519031400112512\n",
      "Test:- after 420 epochs, loss: 1.2761350870132446, auc_score: 0.5177553117146825\n",
      "Training:- after 430 epochs, loss: 1.1735308170318604, auc_score: 0.5187047023136255\n",
      "Test:- after 430 epochs, loss: 1.13435697555542, auc_score: 0.5274942894481934\n",
      "Training:- after 440 epochs, loss: 1.0390348434448242, auc_score: 0.5206973365084161\n",
      "Test:- after 440 epochs, loss: 1.0868701934814453, auc_score: 0.5337778237854897\n",
      "Training:- after 450 epochs, loss: 1.057582974433899, auc_score: 0.5192505448610092\n",
      "Test:- after 450 epochs, loss: 0.9921814203262329, auc_score: 0.5170477068885979\n",
      "Training:- after 460 epochs, loss: 1.1067899465560913, auc_score: 0.5284651635270169\n",
      "Test:- after 460 epochs, loss: 1.189229130744934, auc_score: 0.5265675791115041\n",
      "Training:- after 470 epochs, loss: 1.1256920099258423, auc_score: 0.523349913285428\n",
      "Test:- after 470 epochs, loss: 1.177632212638855, auc_score: 0.516032285600954\n",
      "Training:- after 480 epochs, loss: 1.033695101737976, auc_score: 0.5354547771954218\n",
      "Test:- after 480 epochs, loss: 0.9788886904716492, auc_score: 0.5333898979499212\n",
      "Training:- after 490 epochs, loss: 0.9243079423904419, auc_score: 0.5277156911723986\n",
      "Test:- after 490 epochs, loss: 0.9602159261703491, auc_score: 0.5261496581129627\n",
      "Training:- after 500 epochs, loss: 0.836681067943573, auc_score: 0.5151592094067337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:- after 500 epochs, loss: 0.8875970244407654, auc_score: 0.5192915620612947\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, path2)\n",
    "    for epoch in range(1, 500+1):\n",
    "        _ = sess.run(train_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "        if epoch%10 == 0:\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_tr})\n",
    "            print('Training:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_ts, y1_nn:y_ts.reshape(y_ts.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_ts})\n",
    "            print('Test:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path2 = saver2.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt\n",
      "Training:- after 1 epochs, loss: 0.8893715143203735, auc_score: 0.5047389988416999\n",
      "Test:- after 1 epochs, loss: 0.8591914772987366, auc_score: 0.5094953544645511\n",
      "Training:- after 2 epochs, loss: 0.9021521210670471, auc_score: 0.5026573436259898\n",
      "Test:- after 2 epochs, loss: 0.8467817902565002, auc_score: 0.5010759338632925\n",
      "Training:- after 3 epochs, loss: 0.8482208847999573, auc_score: 0.516933706264063\n",
      "Test:- after 3 epochs, loss: 0.9382467269897461, auc_score: 0.5176343052151607\n",
      "Training:- after 4 epochs, loss: 0.8169036507606506, auc_score: 0.5315636812570281\n",
      "Test:- after 4 epochs, loss: 0.7853375673294067, auc_score: 0.5290705323092266\n",
      "Training:- after 5 epochs, loss: 0.841238260269165, auc_score: 0.5373134610441687\n",
      "Test:- after 5 epochs, loss: 0.8105360865592957, auc_score: 0.5405544084713876\n",
      "Training:- after 6 epochs, loss: 0.8499575257301331, auc_score: 0.5285795896693748\n",
      "Test:- after 6 epochs, loss: 0.8632392287254333, auc_score: 0.5286297380171671\n",
      "Training:- after 7 epochs, loss: 0.7869178056716919, auc_score: 0.5190574328128349\n",
      "Test:- after 7 epochs, loss: 0.9303799867630005, auc_score: 0.5200853038933716\n",
      "Training:- after 8 epochs, loss: 0.7959598898887634, auc_score: 0.5081623051179207\n",
      "Test:- after 8 epochs, loss: 0.8461047410964966, auc_score: 0.5154707583687406\n",
      "Training:- after 9 epochs, loss: 1.0608603954315186, auc_score: 0.5068316948153638\n",
      "Test:- after 9 epochs, loss: 0.8563134670257568, auc_score: 0.5069744178470131\n",
      "Training:- after 10 epochs, loss: 1.0089622735977173, auc_score: 0.5079492413446416\n",
      "Test:- after 10 epochs, loss: 0.9791931509971619, auc_score: 0.5113949320640179\n",
      "Training:- after 11 epochs, loss: 1.0764095783233643, auc_score: 0.5173183059571133\n",
      "Test:- after 11 epochs, loss: 0.7712995409965515, auc_score: 0.5199496712935503\n",
      "Training:- after 12 epochs, loss: 0.8019387722015381, auc_score: 0.5328882933974719\n",
      "Test:- after 12 epochs, loss: 0.8025082349777222, auc_score: 0.5308119335300474\n",
      "Training:- after 13 epochs, loss: 0.945827066898346, auc_score: 0.544258291522403\n",
      "Test:- after 13 epochs, loss: 0.9367896914482117, auc_score: 0.5359807134428316\n",
      "Training:- after 14 epochs, loss: 0.8050302863121033, auc_score: 0.5402629389305442\n",
      "Test:- after 14 epochs, loss: 0.8263975381851196, auc_score: 0.5337347568368082\n",
      "Training:- after 15 epochs, loss: 0.802324116230011, auc_score: 0.5245570798207372\n",
      "Test:- after 15 epochs, loss: 0.8214572668075562, auc_score: 0.5275809891160675\n",
      "Training:- after 16 epochs, loss: 0.8196747303009033, auc_score: 0.5155088069585408\n",
      "Test:- after 16 epochs, loss: 0.840082585811615, auc_score: 0.5088052729811628\n",
      "Training:- after 17 epochs, loss: 0.8823262453079224, auc_score: 0.5097232817899586\n",
      "Test:- after 17 epochs, loss: 0.7850922346115112, auc_score: 0.5137395627775229\n",
      "Training:- after 18 epochs, loss: 0.7694985866546631, auc_score: 0.5255528082722911\n",
      "Test:- after 18 epochs, loss: 0.7942208051681519, auc_score: 0.5261049342649273\n",
      "Training:- after 19 epochs, loss: 0.7906110882759094, auc_score: 0.5299167031257875\n",
      "Test:- after 19 epochs, loss: 0.774230420589447, auc_score: 0.5293761509699545\n",
      "Training:- after 20 epochs, loss: 0.7749003767967224, auc_score: 0.5294352958032421\n",
      "Test:- after 20 epochs, loss: 0.828262448310852, auc_score: 0.5266505359898435\n",
      "Training:- after 21 epochs, loss: 0.801061749458313, auc_score: 0.5206830103359213\n",
      "Test:- after 21 epochs, loss: 0.7854927182197571, auc_score: 0.509544386872632\n",
      "Training:- after 22 epochs, loss: 0.8038344383239746, auc_score: 0.5141238139724992\n",
      "Test:- after 22 epochs, loss: 0.7564241886138916, auc_score: 0.511170927353823\n",
      "Training:- after 23 epochs, loss: 0.8118661642074585, auc_score: 0.5131694627871817\n",
      "Test:- after 23 epochs, loss: 0.935766339302063, auc_score: 0.523896902934919\n",
      "Training:- after 24 epochs, loss: 0.7699868083000183, auc_score: 0.5167080934855477\n",
      "Test:- after 24 epochs, loss: 0.8266744613647461, auc_score: 0.5093742578147828\n",
      "Training:- after 25 epochs, loss: 0.8245022296905518, auc_score: 0.529130663195099\n",
      "Test:- after 25 epochs, loss: 0.7569302320480347, auc_score: 0.5251125417022605\n",
      "Training:- after 26 epochs, loss: 0.7375797033309937, auc_score: 0.5307849583638315\n",
      "Test:- after 26 epochs, loss: 0.8629425764083862, auc_score: 0.535555409449984\n",
      "Training:- after 27 epochs, loss: 0.7592517733573914, auc_score: 0.5284416977361337\n",
      "Test:- after 27 epochs, loss: 0.7404900193214417, auc_score: 0.527035263045984\n",
      "Training:- after 28 epochs, loss: 0.7454735040664673, auc_score: 0.5273903276835915\n",
      "Test:- after 28 epochs, loss: 0.7254014611244202, auc_score: 0.5226016988036752\n",
      "Training:- after 29 epochs, loss: 0.7371158003807068, auc_score: 0.5198456025343264\n",
      "Test:- after 29 epochs, loss: 0.9200705289840698, auc_score: 0.5261019344377671\n",
      "Training:- after 30 epochs, loss: 0.7140361666679382, auc_score: 0.5203810782067425\n",
      "Test:- after 30 epochs, loss: 0.742749810218811, auc_score: 0.5274140992498255\n",
      "Training:- after 31 epochs, loss: 0.8203784227371216, auc_score: 0.5187806885320011\n",
      "Test:- after 31 epochs, loss: 1.1242027282714844, auc_score: 0.5195370940285721\n",
      "Training:- after 32 epochs, loss: 0.8752127885818481, auc_score: 0.5103284930227658\n",
      "Test:- after 32 epochs, loss: 0.9422277808189392, auc_score: 0.5173495734339038\n",
      "Training:- after 33 epochs, loss: 0.729128360748291, auc_score: 0.5177404090044282\n",
      "Test:- after 33 epochs, loss: 0.7147819995880127, auc_score: 0.526714576859613\n",
      "Training:- after 34 epochs, loss: 0.783656656742096, auc_score: 0.527579784774874\n",
      "Test:- after 34 epochs, loss: 0.70867919921875, auc_score: 0.5214738477244213\n",
      "Training:- after 35 epochs, loss: 0.7894673347473145, auc_score: 0.5326153175581557\n",
      "Test:- after 35 epochs, loss: 0.8085207343101501, auc_score: 0.5254352858011497\n",
      "Training:- after 36 epochs, loss: 0.7311763763427734, auc_score: 0.5266942616687041\n",
      "Test:- after 36 epochs, loss: 0.801270067691803, auc_score: 0.5259582007502988\n",
      "Training:- after 37 epochs, loss: 0.7719040513038635, auc_score: 0.5204825381122459\n",
      "Test:- after 37 epochs, loss: 0.7157300710678101, auc_score: 0.5127954254656416\n",
      "Training:- after 38 epochs, loss: 0.7258129119873047, auc_score: 0.5179541624911557\n",
      "Test:- after 38 epochs, loss: 0.8171013593673706, auc_score: 0.5234810149798623\n",
      "Training:- after 39 epochs, loss: 0.6928180456161499, auc_score: 0.5215169034780955\n",
      "Test:- after 39 epochs, loss: 0.7716704607009888, auc_score: 0.5188886433071835\n",
      "Training:- after 40 epochs, loss: 0.8020852208137512, auc_score: 0.5259124319483679\n",
      "Test:- after 40 epochs, loss: 0.7240564227104187, auc_score: 0.5310564054547737\n",
      "Training:- after 41 epochs, loss: 0.852850615978241, auc_score: 0.5244282398447004\n",
      "Test:- after 41 epochs, loss: 0.7380011081695557, auc_score: 0.5253950539222818\n",
      "Training:- after 42 epochs, loss: 0.7144709825515747, auc_score: 0.5228033711305571\n",
      "Test:- after 42 epochs, loss: 0.7489542961120605, auc_score: 0.5298564870252035\n",
      "Training:- after 43 epochs, loss: 0.7227053642272949, auc_score: 0.5305696362761848\n",
      "Test:- after 43 epochs, loss: 0.8513385653495789, auc_score: 0.5283541798006249\n",
      "Training:- after 44 epochs, loss: 0.7505072951316833, auc_score: 0.5271064963027288\n",
      "Test:- after 44 epochs, loss: 0.7425807118415833, auc_score: 0.5212920892848039\n",
      "Training:- after 45 epochs, loss: 0.7069246768951416, auc_score: 0.520509411805871\n",
      "Test:- after 45 epochs, loss: 0.7501431107521057, auc_score: 0.5174315915062303\n",
      "Training:- after 46 epochs, loss: 0.6952288150787354, auc_score: 0.5116654766693889\n",
      "Test:- after 46 epochs, loss: 0.8669204115867615, auc_score: 0.5157762713360764\n",
      "Training:- after 47 epochs, loss: 0.7247967720031738, auc_score: 0.5084058005801361\n",
      "Test:- after 47 epochs, loss: 0.6895298957824707, auc_score: 0.513089461374039\n",
      "Training:- after 48 epochs, loss: 0.7064530849456787, auc_score: 0.5199508115879715\n",
      "Test:- after 48 epochs, loss: 0.6644396781921387, auc_score: 0.5207407863339687\n",
      "Training:- after 49 epochs, loss: 0.6833760142326355, auc_score: 0.5253968045094101\n",
      "Test:- after 49 epochs, loss: 0.7165900468826294, auc_score: 0.5318730299062561\n",
      "Training:- after 50 epochs, loss: 0.6779422760009766, auc_score: 0.5316482485752992\n",
      "Test:- after 50 epochs, loss: 0.7030611634254456, auc_score: 0.5354556193446264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 51 epochs, loss: 0.6858049631118774, auc_score: 0.5301448554072548\n",
      "Test:- after 51 epochs, loss: 0.7224321961402893, auc_score: 0.5348772775371698\n",
      "Training:- after 52 epochs, loss: 0.7295674085617065, auc_score: 0.5255014972921079\n",
      "Test:- after 52 epochs, loss: 0.7300628423690796, auc_score: 0.529491689390746\n",
      "Training:- after 53 epochs, loss: 0.6548298001289368, auc_score: 0.5259082181761616\n",
      "Test:- after 53 epochs, loss: 0.7470594644546509, auc_score: 0.527403421108587\n",
      "Training:- after 54 epochs, loss: 0.6636435985565186, auc_score: 0.5245638986933729\n",
      "Test:- after 54 epochs, loss: 0.7188291549682617, auc_score: 0.5281566139816194\n",
      "Training:- after 55 epochs, loss: 0.6636267304420471, auc_score: 0.5266515783893394\n",
      "Test:- after 55 epochs, loss: 0.6499240398406982, auc_score: 0.5311868279920867\n",
      "Training:- after 56 epochs, loss: 0.8881649374961853, auc_score: 0.5238380941659112\n",
      "Test:- after 56 epochs, loss: 0.6502392292022705, auc_score: 0.5309285817314567\n",
      "Training:- after 57 epochs, loss: 0.6533722877502441, auc_score: 0.5287695755970339\n",
      "Test:- after 57 epochs, loss: 0.6571446657180786, auc_score: 0.5326260455874252\n",
      "Training:- after 58 epochs, loss: 0.6561604738235474, auc_score: 0.5234072422158018\n",
      "Test:- after 58 epochs, loss: 0.6668236255645752, auc_score: 0.5161605258805814\n",
      "Training:- after 59 epochs, loss: 0.6573656797409058, auc_score: 0.5263940214201687\n",
      "Test:- after 59 epochs, loss: 0.7219500541687012, auc_score: 0.526461652572142\n",
      "Training:- after 60 epochs, loss: 0.7421250343322754, auc_score: 0.5209426072580225\n",
      "Test:- after 60 epochs, loss: 0.6380241513252258, auc_score: 0.5206551622517914\n",
      "Training:- after 61 epochs, loss: 0.7222949266433716, auc_score: 0.5160688874235928\n",
      "Test:- after 61 epochs, loss: 0.6537486910820007, auc_score: 0.5151613844839613\n",
      "Training:- after 62 epochs, loss: 0.632221519947052, auc_score: 0.5137421354944196\n",
      "Test:- after 62 epochs, loss: 0.6543571949005127, auc_score: 0.5208905694138245\n",
      "Training:- after 63 epochs, loss: 0.6356679201126099, auc_score: 0.5218135436816547\n",
      "Test:- after 63 epochs, loss: 0.6244869828224182, auc_score: 0.5330189980763803\n",
      "Training:- after 64 epochs, loss: 0.6344153881072998, auc_score: 0.5267342086526843\n",
      "Test:- after 64 epochs, loss: 0.6143636703491211, auc_score: 0.5318243674250478\n",
      "Training:- after 65 epochs, loss: 0.6422660946846008, auc_score: 0.5342835940921289\n",
      "Test:- after 65 epochs, loss: 0.6537359356880188, auc_score: 0.5401404509750526\n",
      "Training:- after 66 epochs, loss: 0.6190438270568848, auc_score: 0.5376203039805909\n",
      "Test:- after 66 epochs, loss: 0.6218920946121216, auc_score: 0.5361471370146963\n",
      "Training:- after 67 epochs, loss: 0.6371943950653076, auc_score: 0.5293229693738092\n",
      "Test:- after 67 epochs, loss: 0.7027224898338318, auc_score: 0.5218586307358871\n",
      "Training:- after 68 epochs, loss: 0.6154822111129761, auc_score: 0.5262465519583793\n",
      "Test:- after 68 epochs, loss: 0.8851313591003418, auc_score: 0.528004919094817\n",
      "Training:- after 69 epochs, loss: 0.7168821692466736, auc_score: 0.5218179778930465\n",
      "Test:- after 69 epochs, loss: 0.6993566155433655, auc_score: 0.5219810330099116\n",
      "Training:- after 70 epochs, loss: 0.6268287301063538, auc_score: 0.518704811444874\n",
      "Test:- after 70 epochs, loss: 0.6221492290496826, auc_score: 0.5111671628038841\n",
      "Training:- after 71 epochs, loss: 0.6118319034576416, auc_score: 0.520937563969599\n",
      "Test:- after 71 epochs, loss: 0.6108697652816772, auc_score: 0.5177969735629739\n",
      "Training:- after 72 epochs, loss: 0.6000347137451172, auc_score: 0.5195673926495177\n",
      "Test:- after 72 epochs, loss: 0.5990117788314819, auc_score: 0.5072419682347836\n",
      "Training:- after 73 epochs, loss: 0.643979012966156, auc_score: 0.5154814283721132\n",
      "Test:- after 73 epochs, loss: 0.6060800552368164, auc_score: 0.5216085384096004\n",
      "Training:- after 74 epochs, loss: 0.6125021576881409, auc_score: 0.5197658448072812\n",
      "Test:- after 74 epochs, loss: 0.6171431541442871, auc_score: 0.5092211422844446\n",
      "Training:- after 75 epochs, loss: 0.6002568006515503, auc_score: 0.5249646012314744\n",
      "Test:- after 75 epochs, loss: 0.6864505410194397, auc_score: 0.530343506633193\n",
      "Training:- after 76 epochs, loss: 0.6509646773338318, auc_score: 0.537887732628085\n",
      "Test:- after 76 epochs, loss: 0.685124397277832, auc_score: 0.5460742458776469\n",
      "Training:- after 77 epochs, loss: 0.7383854985237122, auc_score: 0.5389285695858067\n",
      "Test:- after 77 epochs, loss: 0.7165343165397644, auc_score: 0.5430084784752298\n",
      "Training:- after 78 epochs, loss: 0.608623743057251, auc_score: 0.5350043242638851\n",
      "Test:- after 78 epochs, loss: 0.5792655944824219, auc_score: 0.5334821713899178\n",
      "Training:- after 79 epochs, loss: 0.5867143869400024, auc_score: 0.526368525075692\n",
      "Test:- after 79 epochs, loss: 0.631048321723938, auc_score: 0.5270786999215382\n",
      "Training:- after 80 epochs, loss: 0.6476074457168579, auc_score: 0.522444096516171\n",
      "Test:- after 80 epochs, loss: 0.6144076585769653, auc_score: 0.521629282292129\n",
      "Training:- after 81 epochs, loss: 0.5920969247817993, auc_score: 0.5198419004818096\n",
      "Test:- after 81 epochs, loss: 0.6125618815422058, auc_score: 0.5069339528209567\n",
      "Training:- after 82 epochs, loss: 0.5836412906646729, auc_score: 0.5262522187691312\n",
      "Test:- after 82 epochs, loss: 0.6873539090156555, auc_score: 0.512148513515698\n",
      "Training:- after 83 epochs, loss: 0.5813695788383484, auc_score: 0.5248051703714162\n",
      "Test:- after 83 epochs, loss: 0.5744495987892151, auc_score: 0.5104756171561513\n",
      "Training:- after 84 epochs, loss: 0.5891602635383606, auc_score: 0.5269611519815443\n",
      "Test:- after 84 epochs, loss: 0.6106664538383484, auc_score: 0.522969685891673\n",
      "Training:- after 85 epochs, loss: 0.7249231338500977, auc_score: 0.5209864615958257\n",
      "Test:- after 85 epochs, loss: 0.5969089269638062, auc_score: 0.515715572242677\n",
      "Training:- after 86 epochs, loss: 0.7002251744270325, auc_score: 0.5125046410586416\n",
      "Test:- after 86 epochs, loss: 0.6467542052268982, auc_score: 0.5147063526702503\n",
      "Training:- after 87 epochs, loss: 0.5868517756462097, auc_score: 0.5184775819804106\n",
      "Test:- after 87 epochs, loss: 0.5722400546073914, auc_score: 0.5216017087512885\n",
      "Training:- after 88 epochs, loss: 0.5558319687843323, auc_score: 0.5410466809707095\n",
      "Test:- after 88 epochs, loss: 0.5458377599716187, auc_score: 0.540186769549858\n",
      "Training:- after 89 epochs, loss: 0.6000012159347534, auc_score: 0.5509650173054903\n",
      "Test:- after 89 epochs, loss: 0.5898338556289673, auc_score: 0.5436717014024892\n",
      "Training:- after 90 epochs, loss: 0.5880575776100159, auc_score: 0.5452837623452066\n",
      "Test:- after 90 epochs, loss: 0.5599169731140137, auc_score: 0.540112361401768\n",
      "Training:- after 91 epochs, loss: 0.5647539496421814, auc_score: 0.5294442217103915\n",
      "Test:- after 91 epochs, loss: 0.5514106750488281, auc_score: 0.5251832630161413\n",
      "Training:- after 92 epochs, loss: 0.5787754058837891, auc_score: 0.51527382868073\n",
      "Test:- after 92 epochs, loss: 0.5807009935379028, auc_score: 0.5160273490978137\n",
      "Training:- after 93 epochs, loss: 0.5593311786651611, auc_score: 0.5062199771636678\n",
      "Test:- after 93 epochs, loss: 0.5922197699546814, auc_score: 0.5127212535733693\n",
      "Training:- after 94 epochs, loss: 0.7068064212799072, auc_score: 0.5093604346360242\n",
      "Test:- after 94 epochs, loss: 0.5410562753677368, auc_score: 0.5119602611497203\n",
      "Training:- after 95 epochs, loss: 0.6717911958694458, auc_score: 0.5251248433037781\n",
      "Test:- after 95 epochs, loss: 0.5303453803062439, auc_score: 0.520629969920904\n",
      "Training:- after 96 epochs, loss: 0.5503003001213074, auc_score: 0.5345974417112366\n",
      "Test:- after 96 epochs, loss: 0.5663010478019714, auc_score: 0.5342276237762881\n",
      "Training:- after 97 epochs, loss: 0.6220237612724304, auc_score: 0.5407316962297166\n",
      "Test:- after 97 epochs, loss: 0.5704233646392822, auc_score: 0.5374820134715554\n",
      "Training:- after 98 epochs, loss: 0.5947858095169067, auc_score: 0.5402316963261836\n",
      "Test:- after 98 epochs, loss: 0.5429005026817322, auc_score: 0.5330507123112906\n",
      "Training:- after 99 epochs, loss: 0.6695376634597778, auc_score: 0.5284098444716951\n",
      "Test:- after 99 epochs, loss: 0.5535967350006104, auc_score: 0.5259296728602995\n",
      "Training:- after 100 epochs, loss: 0.6872607469558716, auc_score: 0.5168950528267222\n",
      "Test:- after 100 epochs, loss: 0.5631077885627747, auc_score: 0.5157657766039594\n",
      "Training:- after 101 epochs, loss: 0.5805578827857971, auc_score: 0.5184831135396514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:- after 101 epochs, loss: 0.8611193299293518, auc_score: 0.5085939359348829\n",
      "Training:- after 102 epochs, loss: 0.5409759879112244, auc_score: 0.5248558749459582\n",
      "Test:- after 102 epochs, loss: 0.5126676559448242, auc_score: 0.5251089792132184\n",
      "Training:- after 103 epochs, loss: 0.5566344857215881, auc_score: 0.5382142085036801\n",
      "Test:- after 103 epochs, loss: 0.5486442446708679, auc_score: 0.5411787300130686\n",
      "Training:- after 104 epochs, loss: 0.5796895623207092, auc_score: 0.5368533430218401\n",
      "Test:- after 104 epochs, loss: 0.5556807518005371, auc_score: 0.542300836345595\n",
      "Training:- after 105 epochs, loss: 0.5571986436843872, auc_score: 0.5255331661316622\n",
      "Test:- after 105 epochs, loss: 0.5758150219917297, auc_score: 0.5324820601009931\n",
      "Training:- after 106 epochs, loss: 0.5644760131835938, auc_score: 0.5124463611132533\n",
      "Test:- after 106 epochs, loss: 0.5528866052627563, auc_score: 0.5163881024057059\n",
      "Training:- after 107 epochs, loss: 0.6159065961837769, auc_score: 0.5141469424755981\n",
      "Test:- after 107 epochs, loss: 0.6596693396568298, auc_score: 0.505954678673436\n",
      "Training:- after 108 epochs, loss: 0.6695161461830139, auc_score: 0.5195190282130447\n",
      "Test:- after 108 epochs, loss: 0.5076432824134827, auc_score: 0.5171083562439304\n",
      "Training:- after 109 epochs, loss: 0.527924120426178, auc_score: 0.5265595481954438\n",
      "Test:- after 109 epochs, loss: 0.5188823342323303, auc_score: 0.5343560070528579\n",
      "Training:- after 110 epochs, loss: 0.5374637842178345, auc_score: 0.5360595764404512\n",
      "Test:- after 110 epochs, loss: 0.5900889039039612, auc_score: 0.5320059704332061\n",
      "Training:- after 111 epochs, loss: 0.6773427724838257, auc_score: 0.5442811992894953\n",
      "Test:- after 111 epochs, loss: 0.5131516456604004, auc_score: 0.5361335802828355\n",
      "Training:- after 112 epochs, loss: 0.5415415167808533, auc_score: 0.5381347096046911\n",
      "Test:- after 112 epochs, loss: 0.5241639614105225, auc_score: 0.5402021417211609\n",
      "Training:- after 113 epochs, loss: 0.5029809474945068, auc_score: 0.5335225053443764\n",
      "Test:- after 113 epochs, loss: 0.5350387096405029, auc_score: 0.5297276934095818\n",
      "Training:- after 114 epochs, loss: 0.5254602432250977, auc_score: 0.527841884295162\n",
      "Test:- after 114 epochs, loss: 0.5332170724868774, auc_score: 0.5219832339193722\n",
      "Training:- after 115 epochs, loss: 0.5677844882011414, auc_score: 0.5203204402150748\n",
      "Test:- after 115 epochs, loss: 0.512843132019043, auc_score: 0.5176853613408388\n",
      "Training:- after 116 epochs, loss: 0.5130681991577148, auc_score: 0.5200585249217902\n",
      "Test:- after 116 epochs, loss: 0.4977113604545593, auc_score: 0.5176165611597923\n",
      "Training:- after 117 epochs, loss: 0.5088831186294556, auc_score: 0.5176835367828876\n",
      "Test:- after 117 epochs, loss: 0.5116454362869263, auc_score: 0.5265876328783543\n",
      "Training:- after 118 epochs, loss: 0.5060701966285706, auc_score: 0.5242820837176281\n",
      "Test:- after 118 epochs, loss: 0.5194539427757263, auc_score: 0.5287242962996123\n",
      "Training:- after 119 epochs, loss: 0.5077421069145203, auc_score: 0.5364023198968444\n",
      "Test:- after 119 epochs, loss: 0.5438947677612305, auc_score: 0.5355859144281427\n",
      "Training:- after 120 epochs, loss: 0.5401960015296936, auc_score: 0.5359961396230735\n",
      "Test:- after 120 epochs, loss: 0.5669617056846619, auc_score: 0.5417302692197217\n",
      "Training:- after 121 epochs, loss: 0.5176203846931458, auc_score: 0.532597430620019\n",
      "Test:- after 121 epochs, loss: 0.48981744050979614, auc_score: 0.5343647360835998\n",
      "Training:- after 122 epochs, loss: 0.5387422442436218, auc_score: 0.5273922219962698\n",
      "Test:- after 122 epochs, loss: 0.5250129103660583, auc_score: 0.5337333019983512\n",
      "Training:- after 123 epochs, loss: 0.6012447476387024, auc_score: 0.5200796038747411\n",
      "Test:- after 123 epochs, loss: 0.4924178719520569, auc_score: 0.5164450835786042\n",
      "Training:- after 124 epochs, loss: 0.5318678617477417, auc_score: 0.5215575364157892\n",
      "Test:- after 124 epochs, loss: 0.5081698894500732, auc_score: 0.5177449630881371\n",
      "Training:- after 125 epochs, loss: 0.49933958053588867, auc_score: 0.5232350426039044\n",
      "Test:- after 125 epochs, loss: 0.6223338842391968, auc_score: 0.5233154058688432\n",
      "Training:- after 126 epochs, loss: 0.5210803151130676, auc_score: 0.532727947635641\n",
      "Test:- after 126 epochs, loss: 0.520889401435852, auc_score: 0.5284539046247698\n",
      "Training:- after 127 epochs, loss: 0.4917911887168884, auc_score: 0.5355353626577574\n",
      "Test:- after 127 epochs, loss: 0.5042555928230286, auc_score: 0.5324701695943737\n",
      "Training:- after 128 epochs, loss: 0.5544038414955139, auc_score: 0.5349644902698287\n",
      "Test:- after 128 epochs, loss: 0.5024735331535339, auc_score: 0.5311662613014214\n",
      "Training:- after 129 epochs, loss: 0.5343319773674011, auc_score: 0.5293989514366884\n",
      "Test:- after 129 epochs, loss: 0.48899078369140625, auc_score: 0.5205926850225002\n",
      "Training:- after 130 epochs, loss: 0.5496947765350342, auc_score: 0.522135217089732\n",
      "Test:- after 130 epochs, loss: 0.5213218331336975, auc_score: 0.5214465011135111\n",
      "Training:- after 131 epochs, loss: 0.4973340928554535, auc_score: 0.5270529370011571\n",
      "Test:- after 131 epochs, loss: 0.6044044494628906, auc_score: 0.5227742557009151\n",
      "Training:- after 132 epochs, loss: 0.491707980632782, auc_score: 0.5239810057408232\n",
      "Test:- after 132 epochs, loss: 0.5180261731147766, auc_score: 0.5272146122979857\n",
      "Training:- after 133 epochs, loss: 0.5155755281448364, auc_score: 0.5234742804633215\n",
      "Test:- after 133 epochs, loss: 0.49860137701034546, auc_score: 0.5212283157571439\n",
      "Training:- after 134 epochs, loss: 0.4793907701969147, auc_score: 0.5257633878502954\n",
      "Test:- after 134 epochs, loss: 0.5697348117828369, auc_score: 0.5256649140215341\n",
      "Training:- after 135 epochs, loss: 0.4733261168003082, auc_score: 0.5301009661434944\n",
      "Test:- after 135 epochs, loss: 0.45838460326194763, auc_score: 0.5297906400418795\n",
      "Training:- after 136 epochs, loss: 0.48184913396835327, auc_score: 0.5371977716309302\n",
      "Test:- after 136 epochs, loss: 0.4580734670162201, auc_score: 0.5333468310012397\n",
      "Training:- after 137 epochs, loss: 0.4602518379688263, auc_score: 0.5417806545113485\n",
      "Test:- after 137 epochs, loss: 0.5764327645301819, auc_score: 0.5351339197451421\n",
      "Training:- after 138 epochs, loss: 0.4592369794845581, auc_score: 0.5324897854561279\n",
      "Test:- after 138 epochs, loss: 0.45763805508613586, auc_score: 0.5237690823202311\n",
      "Training:- after 139 epochs, loss: 0.4662357270717621, auc_score: 0.5173825909904417\n",
      "Test:- after 139 epochs, loss: 0.4641319215297699, auc_score: 0.5122087587492368\n",
      "Training:- after 140 epochs, loss: 0.46784549951553345, auc_score: 0.5129917720826624\n",
      "Test:- after 140 epochs, loss: 0.5739861130714417, auc_score: 0.5130582507370559\n",
      "Training:- after 141 epochs, loss: 0.4891922175884247, auc_score: 0.5201362135084906\n",
      "Test:- after 141 epochs, loss: 0.5066391825675964, auc_score: 0.5243437839229159\n",
      "Training:- after 142 epochs, loss: 0.45694270730018616, auc_score: 0.529091617755939\n",
      "Test:- after 142 epochs, loss: 0.48433738946914673, auc_score: 0.5275865069328648\n",
      "Training:- after 143 epochs, loss: 0.44645485281944275, auc_score: 0.5345139701577682\n",
      "Test:- after 143 epochs, loss: 0.6126725077629089, auc_score: 0.5292690400428741\n",
      "Training:- after 144 epochs, loss: 0.47491663694381714, auc_score: 0.5429901626688327\n",
      "Test:- after 144 epochs, loss: 0.4494601786136627, auc_score: 0.5352208805378674\n",
      "Training:- after 145 epochs, loss: 0.44648146629333496, auc_score: 0.540116619848652\n",
      "Test:- after 145 epochs, loss: 0.4582369923591614, auc_score: 0.5474899902140353\n",
      "Training:- after 146 epochs, loss: 0.43877020478248596, auc_score: 0.5348967978284602\n",
      "Test:- after 146 epochs, loss: 0.5167045593261719, auc_score: 0.5326236426170678\n",
      "Training:- after 147 epochs, loss: 0.487026572227478, auc_score: 0.5250677383744438\n",
      "Test:- after 147 epochs, loss: 0.4677855968475342, auc_score: 0.5316337866958132\n",
      "Training:- after 148 epochs, loss: 0.44183072447776794, auc_score: 0.5283846381214972\n",
      "Test:- after 148 epochs, loss: 0.45914506912231445, auc_score: 0.5366724362824277\n",
      "Training:- after 149 epochs, loss: 0.5008624792098999, auc_score: 0.5273928478931675\n",
      "Test:- after 149 epochs, loss: 0.4271029233932495, auc_score: 0.5295384835858162\n",
      "Training:- after 150 epochs, loss: 0.4865719974040985, auc_score: 0.53287158681817\n",
      "Test:- after 150 epochs, loss: 0.44271835684776306, auc_score: 0.529811399467554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 151 epochs, loss: 0.4478629231452942, auc_score: 0.526034683780755\n",
      "Test:- after 151 epochs, loss: 0.45798391103744507, auc_score: 0.5351570541635114\n",
      "Training:- after 152 epochs, loss: 0.4671402871608734, auc_score: 0.530573092165015\n",
      "Test:- after 152 epochs, loss: 0.42690619826316833, auc_score: 0.5307414018425467\n",
      "Training:- after 153 epochs, loss: 0.4782366454601288, auc_score: 0.5343608069734412\n",
      "Test:- after 153 epochs, loss: 0.447378933429718, auc_score: 0.5372282343110594\n",
      "Training:- after 154 epochs, loss: 0.4318068027496338, auc_score: 0.5343989485921522\n",
      "Test:- after 154 epochs, loss: 0.5299240946769714, auc_score: 0.5400353482224236\n",
      "Training:- after 155 epochs, loss: 0.4378581941127777, auc_score: 0.5387490250352279\n",
      "Test:- after 155 epochs, loss: 0.4481811225414276, auc_score: 0.5417230634172787\n",
      "Training:- after 156 epochs, loss: 0.425376296043396, auc_score: 0.5331105565491343\n",
      "Test:- after 156 epochs, loss: 0.4696224331855774, auc_score: 0.5279108986052203\n",
      "Training:- after 157 epochs, loss: 0.4535534977912903, auc_score: 0.5309816838139347\n",
      "Test:- after 157 epochs, loss: 0.4280036687850952, auc_score: 0.533021870449744\n",
      "Training:- after 158 epochs, loss: 0.4372459948062897, auc_score: 0.5292404870263451\n",
      "Test:- after 158 epochs, loss: 0.43238455057144165, auc_score: 0.528483218997952\n",
      "Training:- after 159 epochs, loss: 0.42375487089157104, auc_score: 0.5299339709939135\n",
      "Test:- after 159 epochs, loss: 0.42920204997062683, auc_score: 0.5375362745939198\n",
      "Training:- after 160 epochs, loss: 0.4647846221923828, auc_score: 0.523998381849734\n",
      "Test:- after 160 epochs, loss: 0.44515353441238403, auc_score: 0.5262200063913416\n",
      "Training:- after 161 epochs, loss: 0.4449344575405121, auc_score: 0.5245043372720728\n",
      "Test:- after 161 epochs, loss: 0.4203353524208069, auc_score: 0.520391273829197\n",
      "Training:- after 162 epochs, loss: 0.42637234926223755, auc_score: 0.5167757316086428\n",
      "Test:- after 162 epochs, loss: 0.412757933139801, auc_score: 0.5224480112855673\n",
      "Training:- after 163 epochs, loss: 0.40957146883010864, auc_score: 0.5309214338664708\n",
      "Test:- after 163 epochs, loss: 0.43898800015449524, auc_score: 0.525355285229162\n",
      "Training:- after 164 epochs, loss: 0.40838178992271423, auc_score: 0.5396236974479302\n",
      "Test:- after 164 epochs, loss: 0.4189144968986511, auc_score: 0.5442407826036137\n",
      "Training:- after 165 epochs, loss: 0.40286311507225037, auc_score: 0.5439608905661967\n",
      "Test:- after 165 epochs, loss: 0.4264511466026306, auc_score: 0.5360818122810749\n",
      "Training:- after 166 epochs, loss: 0.43300649523735046, auc_score: 0.5403819911297072\n",
      "Test:- after 166 epochs, loss: 0.39982759952545166, auc_score: 0.5398078960424664\n",
      "Training:- after 167 epochs, loss: 0.41648200154304504, auc_score: 0.5319595069244396\n",
      "Test:- after 167 epochs, loss: 0.539923906326294, auc_score: 0.536445919799854\n",
      "Training:- after 168 epochs, loss: 0.43097200989723206, auc_score: 0.5326080794750939\n",
      "Test:- after 168 epochs, loss: 0.41126149892807007, auc_score: 0.5352645940814188\n",
      "Training:- after 169 epochs, loss: 0.4134087562561035, auc_score: 0.5349308997111084\n",
      "Test:- after 169 epochs, loss: 0.42745843529701233, auc_score: 0.5351155259862748\n",
      "Training:- after 170 epochs, loss: 0.41319894790649414, auc_score: 0.5360675908098014\n",
      "Test:- after 170 epochs, loss: 0.41953110694885254, auc_score: 0.5336088511376961\n",
      "Training:- after 171 epochs, loss: 0.44560614228248596, auc_score: 0.5342734232180708\n",
      "Test:- after 171 epochs, loss: 0.44091588258743286, auc_score: 0.525320515211766\n",
      "Training:- after 172 epochs, loss: 0.406475305557251, auc_score: 0.5204785774295533\n",
      "Test:- after 172 epochs, loss: 0.3981356918811798, auc_score: 0.5186420264283218\n",
      "Training:- after 173 epochs, loss: 0.40118885040283203, auc_score: 0.5102572882965457\n",
      "Test:- after 173 epochs, loss: 0.41508859395980835, auc_score: 0.5128701071730997\n",
      "Training:- after 174 epochs, loss: 0.39431318640708923, auc_score: 0.518406332829956\n",
      "Test:- after 174 epochs, loss: 0.5112868547439575, auc_score: 0.5186409757116586\n",
      "Training:- after 175 epochs, loss: 0.42474570870399475, auc_score: 0.5360354512118786\n",
      "Test:- after 175 epochs, loss: 0.4076167643070221, auc_score: 0.5360627874704836\n",
      "Training:- after 176 epochs, loss: 0.4816613495349884, auc_score: 0.5417270295133589\n",
      "Test:- after 176 epochs, loss: 0.40656036138534546, auc_score: 0.5494966663060656\n",
      "Training:- after 177 epochs, loss: 0.39269545674324036, auc_score: 0.5513012944138519\n",
      "Test:- after 177 epochs, loss: 0.39058059453964233, auc_score: 0.5486701688483026\n",
      "Training:- after 178 epochs, loss: 0.40837258100509644, auc_score: 0.541284427897412\n",
      "Test:- after 178 epochs, loss: 0.3935701549053192, auc_score: 0.5396109581665554\n",
      "Training:- after 179 epochs, loss: 0.42375099658966064, auc_score: 0.5381904367891155\n",
      "Test:- after 179 epochs, loss: 0.38914915919303894, auc_score: 0.5365129915830756\n",
      "Training:- after 180 epochs, loss: 0.40259474515914917, auc_score: 0.5299885044625504\n",
      "Test:- after 180 epochs, loss: 0.3833378851413727, auc_score: 0.5288375405520677\n",
      "Training:- after 181 epochs, loss: 0.4063512682914734, auc_score: 0.5273421511349162\n",
      "Test:- after 181 epochs, loss: 0.40767592191696167, auc_score: 0.523323363959548\n",
      "Training:- after 182 epochs, loss: 0.3992011547088623, auc_score: 0.5223408993163857\n",
      "Test:- after 182 epochs, loss: 0.43626514077186584, auc_score: 0.5328063585144732\n",
      "Training:- after 183 epochs, loss: 0.3780434727668762, auc_score: 0.5297043666633046\n",
      "Test:- after 183 epochs, loss: 0.3777082860469818, auc_score: 0.5320615496143435\n",
      "Training:- after 184 epochs, loss: 0.37532860040664673, auc_score: 0.5334122894123707\n",
      "Test:- after 184 epochs, loss: 0.3800201416015625, auc_score: 0.534580732965023\n",
      "Training:- after 185 epochs, loss: 0.39308348298072815, auc_score: 0.5349041671064774\n",
      "Test:- after 185 epochs, loss: 0.38593271374702454, auc_score: 0.526988213943321\n",
      "Training:- after 186 epochs, loss: 0.39095228910446167, auc_score: 0.5429238777534313\n",
      "Test:- after 186 epochs, loss: 0.3928448259830475, auc_score: 0.5357698924289958\n",
      "Training:- after 187 epochs, loss: 0.3844347596168518, auc_score: 0.5386084723970588\n",
      "Test:- after 187 epochs, loss: 0.37601205706596375, auc_score: 0.5400403842016979\n",
      "Training:- after 188 epochs, loss: 0.3729775846004486, auc_score: 0.5337985898906995\n",
      "Test:- after 188 epochs, loss: 0.3954065442085266, auc_score: 0.5359352031116135\n",
      "Training:- after 189 epochs, loss: 0.46144434809684753, auc_score: 0.5304944293123091\n",
      "Test:- after 189 epochs, loss: 0.3583853840827942, auc_score: 0.5321271727763665\n",
      "Training:- after 190 epochs, loss: 0.3697868287563324, auc_score: 0.5353016949443327\n",
      "Test:- after 190 epochs, loss: 0.373483806848526, auc_score: 0.5394810485530575\n",
      "Training:- after 191 epochs, loss: 0.3833712041378021, auc_score: 0.5315171018041043\n",
      "Test:- after 191 epochs, loss: 0.3949664533138275, auc_score: 0.528250531886453\n",
      "Training:- after 192 epochs, loss: 0.3805154860019684, auc_score: 0.5324545005432545\n",
      "Test:- after 192 epochs, loss: 0.4600929319858551, auc_score: 0.5355520117182885\n",
      "Training:- after 193 epochs, loss: 0.3804543912410736, auc_score: 0.5391991007070631\n",
      "Test:- after 193 epochs, loss: 0.417667955160141, auc_score: 0.5427207126718916\n",
      "Training:- after 194 epochs, loss: 0.3677997589111328, auc_score: 0.5397074708685239\n",
      "Test:- after 194 epochs, loss: 0.4052445888519287, auc_score: 0.5337357422722587\n",
      "Training:- after 195 epochs, loss: 0.3655627369880676, auc_score: 0.5381250831006507\n",
      "Test:- after 195 epochs, loss: 0.36340099573135376, auc_score: 0.5353129239393045\n",
      "Training:- after 196 epochs, loss: 0.36705654859542847, auc_score: 0.5337147811483872\n",
      "Test:- after 196 epochs, loss: 0.3597473204135895, auc_score: 0.5368836769612031\n",
      "Training:- after 197 epochs, loss: 0.4255842864513397, auc_score: 0.5356557238382603\n",
      "Test:- after 197 epochs, loss: 0.36917975544929504, auc_score: 0.5399746056082158\n",
      "Training:- after 198 epochs, loss: 0.37295034527778625, auc_score: 0.5352475352724835\n",
      "Test:- after 198 epochs, loss: 0.3768327534198761, auc_score: 0.5360175320468583\n",
      "Training:- after 199 epochs, loss: 0.35986974835395813, auc_score: 0.5349844774155923\n",
      "Test:- after 199 epochs, loss: 0.3582237660884857, auc_score: 0.5397375446554582\n",
      "Training:- after 200 epochs, loss: 0.412373811006546, auc_score: 0.538093676453126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:- after 200 epochs, loss: 0.41837167739868164, auc_score: 0.5305187151911248\n",
      "Training:- after 201 epochs, loss: 0.35452669858932495, auc_score: 0.537801271392897\n",
      "Test:- after 201 epochs, loss: 0.3492462933063507, auc_score: 0.5307802317296537\n",
      "Training:- after 202 epochs, loss: 0.36151665449142456, auc_score: 0.5371269555425562\n",
      "Test:- after 202 epochs, loss: 0.344543993473053, auc_score: 0.5359988460768478\n",
      "Training:- after 203 epochs, loss: 0.36509042978286743, auc_score: 0.5357697410599926\n",
      "Test:- after 203 epochs, loss: 0.4435429573059082, auc_score: 0.5278232072846373\n",
      "Training:- after 204 epochs, loss: 0.34665030241012573, auc_score: 0.5336163463452626\n",
      "Test:- after 204 epochs, loss: 0.3779710829257965, auc_score: 0.5309567925412795\n",
      "Training:- after 205 epochs, loss: 0.36648330092430115, auc_score: 0.536655982473383\n",
      "Test:- after 205 epochs, loss: 0.34108099341392517, auc_score: 0.5358574469698948\n",
      "Training:- after 206 epochs, loss: 0.3473418056964874, auc_score: 0.5356069550324196\n",
      "Test:- after 206 epochs, loss: 0.34498727321624756, auc_score: 0.541152881761424\n",
      "Training:- after 207 epochs, loss: 0.3951823115348816, auc_score: 0.5335114560775491\n",
      "Test:- after 207 epochs, loss: 0.3673529028892517, auc_score: 0.5308900222950885\n",
      "Training:- after 208 epochs, loss: 0.35353928804397583, auc_score: 0.5338776724485335\n",
      "Test:- after 208 epochs, loss: 0.35082343220710754, auc_score: 0.5226158088715303\n",
      "Training:- after 209 epochs, loss: 0.36440345644950867, auc_score: 0.5333715080640943\n",
      "Test:- after 209 epochs, loss: 0.3454321026802063, auc_score: 0.5256375643019946\n",
      "Training:- after 210 epochs, loss: 0.34636881947517395, auc_score: 0.53620634797674\n",
      "Test:- after 210 epochs, loss: 0.33626291155815125, auc_score: 0.5350593530569638\n",
      "Training:- after 211 epochs, loss: 0.38598668575286865, auc_score: 0.5372576430324677\n",
      "Test:- after 211 epochs, loss: 0.3392295241355896, auc_score: 0.5402922857501682\n",
      "Training:- after 212 epochs, loss: 0.347321093082428, auc_score: 0.5434875891328607\n",
      "Test:- after 212 epochs, loss: 0.36440369486808777, auc_score: 0.5379379654395042\n",
      "Training:- after 213 epochs, loss: 0.3418888747692108, auc_score: 0.5401725093942539\n",
      "Test:- after 213 epochs, loss: 0.3562138080596924, auc_score: 0.5341817404095681\n",
      "Training:- after 214 epochs, loss: 0.33007925748825073, auc_score: 0.5364095882556651\n",
      "Test:- after 214 epochs, loss: 0.3432728052139282, auc_score: 0.5406465389144418\n",
      "Training:- after 215 epochs, loss: 0.3692181706428528, auc_score: 0.5315057170304196\n",
      "Test:- after 215 epochs, loss: 0.33070698380470276, auc_score: 0.5370717241576548\n",
      "Training:- after 216 epochs, loss: 0.33153384923934937, auc_score: 0.5318691545616523\n",
      "Test:- after 216 epochs, loss: 0.3317880928516388, auc_score: 0.5225985155673931\n",
      "Training:- after 217 epochs, loss: 0.33563581109046936, auc_score: 0.5330746449478398\n",
      "Test:- after 217 epochs, loss: 0.3225659728050232, auc_score: 0.539914329288385\n",
      "Training:- after 218 epochs, loss: 0.35506242513656616, auc_score: 0.5412644013733737\n",
      "Test:- after 218 epochs, loss: 0.3362943232059479, auc_score: 0.5292676846805511\n",
      "Training:- after 219 epochs, loss: 0.34479820728302, auc_score: 0.5428059536725779\n",
      "Test:- after 219 epochs, loss: 0.33110150694847107, auc_score: 0.5387301778260236\n",
      "Training:- after 220 epochs, loss: 0.3604530692100525, auc_score: 0.5419895555656618\n",
      "Test:- after 220 epochs, loss: 0.3290029466152191, auc_score: 0.5427999329779548\n",
      "Training:- after 221 epochs, loss: 0.33335253596305847, auc_score: 0.543392783562127\n",
      "Test:- after 221 epochs, loss: 0.3260144591331482, auc_score: 0.5459786555303134\n",
      "Training:- after 222 epochs, loss: 0.33319002389907837, auc_score: 0.5415837125796753\n",
      "Test:- after 222 epochs, loss: 0.3938503861427307, auc_score: 0.5334399033589361\n",
      "Training:- after 223 epochs, loss: 0.3296341001987457, auc_score: 0.5414843490231237\n",
      "Test:- after 223 epochs, loss: 0.3529631197452545, auc_score: 0.5414199534203004\n",
      "Training:- after 224 epochs, loss: 0.36021876335144043, auc_score: 0.533837498198481\n",
      "Test:- after 224 epochs, loss: 0.327934205532074, auc_score: 0.5289290834642066\n",
      "Training:- after 225 epochs, loss: 0.33133354783058167, auc_score: 0.528898234314279\n",
      "Test:- after 225 epochs, loss: 0.3433748781681061, auc_score: 0.5217067648744798\n",
      "Training:- after 226 epochs, loss: 0.33343663811683655, auc_score: 0.5248439284876879\n",
      "Test:- after 226 epochs, loss: 0.3515285551548004, auc_score: 0.5309034764421864\n",
      "Training:- after 227 epochs, loss: 0.33929264545440674, auc_score: 0.5293889334255306\n",
      "Test:- after 227 epochs, loss: 0.34476885199546814, auc_score: 0.5300214557586111\n",
      "Training:- after 228 epochs, loss: 0.32227954268455505, auc_score: 0.5335504877639952\n",
      "Test:- after 228 epochs, loss: 0.3301354944705963, auc_score: 0.5371645509336457\n",
      "Training:- after 229 epochs, loss: 0.34767746925354004, auc_score: 0.546659736519074\n",
      "Test:- after 229 epochs, loss: 0.35166698694229126, auc_score: 0.5498643269879995\n",
      "Training:- after 230 epochs, loss: 0.32488930225372314, auc_score: 0.5465070998954946\n",
      "Test:- after 230 epochs, loss: 0.5009157657623291, auc_score: 0.5473714519660837\n",
      "Training:- after 231 epochs, loss: 0.3301849365234375, auc_score: 0.5367291188128079\n",
      "Test:- after 231 epochs, loss: 0.3743292987346649, auc_score: 0.5349265586355854\n",
      "Training:- after 232 epochs, loss: 0.36962518095970154, auc_score: 0.5335226333732391\n",
      "Test:- after 232 epochs, loss: 0.34892401099205017, auc_score: 0.5300825496479167\n",
      "Training:- after 233 epochs, loss: 0.32574397325515747, auc_score: 0.5340456403800145\n",
      "Test:- after 233 epochs, loss: 0.32076382637023926, auc_score: 0.5371390104362899\n",
      "Training:- after 234 epochs, loss: 0.3175835907459259, auc_score: 0.5383559552533981\n",
      "Test:- after 234 epochs, loss: 0.3095272183418274, auc_score: 0.532324754138518\n",
      "Training:- after 235 epochs, loss: 0.3629229962825775, auc_score: 0.5415400113026532\n",
      "Test:- after 235 epochs, loss: 0.3158343434333801, auc_score: 0.5423582029885117\n",
      "Training:- after 236 epochs, loss: 0.34605199098587036, auc_score: 0.5431119478983476\n",
      "Test:- after 236 epochs, loss: 0.3437420129776001, auc_score: 0.5431149552419571\n",
      "Training:- after 237 epochs, loss: 0.30996081233024597, auc_score: 0.5427117891366214\n",
      "Test:- after 237 epochs, loss: 0.30504110455513, auc_score: 0.5455222217248415\n",
      "Training:- after 238 epochs, loss: 0.3173188865184784, auc_score: 0.5346995749060837\n",
      "Test:- after 238 epochs, loss: 0.32779714465141296, auc_score: 0.535054854870538\n",
      "Training:- after 239 epochs, loss: 0.35540148615837097, auc_score: 0.529577433961137\n",
      "Test:- after 239 epochs, loss: 0.3582081198692322, auc_score: 0.5222311533138608\n",
      "Training:- after 240 epochs, loss: 0.3287719190120697, auc_score: 0.5326858759068177\n",
      "Test:- after 240 epochs, loss: 0.29927632212638855, auc_score: 0.531499266985239\n",
      "Training:- after 241 epochs, loss: 0.30752187967300415, auc_score: 0.5352299243780306\n",
      "Test:- after 241 epochs, loss: 0.3037797212600708, auc_score: 0.5435288256966748\n",
      "Training:- after 242 epochs, loss: 0.303741455078125, auc_score: 0.5403436419340613\n",
      "Test:- after 242 epochs, loss: 0.3043667674064636, auc_score: 0.5454554732390549\n",
      "Training:- after 243 epochs, loss: 0.2970322072505951, auc_score: 0.5446085494023631\n",
      "Test:- after 243 epochs, loss: 0.3070692718029022, auc_score: 0.5389042299739\n",
      "Training:- after 244 epochs, loss: 0.2971760332584381, auc_score: 0.5444133168637822\n",
      "Test:- after 244 epochs, loss: 0.30675873160362244, auc_score: 0.5384048504562846\n",
      "Training:- after 245 epochs, loss: 0.30758923292160034, auc_score: 0.5368459174467419\n",
      "Test:- after 245 epochs, loss: 0.3410507142543793, auc_score: 0.5370930524624695\n",
      "Training:- after 246 epochs, loss: 0.30823326110839844, auc_score: 0.5382372141228163\n",
      "Test:- after 246 epochs, loss: 0.3007715344429016, auc_score: 0.5363138434718165\n",
      "Training:- after 247 epochs, loss: 0.35857918858528137, auc_score: 0.5395820066396025\n",
      "Test:- after 247 epochs, loss: 0.29676181077957153, auc_score: 0.5373394361941426\n",
      "Training:- after 248 epochs, loss: 0.31847450137138367, auc_score: 0.5358672653147217\n",
      "Test:- after 248 epochs, loss: 0.31468915939331055, auc_score: 0.5410379464146936\n",
      "Training:- after 249 epochs, loss: 0.2899552285671234, auc_score: 0.5422998686383302\n",
      "Test:- after 249 epochs, loss: 0.29616522789001465, auc_score: 0.5389199223340085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 250 epochs, loss: 0.2933981716632843, auc_score: 0.5373550804175358\n",
      "Test:- after 250 epochs, loss: 0.2881409227848053, auc_score: 0.5345231549353219\n",
      "Training:- after 251 epochs, loss: 0.30649903416633606, auc_score: 0.5439610389767795\n",
      "Test:- after 251 epochs, loss: 0.30813392996788025, auc_score: 0.5369888854072242\n",
      "Training:- after 252 epochs, loss: 0.3498256802558899, auc_score: 0.547491455841972\n",
      "Test:- after 252 epochs, loss: 0.29645606875419617, auc_score: 0.5439337899287875\n",
      "Training:- after 253 epochs, loss: 0.28825896978378296, auc_score: 0.5438579851416172\n",
      "Test:- after 253 epochs, loss: 0.31939736008644104, auc_score: 0.5447021746726303\n",
      "Training:- after 254 epochs, loss: 0.28571775555610657, auc_score: 0.5369342770511643\n",
      "Test:- after 254 epochs, loss: 0.3070569336414337, auc_score: 0.5335160088185593\n",
      "Training:- after 255 epochs, loss: 0.3010843098163605, auc_score: 0.5293244160801699\n",
      "Test:- after 255 epochs, loss: 0.3190414607524872, auc_score: 0.5180223585045255\n",
      "Training:- after 256 epochs, loss: 0.292266309261322, auc_score: 0.5341681561853581\n",
      "Test:- after 256 epochs, loss: 0.2909010648727417, auc_score: 0.5263729291866708\n",
      "Training:- after 257 epochs, loss: 0.3049796521663666, auc_score: 0.5363816035604174\n",
      "Test:- after 257 epochs, loss: 0.309524804353714, auc_score: 0.5311411280344883\n",
      "Training:- after 258 epochs, loss: 0.2844458520412445, auc_score: 0.5380373047710109\n",
      "Test:- after 258 epochs, loss: 0.27989208698272705, auc_score: 0.5362192509944504\n",
      "Training:- after 259 epochs, loss: 0.28724348545074463, auc_score: 0.5403128997701857\n",
      "Test:- after 259 epochs, loss: 0.2930603325366974, auc_score: 0.5375565459648128\n",
      "Training:- after 260 epochs, loss: 0.28620854020118713, auc_score: 0.5401535515253518\n",
      "Test:- after 260 epochs, loss: 0.3072341978549957, auc_score: 0.5444210986392908\n",
      "Training:- after 261 epochs, loss: 0.28398293256759644, auc_score: 0.5381229927870627\n",
      "Test:- after 261 epochs, loss: 0.34198975563049316, auc_score: 0.5361527107868189\n",
      "Training:- after 262 epochs, loss: 0.3470379114151001, auc_score: 0.532715759268121\n",
      "Test:- after 262 epochs, loss: 0.3017161786556244, auc_score: 0.5350524923123601\n",
      "Training:- after 263 epochs, loss: 0.3035928010940552, auc_score: 0.5370060876883236\n",
      "Test:- after 263 epochs, loss: 0.2803497314453125, auc_score: 0.5494183070902858\n",
      "Training:- after 264 epochs, loss: 0.27394747734069824, auc_score: 0.5422115888788015\n",
      "Test:- after 264 epochs, loss: 0.3139004111289978, auc_score: 0.5407591552238027\n",
      "Training:- after 265 epochs, loss: 0.28257668018341064, auc_score: 0.551043259661545\n",
      "Test:- after 265 epochs, loss: 0.26859015226364136, auc_score: 0.5504644043306934\n",
      "Training:- after 266 epochs, loss: 0.288515567779541, auc_score: 0.5520266410451956\n",
      "Test:- after 266 epochs, loss: 0.3358927369117737, auc_score: 0.5529403777357491\n",
      "Training:- after 267 epochs, loss: 0.2893381118774414, auc_score: 0.5441118559876736\n",
      "Test:- after 267 epochs, loss: 0.3685768246650696, auc_score: 0.5410793813330548\n",
      "Training:- after 268 epochs, loss: 0.2931284010410309, auc_score: 0.5344515383768569\n",
      "Test:- after 268 epochs, loss: 0.3275195360183716, auc_score: 0.5346528997914731\n",
      "Training:- after 269 epochs, loss: 0.3330737054347992, auc_score: 0.5284893416886974\n",
      "Test:- after 269 epochs, loss: 0.27236056327819824, auc_score: 0.5289635799222345\n",
      "Training:- after 270 epochs, loss: 0.2834544777870178, auc_score: 0.5279371301506245\n",
      "Test:- after 270 epochs, loss: 0.2676808536052704, auc_score: 0.5284240990881768\n",
      "Training:- after 271 epochs, loss: 0.27843746542930603, auc_score: 0.5367574405979593\n",
      "Test:- after 271 epochs, loss: 0.2797757387161255, auc_score: 0.5379540090747102\n",
      "Training:- after 272 epochs, loss: 0.27206480503082275, auc_score: 0.54592754944609\n",
      "Test:- after 272 epochs, loss: 0.28006094694137573, auc_score: 0.5413071754622221\n",
      "Training:- after 273 epochs, loss: 0.2772597670555115, auc_score: 0.5424280990426334\n",
      "Test:- after 273 epochs, loss: 0.259758323431015, auc_score: 0.5421471768051499\n",
      "Training:- after 274 epochs, loss: 0.3149459958076477, auc_score: 0.5425494331039769\n",
      "Test:- after 274 epochs, loss: 0.2999366819858551, auc_score: 0.5449144443076648\n",
      "Training:- after 275 epochs, loss: 0.27030667662620544, auc_score: 0.5412016007426941\n",
      "Test:- after 275 epochs, loss: 0.26456770300865173, auc_score: 0.5433695737323321\n",
      "Training:- after 276 epochs, loss: 0.2621944844722748, auc_score: 0.5404566595610483\n",
      "Test:- after 276 epochs, loss: 0.26525038480758667, auc_score: 0.5507132034672406\n",
      "Training:- after 277 epochs, loss: 0.26604437828063965, auc_score: 0.5431976414550611\n",
      "Test:- after 277 epochs, loss: 0.26415136456489563, auc_score: 0.5460689705339257\n",
      "Training:- after 278 epochs, loss: 0.2690191864967346, auc_score: 0.5398922782562483\n",
      "Test:- after 278 epochs, loss: 0.25824591517448425, auc_score: 0.5402723470025975\n",
      "Training:- after 279 epochs, loss: 0.26968544721603394, auc_score: 0.5444179099734381\n",
      "Test:- after 279 epochs, loss: 0.3298216164112091, auc_score: 0.5391371875361378\n",
      "Training:- after 280 epochs, loss: 0.2694205641746521, auc_score: 0.5442315221119475\n",
      "Test:- after 280 epochs, loss: 0.29836490750312805, auc_score: 0.5475174518442254\n",
      "Training:- after 281 epochs, loss: 0.2685360610485077, auc_score: 0.5461415791743819\n",
      "Test:- after 281 epochs, loss: 0.26877331733703613, auc_score: 0.5525368341471725\n",
      "Training:- after 282 epochs, loss: 0.2555411458015442, auc_score: 0.5502197147935456\n",
      "Test:- after 282 epochs, loss: 0.25268059968948364, auc_score: 0.5501412312409771\n",
      "Training:- after 283 epochs, loss: 0.2554159462451935, auc_score: 0.5486386691520426\n",
      "Test:- after 283 epochs, loss: 0.2520916163921356, auc_score: 0.5444857363658633\n",
      "Training:- after 284 epochs, loss: 0.2562973201274872, auc_score: 0.5457130069097642\n",
      "Test:- after 284 epochs, loss: 0.2513931691646576, auc_score: 0.5482154603320265\n",
      "Training:- after 285 epochs, loss: 0.2665019631385803, auc_score: 0.5445934311131182\n",
      "Test:- after 285 epochs, loss: 0.2699776291847229, auc_score: 0.5492570935809294\n",
      "Training:- after 286 epochs, loss: 0.2527909278869629, auc_score: 0.5366598397633694\n",
      "Test:- after 286 epochs, loss: 0.27040424942970276, auc_score: 0.5445200618492861\n",
      "Training:- after 287 epochs, loss: 0.2763073742389679, auc_score: 0.5311036510937645\n",
      "Test:- after 287 epochs, loss: 0.2799992561340332, auc_score: 0.5321023068515431\n",
      "Training:- after 288 epochs, loss: 0.2611788213253021, auc_score: 0.529592323797025\n",
      "Test:- after 288 epochs, loss: 0.3016296625137329, auc_score: 0.5429742213816489\n",
      "Training:- after 289 epochs, loss: 0.2542295455932617, auc_score: 0.5350941194933447\n",
      "Test:- after 289 epochs, loss: 0.2576701045036316, auc_score: 0.5385372469731278\n",
      "Training:- after 290 epochs, loss: 0.2556912302970886, auc_score: 0.5429314469899734\n",
      "Test:- after 290 epochs, loss: 0.24775086343288422, auc_score: 0.5290327780078163\n",
      "Training:- after 291 epochs, loss: 0.2700002193450928, auc_score: 0.5554996585344577\n",
      "Test:- after 291 epochs, loss: 0.2720514237880707, auc_score: 0.5603641510395878\n",
      "Training:- after 292 epochs, loss: 0.25588545203208923, auc_score: 0.5568529132247924\n",
      "Test:- after 292 epochs, loss: 0.26862943172454834, auc_score: 0.5497811152020672\n",
      "Training:- after 293 epochs, loss: 0.2544545531272888, auc_score: 0.5563973695134456\n",
      "Test:- after 293 epochs, loss: 0.24951490759849548, auc_score: 0.552848284596245\n",
      "Training:- after 294 epochs, loss: 0.24577701091766357, auc_score: 0.5498354042043105\n",
      "Test:- after 294 epochs, loss: 0.2571520209312439, auc_score: 0.5485446113156589\n",
      "Training:- after 295 epochs, loss: 0.25519999861717224, auc_score: 0.5365323092633745\n",
      "Test:- after 295 epochs, loss: 0.2494792938232422, auc_score: 0.5428849446601833\n",
      "Training:- after 296 epochs, loss: 0.25478222966194153, auc_score: 0.534627150442754\n",
      "Test:- after 296 epochs, loss: 0.24747037887573242, auc_score: 0.5380367359144904\n",
      "Training:- after 297 epochs, loss: 0.2839934527873993, auc_score: 0.5396343650027385\n",
      "Test:- after 297 epochs, loss: 0.2686667740345001, auc_score: 0.529034636968067\n",
      "Training:- after 298 epochs, loss: 0.24754467606544495, auc_score: 0.5475515924037507\n",
      "Test:- after 298 epochs, loss: 0.2931542694568634, auc_score: 0.5498011347739964\n",
      "Training:- after 299 epochs, loss: 0.26760298013687134, auc_score: 0.5523755768836844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:- after 299 epochs, loss: 0.24685274064540863, auc_score: 0.5514139195710589\n",
      "Training:- after 300 epochs, loss: 0.25631266832351685, auc_score: 0.5509955130088579\n",
      "Test:- after 300 epochs, loss: 0.2405966967344284, auc_score: 0.5446085147840187\n",
      "Training:- after 301 epochs, loss: 0.25412672758102417, auc_score: 0.5415253977083299\n",
      "Test:- after 301 epochs, loss: 0.2658120393753052, auc_score: 0.5423070380608123\n",
      "Training:- after 302 epochs, loss: 0.24353989958763123, auc_score: 0.5274011426595787\n",
      "Test:- after 302 epochs, loss: 0.24344362318515778, auc_score: 0.5295647328506254\n",
      "Training:- after 303 epochs, loss: 0.2957700490951538, auc_score: 0.5269345419640544\n",
      "Test:- after 303 epochs, loss: 0.2576608657836914, auc_score: 0.5306610282350571\n",
      "Training:- after 304 epochs, loss: 0.2756590247154236, auc_score: 0.5348590160559423\n",
      "Test:- after 304 epochs, loss: 0.2463626265525818, auc_score: 0.5397320361645483\n",
      "Training:- after 305 epochs, loss: 0.24568957090377808, auc_score: 0.5485864668178994\n",
      "Test:- after 305 epochs, loss: 0.2841319441795349, auc_score: 0.5432350073923202\n",
      "Training:- after 306 epochs, loss: 0.2412940412759781, auc_score: 0.556782332614543\n",
      "Test:- after 306 epochs, loss: 0.24432270228862762, auc_score: 0.5560687249522204\n",
      "Training:- after 307 epochs, loss: 0.2515222430229187, auc_score: 0.5609083630001553\n",
      "Test:- after 307 epochs, loss: 0.2615005671977997, auc_score: 0.5646834109868903\n",
      "Training:- after 308 epochs, loss: 0.260275661945343, auc_score: 0.5578055041616578\n",
      "Test:- after 308 epochs, loss: 0.24854639172554016, auc_score: 0.5600883348068236\n",
      "Training:- after 309 epochs, loss: 0.2525401711463928, auc_score: 0.5439469893426707\n",
      "Test:- after 309 epochs, loss: 0.2909066379070282, auc_score: 0.5414191513939715\n",
      "Training:- after 310 epochs, loss: 0.2549731731414795, auc_score: 0.5294978456200369\n",
      "Test:- after 310 epochs, loss: 0.26843196153640747, auc_score: 0.5236633578417658\n",
      "Training:- after 311 epochs, loss: 0.2531033754348755, auc_score: 0.5278036500682474\n",
      "Test:- after 311 epochs, loss: 0.23453840613365173, auc_score: 0.5227665058883655\n",
      "Training:- after 312 epochs, loss: 0.2528897523880005, auc_score: 0.5457560476607526\n",
      "Test:- after 312 epochs, loss: 0.2386399358510971, auc_score: 0.5411484239871776\n",
      "Training:- after 313 epochs, loss: 0.2813456952571869, auc_score: 0.5636992991048038\n",
      "Test:- after 313 epochs, loss: 0.25984975695610046, auc_score: 0.5634018754981578\n",
      "Training:- after 314 epochs, loss: 0.27683213353157043, auc_score: 0.5598575780810708\n",
      "Test:- after 314 epochs, loss: 0.237715944647789, auc_score: 0.5530139247935559\n",
      "Training:- after 315 epochs, loss: 0.25534576177597046, auc_score: 0.5380757511261184\n",
      "Test:- after 315 epochs, loss: 0.231765478849411, auc_score: 0.5384138592636528\n",
      "Training:- after 316 epochs, loss: 0.24796709418296814, auc_score: 0.5262366457498606\n",
      "Test:- after 316 epochs, loss: 0.23266370594501495, auc_score: 0.5321670782491703\n",
      "Training:- after 317 epochs, loss: 0.24846875667572021, auc_score: 0.5311868487802374\n",
      "Test:- after 317 epochs, loss: 0.2419997900724411, auc_score: 0.5404463898245863\n",
      "Training:- after 318 epochs, loss: 0.26383793354034424, auc_score: 0.5494179542245268\n",
      "Test:- after 318 epochs, loss: 0.2745477259159088, auc_score: 0.5542174150380559\n",
      "Training:- after 319 epochs, loss: 0.24608129262924194, auc_score: 0.5614178160641682\n",
      "Test:- after 319 epochs, loss: 0.24852347373962402, auc_score: 0.5495541417510037\n",
      "Training:- after 320 epochs, loss: 0.2555953860282898, auc_score: 0.5619866247534733\n",
      "Test:- after 320 epochs, loss: 0.29843229055404663, auc_score: 0.563405577875513\n",
      "Training:- after 321 epochs, loss: 0.24994444847106934, auc_score: 0.5538187135741993\n",
      "Test:- after 321 epochs, loss: 0.2433413714170456, auc_score: 0.5494064569958457\n",
      "Training:- after 322 epochs, loss: 0.2363741546869278, auc_score: 0.5329592592815942\n",
      "Test:- after 322 epochs, loss: 0.2376357465982437, auc_score: 0.5312148740445628\n",
      "Training:- after 323 epochs, loss: 0.23710989952087402, auc_score: 0.5238655370635914\n",
      "Test:- after 323 epochs, loss: 0.2635226547718048, auc_score: 0.525178960673354\n",
      "Training:- after 324 epochs, loss: 0.23957370221614838, auc_score: 0.5238239817046558\n",
      "Test:- after 324 epochs, loss: 0.2890909016132355, auc_score: 0.5286842758075286\n",
      "Training:- after 325 epochs, loss: 0.24173440039157867, auc_score: 0.5357493723011505\n",
      "Test:- after 325 epochs, loss: 0.2826654314994812, auc_score: 0.5315744989200621\n",
      "Training:- after 326 epochs, loss: 0.2346988469362259, auc_score: 0.556520483215557\n",
      "Test:- after 326 epochs, loss: 0.22913521528244019, auc_score: 0.5571719152761768\n",
      "Training:- after 327 epochs, loss: 0.23642247915267944, auc_score: 0.5668824696375817\n",
      "Test:- after 327 epochs, loss: 0.2374066710472107, auc_score: 0.5697464726384677\n",
      "Training:- after 328 epochs, loss: 0.2401529848575592, auc_score: 0.5686591737560382\n",
      "Test:- after 328 epochs, loss: 0.22851477563381195, auc_score: 0.5629479068356269\n",
      "Training:- after 329 epochs, loss: 0.22480084002017975, auc_score: 0.5545961219453942\n",
      "Test:- after 329 epochs, loss: 0.2515060603618622, auc_score: 0.5561373075292242\n",
      "Training:- after 330 epochs, loss: 0.23239628970623016, auc_score: 0.5373903263478962\n",
      "Test:- after 330 epochs, loss: 0.22748614847660065, auc_score: 0.5291806896929048\n",
      "Training:- after 331 epochs, loss: 0.24990597367286682, auc_score: 0.5256656397924074\n",
      "Test:- after 331 epochs, loss: 0.22745943069458008, auc_score: 0.5232022082458254\n",
      "Training:- after 332 epochs, loss: 0.23328152298927307, auc_score: 0.5293394915282268\n",
      "Test:- after 332 epochs, loss: 0.24806895852088928, auc_score: 0.5194103272391768\n",
      "Training:- after 333 epochs, loss: 0.2232142835855484, auc_score: 0.5435695544178543\n",
      "Test:- after 333 epochs, loss: 0.2649083435535431, auc_score: 0.5491048577926495\n",
      "Training:- after 334 epochs, loss: 0.23833104968070984, auc_score: 0.5609521914155767\n",
      "Test:- after 334 epochs, loss: 0.22386115789413452, auc_score: 0.553802758100155\n",
      "Training:- after 335 epochs, loss: 0.23291616141796112, auc_score: 0.5634799812106266\n",
      "Test:- after 335 epochs, loss: 0.2388361096382141, auc_score: 0.573058558491345\n",
      "Training:- after 336 epochs, loss: 0.22629131376743317, auc_score: 0.5594470237516642\n",
      "Test:- after 336 epochs, loss: 0.25980550050735474, auc_score: 0.5582284264243428\n",
      "Training:- after 337 epochs, loss: 0.22764791548252106, auc_score: 0.5487723100125511\n",
      "Test:- after 337 epochs, loss: 0.23146271705627441, auc_score: 0.5606059122396678\n",
      "Training:- after 338 epochs, loss: 0.2231963872909546, auc_score: 0.5404134394311355\n",
      "Test:- after 338 epochs, loss: 0.23514163494110107, auc_score: 0.5381741186725408\n",
      "Training:- after 339 epochs, loss: 0.24240925908088684, auc_score: 0.531522119170146\n",
      "Test:- after 339 epochs, loss: 0.22267255187034607, auc_score: 0.5282912331683273\n",
      "Training:- after 340 epochs, loss: 0.2238284796476364, auc_score: 0.530029322517711\n",
      "Test:- after 340 epochs, loss: 0.21368208527565002, auc_score: 0.5296043492209154\n",
      "Training:- after 341 epochs, loss: 0.25087615847587585, auc_score: 0.5405003472832371\n",
      "Test:- after 341 epochs, loss: 0.22700729966163635, auc_score: 0.5382239748673548\n",
      "Training:- after 342 epochs, loss: 0.21533134579658508, auc_score: 0.5530869626304479\n",
      "Test:- after 342 epochs, loss: 0.218229740858078, auc_score: 0.5550277724931081\n",
      "Training:- after 343 epochs, loss: 0.2363462597131729, auc_score: 0.5687984260206811\n",
      "Test:- after 343 epochs, loss: 0.2171357125043869, auc_score: 0.5601850691296958\n",
      "Training:- after 344 epochs, loss: 0.27009475231170654, auc_score: 0.5676619106401182\n",
      "Test:- after 344 epochs, loss: 0.21303725242614746, auc_score: 0.5723168395686218\n",
      "Training:- after 345 epochs, loss: 0.258049875497818, auc_score: 0.5579859521369241\n",
      "Test:- after 345 epochs, loss: 0.2272273749113083, auc_score: 0.561430920664053\n",
      "Training:- after 346 epochs, loss: 0.2292943298816681, auc_score: 0.5431230283313973\n",
      "Test:- after 346 epochs, loss: 0.21525566279888153, auc_score: 0.548300969394924\n",
      "Training:- after 347 epochs, loss: 0.220068097114563, auc_score: 0.5381171648024178\n",
      "Test:- after 347 epochs, loss: 0.24222436547279358, auc_score: 0.5359062710998206\n",
      "Training:- after 348 epochs, loss: 0.26341432332992554, auc_score: 0.5346254525267468\n",
      "Test:- after 348 epochs, loss: 0.2290242463350296, auc_score: 0.5227180299249079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 349 epochs, loss: 0.21741245687007904, auc_score: 0.5414493084930099\n",
      "Test:- after 349 epochs, loss: 0.2120356410741806, auc_score: 0.5420766078140989\n",
      "Training:- after 350 epochs, loss: 0.22100494801998138, auc_score: 0.5450492848047019\n",
      "Test:- after 350 epochs, loss: 0.2409035563468933, auc_score: 0.5322266426929184\n",
      "Training:- after 351 epochs, loss: 0.21663761138916016, auc_score: 0.5429654785260053\n",
      "Test:- after 351 epochs, loss: 0.2135685533285141, auc_score: 0.5451460123126585\n",
      "Training:- after 352 epochs, loss: 0.2110542356967926, auc_score: 0.5443833291203691\n",
      "Test:- after 352 epochs, loss: 0.20700252056121826, auc_score: 0.5415101254269703\n",
      "Training:- after 353 epochs, loss: 0.22100915014743805, auc_score: 0.5487405361972446\n",
      "Test:- after 353 epochs, loss: 0.20348228514194489, auc_score: 0.5446939554570742\n",
      "Training:- after 354 epochs, loss: 0.20676471292972565, auc_score: 0.5534417308069585\n",
      "Test:- after 354 epochs, loss: 0.2607176601886749, auc_score: 0.54598922797816\n",
      "Training:- after 355 epochs, loss: 0.21927058696746826, auc_score: 0.565196302900439\n",
      "Test:- after 355 epochs, loss: 0.23023472726345062, auc_score: 0.5559126375723844\n",
      "Training:- after 356 epochs, loss: 0.24734678864479065, auc_score: 0.5644807432544459\n",
      "Test:- after 356 epochs, loss: 0.22188271582126617, auc_score: 0.5660569805511724\n",
      "Training:- after 357 epochs, loss: 0.204054057598114, auc_score: 0.563304589583915\n",
      "Test:- after 357 epochs, loss: 0.21887482702732086, auc_score: 0.5668338083318722\n",
      "Training:- after 358 epochs, loss: 0.20596790313720703, auc_score: 0.5603591978366447\n",
      "Test:- after 358 epochs, loss: 0.20539464056491852, auc_score: 0.558656702266688\n",
      "Training:- after 359 epochs, loss: 0.20591124892234802, auc_score: 0.552379962119584\n",
      "Test:- after 359 epochs, loss: 0.2051667869091034, auc_score: 0.5415051858152007\n",
      "Training:- after 360 epochs, loss: 0.20907062292099, auc_score: 0.534258428505371\n",
      "Test:- after 360 epochs, loss: 0.3249244689941406, auc_score: 0.5316853837229689\n",
      "Training:- after 361 epochs, loss: 0.20563474297523499, auc_score: 0.5366656165958333\n",
      "Test:- after 361 epochs, loss: 0.2183818817138672, auc_score: 0.5290236417466516\n",
      "Training:- after 362 epochs, loss: 0.2197199910879135, auc_score: 0.5283932692852291\n",
      "Test:- after 362 epochs, loss: 0.20192736387252808, auc_score: 0.5237293509306614\n",
      "Training:- after 363 epochs, loss: 0.19609880447387695, auc_score: 0.5328443067763693\n",
      "Test:- after 363 epochs, loss: 0.19400864839553833, auc_score: 0.5327280210590976\n",
      "Training:- after 364 epochs, loss: 0.1954042762517929, auc_score: 0.5436596631894051\n",
      "Test:- after 364 epochs, loss: 0.27875369787216187, auc_score: 0.5457133495728121\n",
      "Training:- after 365 epochs, loss: 0.19697055220603943, auc_score: 0.5613383383384225\n",
      "Test:- after 365 epochs, loss: 0.23813684284687042, auc_score: 0.5660164036144654\n",
      "Training:- after 366 epochs, loss: 0.20152223110198975, auc_score: 0.5730656890617527\n",
      "Test:- after 366 epochs, loss: 0.20080463588237762, auc_score: 0.5650571459302448\n",
      "Training:- after 367 epochs, loss: 0.19813133776187897, auc_score: 0.5748821680079133\n",
      "Test:- after 367 epochs, loss: 0.20273354649543762, auc_score: 0.56851406903395\n",
      "Training:- after 368 epochs, loss: 0.20052266120910645, auc_score: 0.5649476156402771\n",
      "Test:- after 368 epochs, loss: 0.19892898201942444, auc_score: 0.5690908938303658\n",
      "Training:- after 369 epochs, loss: 0.2258540689945221, auc_score: 0.5544912381088062\n",
      "Test:- after 369 epochs, loss: 0.19860929250717163, auc_score: 0.5550702519108743\n",
      "Training:- after 370 epochs, loss: 0.19181124866008759, auc_score: 0.5456331810127913\n",
      "Test:- after 370 epochs, loss: 0.19839303195476532, auc_score: 0.5492262062413813\n",
      "Training:- after 371 epochs, loss: 0.19452591240406036, auc_score: 0.5465852133322233\n",
      "Test:- after 371 epochs, loss: 0.18761888146400452, auc_score: 0.5435803045959218\n",
      "Training:- after 372 epochs, loss: 0.20229056477546692, auc_score: 0.5486578077850345\n",
      "Test:- after 372 epochs, loss: 0.2011888176202774, auc_score: 0.5419430859734921\n",
      "Training:- after 373 epochs, loss: 0.20696839690208435, auc_score: 0.5522926060675223\n",
      "Test:- after 373 epochs, loss: 0.18955431878566742, auc_score: 0.5502767084093393\n",
      "Training:- after 374 epochs, loss: 0.193933367729187, auc_score: 0.5487048836218875\n",
      "Test:- after 374 epochs, loss: 0.205291748046875, auc_score: 0.5515955536655089\n",
      "Training:- after 375 epochs, loss: 0.21095384657382965, auc_score: 0.5459357610036343\n",
      "Test:- after 375 epochs, loss: 0.19853970408439636, auc_score: 0.542890708058686\n",
      "Training:- after 376 epochs, loss: 0.20164519548416138, auc_score: 0.5408994228455899\n",
      "Test:- after 376 epochs, loss: 0.19158844649791718, auc_score: 0.5391370476478247\n",
      "Training:- after 377 epochs, loss: 0.20116759836673737, auc_score: 0.5457181532940726\n",
      "Test:- after 377 epochs, loss: 0.20203325152397156, auc_score: 0.5497930709898995\n",
      "Training:- after 378 epochs, loss: 0.18535131216049194, auc_score: 0.5455417207155335\n",
      "Test:- after 378 epochs, loss: 0.1943778395652771, auc_score: 0.5442857395988376\n",
      "Training:- after 379 epochs, loss: 0.1886737197637558, auc_score: 0.5548978317555203\n",
      "Test:- after 379 epochs, loss: 0.21635526418685913, auc_score: 0.5618814729431134\n",
      "Training:- after 380 epochs, loss: 0.19296880066394806, auc_score: 0.5618037041589576\n",
      "Test:- after 380 epochs, loss: 0.183329239487648, auc_score: 0.5486645981848093\n",
      "Training:- after 381 epochs, loss: 0.1923343539237976, auc_score: 0.5656821631341098\n",
      "Test:- after 381 epochs, loss: 0.18345870077610016, auc_score: 0.5659090937351174\n",
      "Training:- after 382 epochs, loss: 0.18119563162326813, auc_score: 0.5636008371920126\n",
      "Test:- after 382 epochs, loss: 0.18911781907081604, auc_score: 0.5631832114128968\n",
      "Training:- after 383 epochs, loss: 0.1860661506652832, auc_score: 0.5622005413929014\n",
      "Test:- after 383 epochs, loss: 0.1828424483537674, auc_score: 0.5629304176878513\n",
      "Training:- after 384 epochs, loss: 0.18803143501281738, auc_score: 0.5603478690632199\n",
      "Test:- after 384 epochs, loss: 0.18852517008781433, auc_score: 0.5645027032639363\n",
      "Training:- after 385 epochs, loss: 0.19268572330474854, auc_score: 0.5573178533048359\n",
      "Test:- after 385 epochs, loss: 0.2017691284418106, auc_score: 0.5640823202310831\n",
      "Training:- after 386 epochs, loss: 0.19198839366436005, auc_score: 0.5541131270253746\n",
      "Test:- after 386 epochs, loss: 0.20106172561645508, auc_score: 0.5512998359887243\n",
      "Training:- after 387 epochs, loss: 0.18522332608699799, auc_score: 0.5569670482845273\n",
      "Test:- after 387 epochs, loss: 0.18895108997821808, auc_score: 0.5592135914241625\n",
      "Training:- after 388 epochs, loss: 0.18833594024181366, auc_score: 0.5547392028073108\n",
      "Test:- after 388 epochs, loss: 0.19054092466831207, auc_score: 0.5611136477525233\n",
      "Training:- after 389 epochs, loss: 0.18039055168628693, auc_score: 0.5516390791758538\n",
      "Test:- after 389 epochs, loss: 0.18208374083042145, auc_score: 0.5476097315014803\n",
      "Training:- after 390 epochs, loss: 0.17792649567127228, auc_score: 0.5499195441990437\n",
      "Test:- after 390 epochs, loss: 0.18697872757911682, auc_score: 0.5432195854829505\n",
      "Training:- after 391 epochs, loss: 0.18317550420761108, auc_score: 0.5507209005965754\n",
      "Test:- after 391 epochs, loss: 0.17413242161273956, auc_score: 0.5449436996168926\n",
      "Training:- after 392 epochs, loss: 0.17953990399837494, auc_score: 0.5467629370828324\n",
      "Test:- after 392 epochs, loss: 0.1789494901895523, auc_score: 0.5498472077670966\n",
      "Training:- after 393 epochs, loss: 0.1772637665271759, auc_score: 0.5499242262561087\n",
      "Test:- after 393 epochs, loss: 0.1829156130552292, auc_score: 0.5532589345111308\n",
      "Training:- after 394 epochs, loss: 0.17862577736377716, auc_score: 0.5551618564578878\n",
      "Test:- after 394 epochs, loss: 0.18386998772621155, auc_score: 0.5610404271007805\n",
      "Training:- after 395 epochs, loss: 0.1763300746679306, auc_score: 0.5585072544997459\n",
      "Test:- after 395 epochs, loss: 0.18109333515167236, auc_score: 0.5647230677693597\n",
      "Training:- after 396 epochs, loss: 0.1784350425004959, auc_score: 0.5543548180127844\n",
      "Test:- after 396 epochs, loss: 0.17728586494922638, auc_score: 0.5513256935662567\n",
      "Training:- after 397 epochs, loss: 0.17614613473415375, auc_score: 0.553238862741775\n",
      "Test:- after 397 epochs, loss: 0.17340974509716034, auc_score: 0.5595731106062697\n",
      "Training:- after 398 epochs, loss: 0.1745099276304245, auc_score: 0.5559438933593978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:- after 398 epochs, loss: 0.2203957587480545, auc_score: 0.5444591731295068\n",
      "Training:- after 399 epochs, loss: 0.1810242235660553, auc_score: 0.5587195185378645\n",
      "Test:- after 399 epochs, loss: 0.18647725880146027, auc_score: 0.5524491708042522\n",
      "Training:- after 400 epochs, loss: 0.17102746665477753, auc_score: 0.5627225160556628\n",
      "Test:- after 400 epochs, loss: 0.17558583617210388, auc_score: 0.5609569697331429\n",
      "Training:- after 401 epochs, loss: 0.17047825455665588, auc_score: 0.5634585777332013\n",
      "Test:- after 401 epochs, loss: 0.18624725937843323, auc_score: 0.5591173606992177\n",
      "Training:- after 402 epochs, loss: 0.17293940484523773, auc_score: 0.5636730510112552\n",
      "Test:- after 402 epochs, loss: 0.18977902829647064, auc_score: 0.564756594335083\n",
      "Training:- after 403 epochs, loss: 0.1721278727054596, auc_score: 0.5624348138299805\n",
      "Test:- after 403 epochs, loss: 0.17648589611053467, auc_score: 0.5693256917010792\n",
      "Training:- after 404 epochs, loss: 0.1718723028898239, auc_score: 0.5590935548603355\n",
      "Test:- after 404 epochs, loss: 0.17118625342845917, auc_score: 0.558513145771083\n",
      "Training:- after 405 epochs, loss: 0.1706123650074005, auc_score: 0.5535441228298619\n",
      "Test:- after 405 epochs, loss: 0.16676263511180878, auc_score: 0.5545863658010999\n",
      "Training:- after 406 epochs, loss: 0.1725560575723648, auc_score: 0.5548170912535959\n",
      "Test:- after 406 epochs, loss: 0.16922631859779358, auc_score: 0.5521087759088699\n",
      "Training:- after 407 epochs, loss: 0.2060147225856781, auc_score: 0.5537786110559285\n",
      "Test:- after 407 epochs, loss: 0.1815745234489441, auc_score: 0.5462649323002737\n",
      "Training:- after 408 epochs, loss: 0.1709740310907364, auc_score: 0.5548373348528466\n",
      "Test:- after 408 epochs, loss: 0.19829827547073364, auc_score: 0.548822889582735\n",
      "Training:- after 409 epochs, loss: 0.16896973550319672, auc_score: 0.5559940504967701\n",
      "Test:- after 409 epochs, loss: 0.18566454946994781, auc_score: 0.5647215973877566\n",
      "Training:- after 410 epochs, loss: 0.17181552946567535, auc_score: 0.5572285157736135\n",
      "Test:- after 410 epochs, loss: 0.17919540405273438, auc_score: 0.5548780733462404\n",
      "Training:- after 411 epochs, loss: 0.16851311922073364, auc_score: 0.5592899130437166\n",
      "Test:- after 411 epochs, loss: 0.16937702894210815, auc_score: 0.5529383136059726\n",
      "Training:- after 412 epochs, loss: 0.16846218705177307, auc_score: 0.5642897255764154\n",
      "Test:- after 412 epochs, loss: 0.17841987311840057, auc_score: 0.5615855376622859\n",
      "Training:- after 413 epochs, loss: 0.16705743968486786, auc_score: 0.5571620994653761\n",
      "Test:- after 413 epochs, loss: 0.1636257767677307, auc_score: 0.5644738645110189\n",
      "Training:- after 414 epochs, loss: 0.16704179346561432, auc_score: 0.5567371116131533\n",
      "Test:- after 414 epochs, loss: 0.17059603333473206, auc_score: 0.5688772284208288\n",
      "Training:- after 415 epochs, loss: 0.17890778183937073, auc_score: 0.5566948136076615\n",
      "Test:- after 415 epochs, loss: 0.20434343814849854, auc_score: 0.5571444194510659\n",
      "Training:- after 416 epochs, loss: 0.17340515553951263, auc_score: 0.5532441960244772\n",
      "Test:- after 416 epochs, loss: 0.1982884407043457, auc_score: 0.5495456427588215\n",
      "Training:- after 417 epochs, loss: 0.1791824996471405, auc_score: 0.5546165733194608\n",
      "Test:- after 417 epochs, loss: 0.1896161437034607, auc_score: 0.5562123000996005\n",
      "Training:- after 418 epochs, loss: 0.16760103404521942, auc_score: 0.557762202504865\n",
      "Test:- after 418 epochs, loss: 0.17219345271587372, auc_score: 0.5631290932874748\n",
      "Training:- after 419 epochs, loss: 0.16965743899345398, auc_score: 0.5617274942363637\n",
      "Test:- after 419 epochs, loss: 0.16343243420124054, auc_score: 0.561066048422495\n",
      "Training:- after 420 epochs, loss: 0.16423292458057404, auc_score: 0.561435039607\n",
      "Test:- after 420 epochs, loss: 0.1598612517118454, auc_score: 0.5600249902699906\n",
      "Training:- after 421 epochs, loss: 0.16163542866706848, auc_score: 0.565104545089433\n",
      "Test:- after 421 epochs, loss: 0.17825916409492493, auc_score: 0.5660859374319988\n",
      "Training:- after 422 epochs, loss: 0.16362425684928894, auc_score: 0.5668352055171693\n",
      "Test:- after 422 epochs, loss: 0.1627407670021057, auc_score: 0.5619362967273596\n",
      "Training:- after 423 epochs, loss: 0.16179494559764862, auc_score: 0.5670876910988463\n",
      "Test:- after 423 epochs, loss: 0.1710195541381836, auc_score: 0.566223609292563\n",
      "Training:- after 424 epochs, loss: 0.1705036461353302, auc_score: 0.565011415173119\n",
      "Test:- after 424 epochs, loss: 0.19982440769672394, auc_score: 0.5589637384623228\n",
      "Training:- after 425 epochs, loss: 0.15933342278003693, auc_score: 0.5622509371744908\n",
      "Test:- after 425 epochs, loss: 0.18377038836479187, auc_score: 0.5605289861019407\n",
      "Training:- after 426 epochs, loss: 0.15916818380355835, auc_score: 0.5606668411018696\n",
      "Test:- after 426 epochs, loss: 0.1722010374069214, auc_score: 0.5602006464705246\n",
      "Training:- after 427 epochs, loss: 0.16141140460968018, auc_score: 0.5591913074694814\n",
      "Test:- after 427 epochs, loss: 0.16228526830673218, auc_score: 0.5567854598222113\n",
      "Training:- after 428 epochs, loss: 0.16227364540100098, auc_score: 0.5556633235484423\n",
      "Test:- after 428 epochs, loss: 0.16160233318805695, auc_score: 0.550568866705711\n",
      "Training:- after 429 epochs, loss: 0.15680959820747375, auc_score: 0.5548648340476079\n",
      "Test:- after 429 epochs, loss: 0.15738916397094727, auc_score: 0.5555648161618875\n",
      "Training:- after 430 epochs, loss: 0.16899654269218445, auc_score: 0.5575396322422367\n",
      "Test:- after 430 epochs, loss: 0.1669500470161438, auc_score: 0.5553323124595102\n",
      "Training:- after 431 epochs, loss: 0.17536447942256927, auc_score: 0.5587651768557713\n",
      "Test:- after 431 epochs, loss: 0.1607527732849121, auc_score: 0.564003718542227\n",
      "Training:- after 432 epochs, loss: 0.16264338791370392, auc_score: 0.5625131694727801\n",
      "Test:- after 432 epochs, loss: 0.15814903378486633, auc_score: 0.5595123306885116\n",
      "Training:- after 433 epochs, loss: 0.16897675395011902, auc_score: 0.5681082014463313\n",
      "Test:- after 433 epochs, loss: 0.18906539678573608, auc_score: 0.5668705709805736\n",
      "Training:- after 434 epochs, loss: 0.1617552787065506, auc_score: 0.5632608201369652\n",
      "Test:- after 434 epochs, loss: 0.1585593819618225, auc_score: 0.5680067562946632\n",
      "Training:- after 435 epochs, loss: 0.16631822288036346, auc_score: 0.5679490987715418\n",
      "Test:- after 435 epochs, loss: 0.15433822572231293, auc_score: 0.567861160538315\n",
      "Training:- after 436 epochs, loss: 0.16790352761745453, auc_score: 0.5649891138116682\n",
      "Test:- after 436 epochs, loss: 0.1556929051876068, auc_score: 0.559632898871319\n",
      "Training:- after 437 epochs, loss: 0.15756551921367645, auc_score: 0.5581684368990283\n",
      "Test:- after 437 epochs, loss: 0.22698231041431427, auc_score: 0.5617058105253211\n",
      "Training:- after 438 epochs, loss: 0.15495476126670837, auc_score: 0.5521626961501241\n",
      "Test:- after 438 epochs, loss: 0.1634160876274109, auc_score: 0.5605011763052823\n",
      "Training:- after 439 epochs, loss: 0.16044972836971283, auc_score: 0.5552157990545247\n",
      "Test:- after 439 epochs, loss: 0.15437425673007965, auc_score: 0.5568075031117379\n",
      "Training:- after 440 epochs, loss: 0.18110685050487518, auc_score: 0.5525780985585677\n",
      "Test:- after 440 epochs, loss: 0.15410999953746796, auc_score: 0.5594867870825266\n",
      "Training:- after 441 epochs, loss: 0.16039258241653442, auc_score: 0.5576978267432001\n",
      "Test:- after 441 epochs, loss: 0.17244763672351837, auc_score: 0.5544382831414065\n",
      "Training:- after 442 epochs, loss: 0.15564417839050293, auc_score: 0.5618575932288443\n",
      "Test:- after 442 epochs, loss: 0.15871964395046234, auc_score: 0.5662253625594214\n",
      "Training:- after 443 epochs, loss: 0.15638023614883423, auc_score: 0.5676302517935431\n",
      "Test:- after 443 epochs, loss: 0.1897435486316681, auc_score: 0.5632436773591076\n",
      "Training:- after 444 epochs, loss: 0.15513034164905548, auc_score: 0.5669446523855352\n",
      "Test:- after 444 epochs, loss: 0.1584891378879547, auc_score: 0.5673744922054231\n",
      "Training:- after 445 epochs, loss: 0.17945101857185364, auc_score: 0.5658424878216378\n",
      "Test:- after 445 epochs, loss: 0.1605260819196701, auc_score: 0.5722145843203231\n",
      "Training:- after 446 epochs, loss: 0.1639392375946045, auc_score: 0.5667687488412534\n",
      "Test:- after 446 epochs, loss: 0.21207939088344574, auc_score: 0.5675796461882611\n",
      "Training:- after 447 epochs, loss: 0.1714651882648468, auc_score: 0.5590944276135026\n",
      "Test:- after 447 epochs, loss: 0.1587727963924408, auc_score: 0.5596804018338426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 448 epochs, loss: 0.1616634726524353, auc_score: 0.558508897404897\n",
      "Test:- after 448 epochs, loss: 0.18477410078048706, auc_score: 0.5591889524292694\n",
      "Training:- after 449 epochs, loss: 0.16799484193325043, auc_score: 0.5649087992481163\n",
      "Test:- after 449 epochs, loss: 0.15955324470996857, auc_score: 0.5614211191562435\n",
      "Training:- after 450 epochs, loss: 0.15116436779499054, auc_score: 0.5679934053658608\n",
      "Test:- after 450 epochs, loss: 0.18030716478824615, auc_score: 0.5686086055559908\n",
      "Training:- after 451 epochs, loss: 0.15607237815856934, auc_score: 0.5643858194499479\n",
      "Test:- after 451 epochs, loss: 0.15573883056640625, auc_score: 0.564121902406452\n",
      "Training:- after 452 epochs, loss: 0.1547309309244156, auc_score: 0.5611996512212789\n",
      "Test:- after 452 epochs, loss: 0.16056512296199799, auc_score: 0.5659407986441403\n",
      "Training:- after 453 epochs, loss: 0.14869044721126556, auc_score: 0.5562475660478914\n",
      "Test:- after 453 epochs, loss: 0.15685974061489105, auc_score: 0.5593791787747773\n",
      "Training:- after 454 epochs, loss: 0.15260358154773712, auc_score: 0.5578467741765132\n",
      "Test:- after 454 epochs, loss: 0.15086399018764496, auc_score: 0.5510023277415311\n",
      "Training:- after 455 epochs, loss: 0.15197180211544037, auc_score: 0.5582397971595392\n",
      "Test:- after 455 epochs, loss: 0.1485646814107895, auc_score: 0.5636881740285223\n",
      "Training:- after 456 epochs, loss: 0.1490403115749359, auc_score: 0.5647362431539992\n",
      "Test:- after 456 epochs, loss: 0.14925895631313324, auc_score: 0.5590456384067405\n",
      "Training:- after 457 epochs, loss: 0.14801229536533356, auc_score: 0.5764167249248286\n",
      "Test:- after 457 epochs, loss: 0.15069818496704102, auc_score: 0.5768307059199491\n",
      "Training:- after 458 epochs, loss: 0.1503220796585083, auc_score: 0.5800533680498006\n",
      "Test:- after 458 epochs, loss: 0.14633667469024658, auc_score: 0.583134095071828\n",
      "Training:- after 459 epochs, loss: 0.15566490590572357, auc_score: 0.5750518317776532\n",
      "Test:- after 459 epochs, loss: 0.16039593517780304, auc_score: 0.5746127611714807\n",
      "Training:- after 460 epochs, loss: 0.14504171907901764, auc_score: 0.5638293064784846\n",
      "Test:- after 460 epochs, loss: 0.14403651654720306, auc_score: 0.5698073395978429\n",
      "Training:- after 461 epochs, loss: 0.1466425508260727, auc_score: 0.5548394633574246\n",
      "Test:- after 461 epochs, loss: 0.1598908007144928, auc_score: 0.5530920446448888\n",
      "Training:- after 462 epochs, loss: 0.14794650673866272, auc_score: 0.557503162815032\n",
      "Test:- after 462 epochs, loss: 0.16626188158988953, auc_score: 0.5566077363832715\n",
      "Training:- after 463 epochs, loss: 0.1497422456741333, auc_score: 0.5538274781095751\n",
      "Test:- after 463 epochs, loss: 0.14484275877475739, auc_score: 0.5488822892691365\n",
      "Training:- after 464 epochs, loss: 0.15293166041374207, auc_score: 0.5630268266128413\n",
      "Test:- after 464 epochs, loss: 0.1418030858039856, auc_score: 0.5627809952089807\n",
      "Training:- after 465 epochs, loss: 0.14406214654445648, auc_score: 0.564968415482392\n",
      "Test:- after 465 epochs, loss: 0.1424310952425003, auc_score: 0.5774534234089725\n",
      "Training:- after 466 epochs, loss: 0.1399945616722107, auc_score: 0.5683106067673177\n",
      "Test:- after 466 epochs, loss: 0.14488014578819275, auc_score: 0.5724341592339343\n",
      "Training:- after 467 epochs, loss: 0.14513838291168213, auc_score: 0.5731265210755222\n",
      "Test:- after 467 epochs, loss: 0.14490847289562225, auc_score: 0.5624804280706728\n",
      "Training:- after 468 epochs, loss: 0.14826378226280212, auc_score: 0.5715831395664152\n",
      "Test:- after 468 epochs, loss: 0.15092219412326813, auc_score: 0.5729336693139753\n",
      "Training:- after 469 epochs, loss: 0.1454923003911972, auc_score: 0.5708598822592557\n",
      "Test:- after 469 epochs, loss: 0.1499091535806656, auc_score: 0.5812378219451811\n",
      "Training:- after 470 epochs, loss: 0.14515966176986694, auc_score: 0.577276907319753\n",
      "Test:- after 470 epochs, loss: 0.1534873992204666, auc_score: 0.5813809214722965\n",
      "Training:- after 471 epochs, loss: 0.1410936415195465, auc_score: 0.5732896716984269\n",
      "Test:- after 471 epochs, loss: 0.14151376485824585, auc_score: 0.5748154437941192\n",
      "Training:- after 472 epochs, loss: 0.1421990692615509, auc_score: 0.570861247636617\n",
      "Test:- after 472 epochs, loss: 0.15528470277786255, auc_score: 0.5676941214578726\n",
      "Training:- after 473 epochs, loss: 0.1463116556406021, auc_score: 0.5645038302025815\n",
      "Test:- after 473 epochs, loss: 0.1495922952890396, auc_score: 0.562215078592363\n",
      "Training:- after 474 epochs, loss: 0.13855022192001343, auc_score: 0.5637593874826132\n",
      "Test:- after 474 epochs, loss: 0.15316759049892426, auc_score: 0.5641431685386832\n",
      "Training:- after 475 epochs, loss: 0.1435595452785492, auc_score: 0.564326100218728\n",
      "Test:- after 475 epochs, loss: 0.14834952354431152, auc_score: 0.5622220574648755\n",
      "Training:- after 476 epochs, loss: 0.1422787308692932, auc_score: 0.5660091512240961\n",
      "Test:- after 476 epochs, loss: 0.16146187484264374, auc_score: 0.5607739460814485\n",
      "Training:- after 477 epochs, loss: 0.1548326015472412, auc_score: 0.5670079784886182\n",
      "Test:- after 477 epochs, loss: 0.15598691999912262, auc_score: 0.5685953441439022\n",
      "Training:- after 478 epochs, loss: 0.13957299292087555, auc_score: 0.5620572615618634\n",
      "Test:- after 478 epochs, loss: 0.1401793211698532, auc_score: 0.5696727888009768\n",
      "Training:- after 479 epochs, loss: 0.13649414479732513, auc_score: 0.561435170505134\n",
      "Test:- after 479 epochs, loss: 0.14961786568164825, auc_score: 0.5640319200261623\n",
      "Training:- after 480 epochs, loss: 0.13838034868240356, auc_score: 0.5629142537229005\n",
      "Test:- after 480 epochs, loss: 0.15450243651866913, auc_score: 0.5701374915600718\n",
      "Training:- after 481 epochs, loss: 0.1378348469734192, auc_score: 0.5686061859341505\n",
      "Test:- after 481 epochs, loss: 0.1375989019870758, auc_score: 0.5771849777359979\n",
      "Training:- after 482 epochs, loss: 0.14065155386924744, auc_score: 0.5742367028780408\n",
      "Test:- after 482 epochs, loss: 0.13717155158519745, auc_score: 0.577774202854219\n",
      "Training:- after 483 epochs, loss: 0.1406266689300537, auc_score: 0.5791488348342038\n",
      "Test:- after 483 epochs, loss: 0.13618390262126923, auc_score: 0.5692793140623194\n",
      "Training:- after 484 epochs, loss: 0.1397951990365982, auc_score: 0.5757067099971481\n",
      "Test:- after 484 epochs, loss: 0.13760383427143097, auc_score: 0.5792629657814534\n",
      "Training:- after 485 epochs, loss: 0.13854464888572693, auc_score: 0.5713973980824828\n",
      "Test:- after 485 epochs, loss: 0.1405337005853653, auc_score: 0.5731791453259274\n",
      "Training:- after 486 epochs, loss: 0.13816629350185394, auc_score: 0.5743047227131548\n",
      "Test:- after 486 epochs, loss: 0.13407087326049805, auc_score: 0.5777428616548104\n",
      "Training:- after 487 epochs, loss: 0.1419312059879303, auc_score: 0.5716886954061221\n",
      "Test:- after 487 epochs, loss: 0.13345669209957123, auc_score: 0.5585093159399314\n",
      "Training:- after 488 epochs, loss: 0.13890445232391357, auc_score: 0.569098066393641\n",
      "Test:- after 488 epochs, loss: 0.1393301635980606, auc_score: 0.565781008886949\n",
      "Training:- after 489 epochs, loss: 0.14009986817836761, auc_score: 0.563058593898082\n",
      "Test:- after 489 epochs, loss: 0.13957643508911133, auc_score: 0.5539031139760238\n",
      "Training:- after 490 epochs, loss: 0.13969092071056366, auc_score: 0.5604645925024586\n",
      "Test:- after 490 epochs, loss: 0.1413816511631012, auc_score: 0.5524802042493717\n",
      "Training:- after 491 epochs, loss: 0.13450364768505096, auc_score: 0.5599767449521442\n",
      "Test:- after 491 epochs, loss: 0.1343526542186737, auc_score: 0.5525477423269707\n",
      "Training:- after 492 epochs, loss: 0.13949821889400482, auc_score: 0.5689091920612469\n",
      "Test:- after 492 epochs, loss: 0.13548783957958221, auc_score: 0.568311293152436\n",
      "Training:- after 493 epochs, loss: 0.14664535224437714, auc_score: 0.5829886620399601\n",
      "Test:- after 493 epochs, loss: 0.13227997720241547, auc_score: 0.5880851341622182\n",
      "Training:- after 494 epochs, loss: 0.1505575180053711, auc_score: 0.5796790139308018\n",
      "Test:- after 494 epochs, loss: 0.1526821255683899, auc_score: 0.5681927362527092\n",
      "Training:- after 495 epochs, loss: 0.13896825909614563, auc_score: 0.5705519145684967\n",
      "Test:- after 495 epochs, loss: 0.13575012981891632, auc_score: 0.5709352715014555\n",
      "Training:- after 496 epochs, loss: 0.13495565950870514, auc_score: 0.567655049618877\n",
      "Test:- after 496 epochs, loss: 0.13723039627075195, auc_score: 0.5694807439073977\n",
      "Training:- after 497 epochs, loss: 0.1446320116519928, auc_score: 0.5681511603736186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:- after 497 epochs, loss: 0.13464316725730896, auc_score: 0.5682076017174554\n",
      "Training:- after 498 epochs, loss: 0.1401665359735489, auc_score: 0.5743222198261608\n",
      "Test:- after 498 epochs, loss: 0.14006724953651428, auc_score: 0.5743124769184282\n",
      "Training:- after 499 epochs, loss: 0.13372382521629333, auc_score: 0.5770716393565057\n",
      "Test:- after 499 epochs, loss: 0.1343471109867096, auc_score: 0.5749839252785021\n",
      "Training:- after 500 epochs, loss: 0.14163939654827118, auc_score: 0.5812580423756638\n",
      "Test:- after 500 epochs, loss: 0.14059501886367798, auc_score: 0.5706890587443874\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, path2)\n",
    "    for epoch in range(1, 500+1):\n",
    "        _ = sess.run(train_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "        if 500%10 == 0:\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_tr})\n",
    "            print('Training:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_ts, y1_nn:y_ts.reshape(y_ts.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_ts})\n",
    "            print('Test:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path2 = saver2.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt\n",
      "Training:- after 1 epochs, loss: 0.14369477331638336, auc_score: 0.5723437449903699\n",
      "Test:- after 1 epochs, loss: 0.13262833654880524, auc_score: 0.5744990817109398\n",
      "Training:- after 2 epochs, loss: 0.13203515112400055, auc_score: 0.5710671196309361\n",
      "Test:- after 2 epochs, loss: 0.1350337564945221, auc_score: 0.5724006451027277\n",
      "Training:- after 3 epochs, loss: 0.13914115726947784, auc_score: 0.5687515767573177\n",
      "Test:- after 3 epochs, loss: 0.1355879306793213, auc_score: 0.5705115715612655\n",
      "Training:- after 4 epochs, loss: 0.13482606410980225, auc_score: 0.5654336041996316\n",
      "Test:- after 4 epochs, loss: 0.13044650852680206, auc_score: 0.571587729245859\n",
      "Training:- after 5 epochs, loss: 0.13224689662456512, auc_score: 0.564851050513674\n",
      "Test:- after 5 epochs, loss: 0.1316026747226715, auc_score: 0.5638254200068888\n",
      "Training:- after 6 epochs, loss: 0.13071739673614502, auc_score: 0.5666916187730463\n",
      "Test:- after 6 epochs, loss: 0.1354665607213974, auc_score: 0.5649840931444778\n",
      "Training:- after 7 epochs, loss: 0.13697217404842377, auc_score: 0.5711130813990145\n",
      "Test:- after 7 epochs, loss: 0.1328907310962677, auc_score: 0.5718929500020516\n",
      "Training:- after 8 epochs, loss: 0.1335667222738266, auc_score: 0.5758173262419657\n",
      "Test:- after 8 epochs, loss: 0.12804922461509705, auc_score: 0.5746330449768904\n",
      "Training:- after 9 epochs, loss: 0.1350172609090805, auc_score: 0.5778975178325085\n",
      "Test:- after 9 epochs, loss: 0.13378439843654633, auc_score: 0.5816458948064754\n",
      "Training:- after 10 epochs, loss: 0.1314890831708908, auc_score: 0.5775887456574507\n",
      "Test:- after 10 epochs, loss: 0.1452808529138565, auc_score: 0.5785261118633993\n",
      "Training:- after 11 epochs, loss: 0.12798994779586792, auc_score: 0.5825720410816917\n",
      "Test:- after 11 epochs, loss: 0.13621491193771362, auc_score: 0.5855659445942804\n",
      "Training:- after 12 epochs, loss: 0.13243626058101654, auc_score: 0.5766607741563985\n",
      "Test:- after 12 epochs, loss: 0.1284523606300354, auc_score: 0.5731404149149542\n",
      "Training:- after 13 epochs, loss: 0.12677468359470367, auc_score: 0.5726056903615326\n",
      "Test:- after 13 epochs, loss: 0.15005940198898315, auc_score: 0.5777903459655589\n",
      "Training:- after 14 epochs, loss: 0.13304883241653442, auc_score: 0.5669141301661433\n",
      "Test:- after 14 epochs, loss: 0.1271851807832718, auc_score: 0.5607811270148579\n",
      "Training:- after 15 epochs, loss: 0.12799227237701416, auc_score: 0.5619296115418791\n",
      "Test:- after 15 epochs, loss: 0.13261130452156067, auc_score: 0.5659244596891619\n",
      "Training:- after 16 epochs, loss: 0.12634672224521637, auc_score: 0.571650182464133\n",
      "Test:- after 16 epochs, loss: 0.1276511400938034, auc_score: 0.5760317944375433\n",
      "Training:- after 17 epochs, loss: 0.13928557932376862, auc_score: 0.5761567745876599\n",
      "Test:- after 17 epochs, loss: 0.15265022218227386, auc_score: 0.5730489217408821\n",
      "Training:- after 18 epochs, loss: 0.13125725090503693, auc_score: 0.5800649099408224\n",
      "Test:- after 18 epochs, loss: 0.12661567330360413, auc_score: 0.5842230820690538\n",
      "Training:- after 19 epochs, loss: 0.12826155126094818, auc_score: 0.5763178939643884\n",
      "Test:- after 19 epochs, loss: 0.12641219794750214, auc_score: 0.5789775034723388\n",
      "Training:- after 20 epochs, loss: 0.12789520621299744, auc_score: 0.5787307383779215\n",
      "Test:- after 20 epochs, loss: 0.12895673513412476, auc_score: 0.5734197470073227\n",
      "Training:- after 21 epochs, loss: 0.12708014249801636, auc_score: 0.5754019273953761\n",
      "Test:- after 21 epochs, loss: 0.13561873137950897, auc_score: 0.5866415769205422\n",
      "Training:- after 22 epochs, loss: 0.12446925789117813, auc_score: 0.5788269940189892\n",
      "Test:- after 22 epochs, loss: 0.1264474093914032, auc_score: 0.5794324451358036\n",
      "Training:- after 23 epochs, loss: 0.12756989896297455, auc_score: 0.575603419100815\n",
      "Test:- after 23 epochs, loss: 0.12376205623149872, auc_score: 0.5600520571042746\n",
      "Training:- after 24 epochs, loss: 0.1257692277431488, auc_score: 0.5687354301806149\n",
      "Test:- after 24 epochs, loss: 0.1281432956457138, auc_score: 0.5696235698751451\n",
      "Training:- after 25 epochs, loss: 0.12699326872825623, auc_score: 0.5687834871103603\n",
      "Test:- after 25 epochs, loss: 0.12849640846252441, auc_score: 0.5772645648603044\n",
      "Training:- after 26 epochs, loss: 0.12743544578552246, auc_score: 0.5778077044969578\n",
      "Test:- after 26 epochs, loss: 0.1307472139596939, auc_score: 0.5742198957241428\n",
      "Training:- after 27 epochs, loss: 0.12348861992359161, auc_score: 0.5820430475877693\n",
      "Test:- after 27 epochs, loss: 0.12389188259840012, auc_score: 0.5783464455312212\n",
      "Training:- after 28 epochs, loss: 0.12477816641330719, auc_score: 0.5864268534029302\n",
      "Test:- after 28 epochs, loss: 0.12387716770172119, auc_score: 0.5812261863461545\n",
      "Training:- after 29 epochs, loss: 0.1248585656285286, auc_score: 0.5767071642374187\n",
      "Test:- after 29 epochs, loss: 0.12973277270793915, auc_score: 0.5783496722883117\n",
      "Training:- after 30 epochs, loss: 0.12593618035316467, auc_score: 0.5733777650542636\n",
      "Test:- after 30 epochs, loss: 0.12861740589141846, auc_score: 0.5746109985787347\n",
      "Training:- after 31 epochs, loss: 0.12185367941856384, auc_score: 0.5749768170549523\n",
      "Test:- after 31 epochs, loss: 0.12564072012901306, auc_score: 0.5783454600957707\n",
      "Training:- after 32 epochs, loss: 0.1247389167547226, auc_score: 0.5802795697215084\n",
      "Test:- after 32 epochs, loss: 0.12230336666107178, auc_score: 0.57370732629291\n",
      "Training:- after 33 epochs, loss: 0.1288381665945053, auc_score: 0.5787791362562458\n",
      "Test:- after 33 epochs, loss: 0.12339004874229431, auc_score: 0.5833598343971063\n",
      "Training:- after 34 epochs, loss: 0.12846311926841736, auc_score: 0.5810050562545614\n",
      "Test:- after 34 epochs, loss: 0.13118718564510345, auc_score: 0.5799946407232909\n",
      "Training:- after 35 epochs, loss: 0.13107700645923615, auc_score: 0.5807946608046202\n",
      "Test:- after 35 epochs, loss: 0.12453147023916245, auc_score: 0.5820065548554922\n",
      "Training:- after 36 epochs, loss: 0.12300779670476913, auc_score: 0.578971771510688\n",
      "Test:- after 36 epochs, loss: 0.1243433728814125, auc_score: 0.5741247872143326\n",
      "Training:- after 37 epochs, loss: 0.12104412913322449, auc_score: 0.57772889343155\n",
      "Test:- after 37 epochs, loss: 0.13094086945056915, auc_score: 0.5671457530529848\n",
      "Training:- after 38 epochs, loss: 0.12160302698612213, auc_score: 0.5730168271530063\n",
      "Test:- after 38 epochs, loss: 0.12066547572612762, auc_score: 0.5659255787956674\n",
      "Training:- after 39 epochs, loss: 0.12875770032405853, auc_score: 0.5750340335890449\n",
      "Test:- after 39 epochs, loss: 0.12065868079662323, auc_score: 0.569674417722668\n",
      "Training:- after 40 epochs, loss: 0.13536618649959564, auc_score: 0.5761531106271925\n",
      "Test:- after 40 epochs, loss: 0.1219949871301651, auc_score: 0.5744144959109092\n",
      "Training:- after 41 epochs, loss: 0.12355315685272217, auc_score: 0.5747548306395568\n",
      "Test:- after 41 epochs, loss: 0.1232973113656044, auc_score: 0.5817693136022422\n",
      "Training:- after 42 epochs, loss: 0.12009048461914062, auc_score: 0.5829831986506471\n",
      "Test:- after 42 epochs, loss: 0.12240727245807648, auc_score: 0.5825069664379959\n",
      "Training:- after 43 epochs, loss: 0.12187066674232483, auc_score: 0.5845640590757427\n",
      "Test:- after 43 epochs, loss: 0.12322521209716797, auc_score: 0.5819818723397906\n",
      "Training:- after 44 epochs, loss: 0.12257452309131622, auc_score: 0.5870494706246456\n",
      "Test:- after 44 epochs, loss: 0.11890952289104462, auc_score: 0.5922908856235848\n",
      "Training:- after 45 epochs, loss: 0.12270361185073853, auc_score: 0.5869327362030237\n",
      "Test:- after 45 epochs, loss: 0.12834510207176208, auc_score: 0.5863567612062973\n",
      "Training:- after 46 epochs, loss: 0.12025607377290726, auc_score: 0.577623952605298\n",
      "Test:- after 46 epochs, loss: 0.12362120300531387, auc_score: 0.577588564845383\n",
      "Training:- after 47 epochs, loss: 0.12103614211082458, auc_score: 0.5721472541279278\n",
      "Test:- after 47 epochs, loss: 0.14500240981578827, auc_score: 0.5753075055986412\n",
      "Training:- after 48 epochs, loss: 0.12146209925413132, auc_score: 0.5745066236360405\n",
      "Test:- after 48 epochs, loss: 0.11796370893716812, auc_score: 0.5671608982943573\n",
      "Training:- after 49 epochs, loss: 0.11615118384361267, auc_score: 0.5788722740877907\n",
      "Test:- after 49 epochs, loss: 0.12332269549369812, auc_score: 0.5755462421025276\n",
      "Training:- after 50 epochs, loss: 0.11755538731813431, auc_score: 0.5818916535565293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:- after 50 epochs, loss: 0.119501993060112, auc_score: 0.5790523748061771\n",
      "Training:- after 51 epochs, loss: 0.12146981060504913, auc_score: 0.5791398322482533\n",
      "Test:- after 51 epochs, loss: 0.1188327744603157, auc_score: 0.5793706953257408\n",
      "Training:- after 52 epochs, loss: 0.11710301786661148, auc_score: 0.5706060529681625\n",
      "Test:- after 52 epochs, loss: 0.12139666825532913, auc_score: 0.5722119015733395\n",
      "Training:- after 53 epochs, loss: 0.12052460759878159, auc_score: 0.5746174091678629\n",
      "Test:- after 53 epochs, loss: 0.11813880503177643, auc_score: 0.5728135176874783\n",
      "Training:- after 54 epochs, loss: 0.11778280138969421, auc_score: 0.5766525925777919\n",
      "Test:- after 54 epochs, loss: 0.11739036440849304, auc_score: 0.5764842429804045\n",
      "Training:- after 55 epochs, loss: 0.12057226151227951, auc_score: 0.5813639058210385\n",
      "Test:- after 55 epochs, loss: 0.11756900697946548, auc_score: 0.587304482767625\n",
      "Training:- after 56 epochs, loss: 0.12077152729034424, auc_score: 0.583917063832762\n",
      "Test:- after 56 epochs, loss: 0.11817121505737305, auc_score: 0.5875002704507388\n",
      "Training:- after 57 epochs, loss: 0.11606782674789429, auc_score: 0.5856203067904979\n",
      "Test:- after 57 epochs, loss: 0.11813399195671082, auc_score: 0.5893443403675395\n",
      "Training:- after 58 epochs, loss: 0.11589428782463074, auc_score: 0.5852992772864692\n",
      "Test:- after 58 epochs, loss: 0.11807099729776382, auc_score: 0.5831707893306873\n",
      "Training:- after 59 epochs, loss: 0.11623142659664154, auc_score: 0.5889202390524452\n",
      "Test:- after 59 epochs, loss: 0.12173646688461304, auc_score: 0.5915945837732044\n",
      "Training:- after 60 epochs, loss: 0.11473074555397034, auc_score: 0.5928374302214872\n",
      "Test:- after 60 epochs, loss: 0.11624067276716232, auc_score: 0.5869794880212083\n",
      "Training:- after 61 epochs, loss: 0.11602112650871277, auc_score: 0.5871116070684972\n",
      "Test:- after 61 epochs, loss: 0.11407601833343506, auc_score: 0.5854161117763578\n",
      "Training:- after 62 epochs, loss: 0.12704087793827057, auc_score: 0.5841203627833375\n",
      "Test:- after 62 epochs, loss: 0.1139415055513382, auc_score: 0.5773356716442037\n",
      "Training:- after 63 epochs, loss: 0.11550745368003845, auc_score: 0.5709888136562115\n",
      "Test:- after 63 epochs, loss: 0.12106004357337952, auc_score: 0.5714557181990343\n",
      "Training:- after 64 epochs, loss: 0.11537601053714752, auc_score: 0.5704569978877068\n",
      "Test:- after 64 epochs, loss: 0.12371833622455597, auc_score: 0.5743286138125099\n",
      "Training:- after 65 epochs, loss: 0.11484985053539276, auc_score: 0.5767502158718499\n",
      "Test:- after 65 epochs, loss: 0.1152842566370964, auc_score: 0.5867914097384648\n",
      "Training:- after 66 epochs, loss: 0.11547385901212692, auc_score: 0.5875723366413672\n",
      "Test:- after 66 epochs, loss: 0.11482039093971252, auc_score: 0.5886004889251977\n",
      "Training:- after 67 epochs, loss: 0.1138148307800293, auc_score: 0.5902489188301414\n",
      "Test:- after 67 epochs, loss: 0.11649581789970398, auc_score: 0.6003814101488039\n",
      "Training:- after 68 epochs, loss: 0.11467887461185455, auc_score: 0.5980073039674665\n",
      "Test:- after 68 epochs, loss: 0.11679333448410034, auc_score: 0.5928445915447773\n",
      "Training:- after 69 epochs, loss: 0.11327648162841797, auc_score: 0.5946570942566346\n",
      "Test:- after 69 epochs, loss: 0.12205909192562103, auc_score: 0.6002953384240245\n",
      "Training:- after 70 epochs, loss: 0.11284977197647095, auc_score: 0.585750671240041\n",
      "Test:- after 70 epochs, loss: 0.11290862411260605, auc_score: 0.5857604173272504\n",
      "Training:- after 71 epochs, loss: 0.11324404925107956, auc_score: 0.5876618045760217\n",
      "Test:- after 71 epochs, loss: 0.11501444876194, auc_score: 0.5752678830110929\n",
      "Training:- after 72 epochs, loss: 0.11638396978378296, auc_score: 0.5849501558358116\n",
      "Test:- after 72 epochs, loss: 0.11872918158769608, auc_score: 0.5773952018930308\n",
      "Training:- after 73 epochs, loss: 0.11316471546888351, auc_score: 0.5834333227043323\n",
      "Test:- after 73 epochs, loss: 0.11285717785358429, auc_score: 0.5780816058680971\n",
      "Training:- after 74 epochs, loss: 0.11169617623090744, auc_score: 0.5776323189056101\n",
      "Test:- after 74 epochs, loss: 0.11728528887033463, auc_score: 0.5727428150253726\n",
      "Training:- after 75 epochs, loss: 0.1100725531578064, auc_score: 0.5719345221017715\n",
      "Test:- after 75 epochs, loss: 0.11211103200912476, auc_score: 0.5761072812799594\n",
      "Training:- after 76 epochs, loss: 0.11406239122152328, auc_score: 0.5764616642429321\n",
      "Test:- after 76 epochs, loss: 0.11393853276968002, auc_score: 0.5711127586845774\n",
      "Training:- after 77 epochs, loss: 0.11000530421733856, auc_score: 0.5796600975179226\n",
      "Test:- after 77 epochs, loss: 0.11391620337963104, auc_score: 0.5850391158809917\n",
      "Training:- after 78 epochs, loss: 0.11065628379583359, auc_score: 0.5868660126848801\n",
      "Test:- after 78 epochs, loss: 0.10968532413244247, auc_score: 0.5889932144842225\n",
      "Training:- after 79 epochs, loss: 0.10958538204431534, auc_score: 0.5967741833894433\n",
      "Test:- after 79 epochs, loss: 0.12310050427913666, auc_score: 0.6007617975586069\n",
      "Training:- after 80 epochs, loss: 0.1102817952632904, auc_score: 0.5978276379180906\n",
      "Test:- after 80 epochs, loss: 0.11201655864715576, auc_score: 0.5989943335907277\n",
      "Training:- after 81 epochs, loss: 0.10971422493457794, auc_score: 0.5972809103489316\n",
      "Test:- after 81 epochs, loss: 0.11227896809577942, auc_score: 0.5952859503638961\n",
      "Training:- after 82 epochs, loss: 0.10869593173265457, auc_score: 0.5947609379329183\n",
      "Test:- after 82 epochs, loss: 0.12675949931144714, auc_score: 0.5943831329510962\n",
      "Training:- after 83 epochs, loss: 0.10853390395641327, auc_score: 0.5884608791113732\n",
      "Test:- after 83 epochs, loss: 0.11151087284088135, auc_score: 0.5923228143539088\n",
      "Training:- after 84 epochs, loss: 0.1120888888835907, auc_score: 0.583333807175344\n",
      "Test:- after 84 epochs, loss: 0.11529196798801422, auc_score: 0.5916545989681838\n",
      "Training:- after 85 epochs, loss: 0.1104939728975296, auc_score: 0.5831239478833681\n",
      "Test:- after 85 epochs, loss: 0.12265036255121231, auc_score: 0.5829216855484803\n",
      "Training:- after 86 epochs, loss: 0.11095729470252991, auc_score: 0.5867042713688693\n",
      "Test:- after 86 epochs, loss: 0.11101534217596054, auc_score: 0.5867418115598728\n",
      "Training:- after 87 epochs, loss: 0.1081208884716034, auc_score: 0.5847550024495414\n",
      "Test:- after 87 epochs, loss: 0.10884855687618256, auc_score: 0.5764478129550256\n",
      "Training:- after 88 epochs, loss: 0.10703745484352112, auc_score: 0.5886825801826884\n",
      "Test:- after 88 epochs, loss: 0.11383652687072754, auc_score: 0.5907760537320337\n",
      "Training:- after 89 epochs, loss: 0.10639888048171997, auc_score: 0.5926641668025324\n",
      "Test:- after 89 epochs, loss: 0.11045932024717331, auc_score: 0.587816371409067\n",
      "Training:- after 90 epochs, loss: 0.1083579957485199, auc_score: 0.5912248557410795\n",
      "Test:- after 90 epochs, loss: 0.10963115096092224, auc_score: 0.5961562328636817\n",
      "Training:- after 91 epochs, loss: 0.11738047748804092, auc_score: 0.5865440916290103\n",
      "Test:- after 91 epochs, loss: 0.10537905991077423, auc_score: 0.5858168544900418\n",
      "Training:- after 92 epochs, loss: 0.10571844130754471, auc_score: 0.5870663168088357\n",
      "Test:- after 92 epochs, loss: 0.10851013660430908, auc_score: 0.5880410569090526\n",
      "Training:- after 93 epochs, loss: 0.1086142361164093, auc_score: 0.5858861602080665\n",
      "Test:- after 93 epochs, loss: 0.11064518243074417, auc_score: 0.5820823867557475\n",
      "Training:- after 94 epochs, loss: 0.1072806641459465, auc_score: 0.5833318533005517\n",
      "Test:- after 94 epochs, loss: 0.10666343569755554, auc_score: 0.5831284746702677\n",
      "Training:- after 95 epochs, loss: 0.10615308582782745, auc_score: 0.5898647730755935\n",
      "Test:- after 95 epochs, loss: 0.11847483366727829, auc_score: 0.5839023430359868\n",
      "Training:- after 96 epochs, loss: 0.11190589517354965, auc_score: 0.5918469061333093\n",
      "Test:- after 96 epochs, loss: 0.10607615113258362, auc_score: 0.5921378384830884\n",
      "Training:- after 97 epochs, loss: 0.1073288768529892, auc_score: 0.5930166476751415\n",
      "Test:- after 97 epochs, loss: 0.10698305070400238, auc_score: 0.5935802641837424\n",
      "Training:- after 98 epochs, loss: 0.10681813210248947, auc_score: 0.5962954423124873\n",
      "Test:- after 98 epochs, loss: 0.10705965757369995, auc_score: 0.5958456124186006\n",
      "Training:- after 99 epochs, loss: 0.10676715523004532, auc_score: 0.5925280589623768\n",
      "Test:- after 99 epochs, loss: 0.10609012097120285, auc_score: 0.5927348196311176\n",
      "Training:- after 100 epochs, loss: 0.11864066869020462, auc_score: 0.5902522573756708\n",
      "Test:- after 100 epochs, loss: 0.10591370612382889, auc_score: 0.5887790858889373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 101 epochs, loss: 0.10883238166570663, auc_score: 0.5915399010335902\n",
      "Test:- after 101 epochs, loss: 0.10637940466403961, auc_score: 0.5870808231152692\n",
      "Training:- after 102 epochs, loss: 0.10836257040500641, auc_score: 0.5871268130189266\n",
      "Test:- after 102 epochs, loss: 0.10562226921319962, auc_score: 0.5835899568895306\n",
      "Training:- after 103 epochs, loss: 0.107384093105793, auc_score: 0.5932893620150108\n",
      "Test:- after 103 epochs, loss: 0.10709827393293381, auc_score: 0.5827678270557676\n",
      "Training:- after 104 epochs, loss: 0.12811094522476196, auc_score: 0.5933115385136914\n",
      "Test:- after 104 epochs, loss: 0.11071528494358063, auc_score: 0.5935870627557625\n",
      "Training:- after 105 epochs, loss: 0.1175740584731102, auc_score: 0.5967207991134189\n",
      "Test:- after 105 epochs, loss: 0.10620161145925522, auc_score: 0.5926282371709982\n",
      "Training:- after 106 epochs, loss: 0.10731269419193268, auc_score: 0.5885753936074981\n",
      "Test:- after 106 epochs, loss: 0.11201642453670502, auc_score: 0.5938537334014744\n",
      "Training:- after 107 epochs, loss: 0.10516754537820816, auc_score: 0.584689890274565\n",
      "Test:- after 107 epochs, loss: 0.10733702033758163, auc_score: 0.5951035360035215\n",
      "Training:- after 108 epochs, loss: 0.10912001878023148, auc_score: 0.5868184179056892\n",
      "Test:- after 108 epochs, loss: 0.10947220027446747, auc_score: 0.58646838275432\n",
      "Training:- after 109 epochs, loss: 0.10756352543830872, auc_score: 0.5877631361558411\n",
      "Test:- after 109 epochs, loss: 0.12099706381559372, auc_score: 0.5941745998883381\n",
      "Training:- after 110 epochs, loss: 0.10358079522848129, auc_score: 0.5937023312814201\n",
      "Test:- after 110 epochs, loss: 0.10658496618270874, auc_score: 0.5912315238624593\n",
      "Training:- after 111 epochs, loss: 0.10603597015142441, auc_score: 0.5941041148422065\n",
      "Test:- after 111 epochs, loss: 0.1073903739452362, auc_score: 0.59102675534964\n",
      "Training:- after 112 epochs, loss: 0.10563305765390396, auc_score: 0.5880038792943287\n",
      "Test:- after 112 epochs, loss: 0.11547278612852097, auc_score: 0.5921225378102567\n",
      "Training:- after 113 epochs, loss: 0.10519316047430038, auc_score: 0.5917787032584765\n",
      "Test:- after 113 epochs, loss: 0.10531073808670044, auc_score: 0.588519188946212\n",
      "Training:- after 114 epochs, loss: 0.10411620140075684, auc_score: 0.5899383935303394\n",
      "Test:- after 114 epochs, loss: 0.10884171724319458, auc_score: 0.5905702873492471\n",
      "Training:- after 115 epochs, loss: 0.1029421016573906, auc_score: 0.5898562124563584\n",
      "Test:- after 115 epochs, loss: 0.10498892515897751, auc_score: 0.5904112156853968\n",
      "Training:- after 116 epochs, loss: 0.10347721725702286, auc_score: 0.5905576209554042\n",
      "Test:- after 116 epochs, loss: 0.10433092713356018, auc_score: 0.5966691442441243\n",
      "Training:- after 117 epochs, loss: 0.10598684847354889, auc_score: 0.5956422438039682\n",
      "Test:- after 117 epochs, loss: 0.10945428907871246, auc_score: 0.5958049018108387\n",
      "Training:- after 118 epochs, loss: 0.10309262573719025, auc_score: 0.6033377657802882\n",
      "Test:- after 118 epochs, loss: 0.10370957106351852, auc_score: 0.5994708988787796\n",
      "Training:- after 119 epochs, loss: 0.10718230158090591, auc_score: 0.599978114485002\n",
      "Test:- after 119 epochs, loss: 0.11124231666326523, auc_score: 0.5955234030039306\n",
      "Training:- after 120 epochs, loss: 0.1047825887799263, auc_score: 0.5965592784344745\n",
      "Test:- after 120 epochs, loss: 0.10565103590488434, auc_score: 0.5992293304137088\n",
      "Training:- after 121 epochs, loss: 0.1039874479174614, auc_score: 0.5922723140864217\n",
      "Test:- after 121 epochs, loss: 0.1137067973613739, auc_score: 0.5917407048878842\n",
      "Training:- after 122 epochs, loss: 0.10265122354030609, auc_score: 0.5883868355875259\n",
      "Test:- after 122 epochs, loss: 0.1039486825466156, auc_score: 0.582902862798786\n",
      "Training:- after 123 epochs, loss: 0.10084980726242065, auc_score: 0.5863133584875089\n",
      "Test:- after 123 epochs, loss: 0.10416290909051895, auc_score: 0.5896739141247406\n",
      "Training:- after 124 epochs, loss: 0.10364009439945221, auc_score: 0.5855857015980936\n",
      "Test:- after 124 epochs, loss: 0.10268222540616989, auc_score: 0.5829448821394332\n",
      "Training:- after 125 epochs, loss: 0.1019844338297844, auc_score: 0.5864501641542248\n",
      "Test:- after 125 epochs, loss: 0.10448433458805084, auc_score: 0.5934328592052105\n",
      "Training:- after 126 epochs, loss: 0.10147008299827576, auc_score: 0.5909792416683252\n",
      "Test:- after 126 epochs, loss: 0.10373235493898392, auc_score: 0.5992106662041026\n",
      "Training:- after 127 epochs, loss: 0.10531426966190338, auc_score: 0.6018150213563571\n",
      "Test:- after 127 epochs, loss: 0.106117382645607, auc_score: 0.605662601201423\n",
      "Training:- after 128 epochs, loss: 0.11246997117996216, auc_score: 0.6077722867566128\n",
      "Test:- after 128 epochs, loss: 0.10289393365383148, auc_score: 0.601725189719639\n",
      "Training:- after 129 epochs, loss: 0.10824862122535706, auc_score: 0.6061015768827247\n",
      "Test:- after 129 epochs, loss: 0.10651645064353943, auc_score: 0.6030348489765771\n",
      "Training:- after 130 epochs, loss: 0.10282378643751144, auc_score: 0.5977749675959096\n",
      "Test:- after 130 epochs, loss: 0.10178930312395096, auc_score: 0.5896305860512079\n",
      "Training:- after 131 epochs, loss: 0.10137876123189926, auc_score: 0.5936833154334504\n",
      "Test:- after 131 epochs, loss: 0.10440599918365479, auc_score: 0.5930982619032521\n",
      "Training:- after 132 epochs, loss: 0.10180090367794037, auc_score: 0.5891099472544337\n",
      "Test:- after 132 epochs, loss: 0.10718901455402374, auc_score: 0.580107860106713\n",
      "Training:- after 133 epochs, loss: 0.10183265060186386, auc_score: 0.5907030891499552\n",
      "Test:- after 133 epochs, loss: 0.10671386867761612, auc_score: 0.5910409897626623\n",
      "Training:- after 134 epochs, loss: 0.10014455765485764, auc_score: 0.590450016258132\n",
      "Test:- after 134 epochs, loss: 0.10729052871465683, auc_score: 0.584458063348889\n",
      "Training:- after 135 epochs, loss: 0.1043180525302887, auc_score: 0.5943377357568274\n",
      "Test:- after 135 epochs, loss: 0.10283482074737549, auc_score: 0.5911819567701592\n",
      "Training:- after 136 epochs, loss: 0.10379813611507416, auc_score: 0.6053435585520488\n",
      "Test:- after 136 epochs, loss: 0.10068817436695099, auc_score: 0.597491183927641\n",
      "Training:- after 137 epochs, loss: 0.10187612473964691, auc_score: 0.608966146205429\n",
      "Test:- after 137 epochs, loss: 0.10171779245138168, auc_score: 0.6102503006044417\n",
      "Training:- after 138 epochs, loss: 0.10103759169578552, auc_score: 0.6100663188024846\n",
      "Test:- after 138 epochs, loss: 0.10136908292770386, auc_score: 0.6068954431226553\n",
      "Training:- after 139 epochs, loss: 0.10045324265956879, auc_score: 0.6043948327214604\n",
      "Test:- after 139 epochs, loss: 0.10360242426395416, auc_score: 0.5925118438771818\n",
      "Training:- after 140 epochs, loss: 0.09903386235237122, auc_score: 0.5947869611349639\n",
      "Test:- after 140 epochs, loss: 0.10047046840190887, auc_score: 0.5970178733743423\n",
      "Training:- after 141 epochs, loss: 0.09901847690343857, auc_score: 0.587362269178814\n",
      "Test:- after 141 epochs, loss: 0.099919892847538, auc_score: 0.5890904306446177\n",
      "Training:- after 142 epochs, loss: 0.10000555217266083, auc_score: 0.5838664947076119\n",
      "Test:- after 142 epochs, loss: 0.10080575942993164, auc_score: 0.5899715436084718\n",
      "Training:- after 143 epochs, loss: 0.09892123192548752, auc_score: 0.5882745497236523\n",
      "Test:- after 143 epochs, loss: 0.1003749668598175, auc_score: 0.579975413851803\n",
      "Training:- after 144 epochs, loss: 0.09909296780824661, auc_score: 0.5929102282837238\n",
      "Test:- after 144 epochs, loss: 0.10113511979579926, auc_score: 0.595672306341728\n",
      "Training:- after 145 epochs, loss: 0.09960741549730301, auc_score: 0.6056381463361887\n",
      "Test:- after 145 epochs, loss: 0.09986185282468796, auc_score: 0.6071964081654985\n",
      "Training:- after 146 epochs, loss: 0.10015173256397247, auc_score: 0.6098614695549616\n",
      "Test:- after 146 epochs, loss: 0.10326794534921646, auc_score: 0.605501701663614\n",
      "Training:- after 147 epochs, loss: 0.10184334963560104, auc_score: 0.6165857066984706\n",
      "Test:- after 147 epochs, loss: 0.09857916831970215, auc_score: 0.6137776497022556\n",
      "Training:- after 148 epochs, loss: 0.100522480905056, auc_score: 0.6097651131925783\n",
      "Test:- after 148 epochs, loss: 0.10027959942817688, auc_score: 0.5997283804166309\n",
      "Training:- after 149 epochs, loss: 0.09910796582698822, auc_score: 0.6008336005754452\n",
      "Test:- after 149 epochs, loss: 0.09814400970935822, auc_score: 0.5988654063040513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 150 epochs, loss: 0.09949900954961777, auc_score: 0.5960503911116031\n",
      "Test:- after 150 epochs, loss: 0.10054990649223328, auc_score: 0.6007756371757234\n",
      "Training:- after 151 epochs, loss: 0.09707853943109512, auc_score: 0.5971298913017641\n",
      "Test:- after 151 epochs, loss: 0.09964515268802643, auc_score: 0.5938276084818325\n",
      "Training:- after 152 epochs, loss: 0.09807473421096802, auc_score: 0.5973383315906879\n",
      "Test:- after 152 epochs, loss: 0.10312913358211517, auc_score: 0.596381272747394\n",
      "Training:- after 153 epochs, loss: 0.09634771198034286, auc_score: 0.5955331912130506\n",
      "Test:- after 153 epochs, loss: 0.09790915995836258, auc_score: 0.6015109367791865\n",
      "Training:- after 154 epochs, loss: 0.09690219163894653, auc_score: 0.6038893371740475\n",
      "Test:- after 154 epochs, loss: 0.09655913710594177, auc_score: 0.605277386090501\n",
      "Training:- after 155 epochs, loss: 0.09644613415002823, auc_score: 0.6097930442621354\n",
      "Test:- after 155 epochs, loss: 0.10702624917030334, auc_score: 0.6098384289982878\n",
      "Training:- after 156 epochs, loss: 0.09712225198745728, auc_score: 0.6120415128739329\n",
      "Test:- after 156 epochs, loss: 0.09640344977378845, auc_score: 0.615779756109389\n",
      "Training:- after 157 epochs, loss: 0.09512119740247726, auc_score: 0.6120863746227718\n",
      "Test:- after 157 epochs, loss: 0.09696545451879501, auc_score: 0.6088995204006898\n",
      "Training:- after 158 epochs, loss: 0.09635627269744873, auc_score: 0.6106444067150664\n",
      "Test:- after 158 epochs, loss: 0.10328689217567444, auc_score: 0.6066044288018224\n",
      "Training:- after 159 epochs, loss: 0.09646408259868622, auc_score: 0.6069543373633451\n",
      "Test:- after 159 epochs, loss: 0.0974920392036438, auc_score: 0.6104649452321711\n",
      "Training:- after 160 epochs, loss: 0.09885295480489731, auc_score: 0.6020376549408339\n",
      "Test:- after 160 epochs, loss: 0.09773065894842148, auc_score: 0.6021951989087467\n",
      "Training:- after 161 epochs, loss: 0.09532434493303299, auc_score: 0.5992578397358541\n",
      "Test:- after 161 epochs, loss: 0.09879682213068008, auc_score: 0.5867222582823207\n",
      "Training:- after 162 epochs, loss: 0.0955633744597435, auc_score: 0.5990190520552048\n",
      "Test:- after 162 epochs, loss: 0.09894417971372604, auc_score: 0.6021234703990113\n",
      "Training:- after 163 epochs, loss: 0.09622038155794144, auc_score: 0.6033601750857029\n",
      "Test:- after 163 epochs, loss: 0.09876080602407455, auc_score: 0.6028723422774812\n",
      "Training:- after 164 epochs, loss: 0.09663582593202591, auc_score: 0.607452902631245\n",
      "Test:- after 164 epochs, loss: 0.10308635979890823, auc_score: 0.6006389134470594\n",
      "Training:- after 165 epochs, loss: 0.09564505517482758, auc_score: 0.6108881994931492\n",
      "Test:- after 165 epochs, loss: 0.10832711309194565, auc_score: 0.6098864573191431\n",
      "Training:- after 166 epochs, loss: 0.09702400863170624, auc_score: 0.6091507212811214\n",
      "Test:- after 166 epochs, loss: 0.09573056548833847, auc_score: 0.6067180274380046\n",
      "Training:- after 167 epochs, loss: 0.09615567326545715, auc_score: 0.6094969885983916\n",
      "Test:- after 167 epochs, loss: 0.09759563952684402, auc_score: 0.6099205247863438\n",
      "Training:- after 168 epochs, loss: 0.09506545215845108, auc_score: 0.6068485044905505\n",
      "Test:- after 168 epochs, loss: 0.09900826215744019, auc_score: 0.6110388790034481\n",
      "Training:- after 169 epochs, loss: 0.09423554688692093, auc_score: 0.6060285795545456\n",
      "Test:- after 169 epochs, loss: 0.09737323224544525, auc_score: 0.6054269608922015\n",
      "Training:- after 170 epochs, loss: 0.09382449835538864, auc_score: 0.6097582930337175\n",
      "Test:- after 170 epochs, loss: 0.09488704055547714, auc_score: 0.6066397645897292\n",
      "Training:- after 171 epochs, loss: 0.09632153064012527, auc_score: 0.6087495443238569\n",
      "Test:- after 171 epochs, loss: 0.09474661946296692, auc_score: 0.6077622066542073\n",
      "Training:- after 172 epochs, loss: 0.09322822093963623, auc_score: 0.6068755182837657\n",
      "Test:- after 172 epochs, loss: 0.09585661441087723, auc_score: 0.6112946632297662\n",
      "Training:- after 173 epochs, loss: 0.09321675449609756, auc_score: 0.605728858545169\n",
      "Test:- after 173 epochs, loss: 0.0941905751824379, auc_score: 0.6102125089994814\n",
      "Training:- after 174 epochs, loss: 0.09386312961578369, auc_score: 0.6035112862463723\n",
      "Test:- after 174 epochs, loss: 0.09603361785411835, auc_score: 0.6074933133386304\n",
      "Training:- after 175 epochs, loss: 0.09357069432735443, auc_score: 0.6068414406415128\n",
      "Test:- after 175 epochs, loss: 0.09648605436086655, auc_score: 0.6108432094482432\n",
      "Training:- after 176 epochs, loss: 0.0928577408194542, auc_score: 0.6078626258613881\n",
      "Test:- after 176 epochs, loss: 0.09529179334640503, auc_score: 0.6091895368515555\n",
      "Training:- after 177 epochs, loss: 0.09235983341932297, auc_score: 0.6128576131702796\n",
      "Test:- after 177 epochs, loss: 0.1002117171883583, auc_score: 0.6142182326075305\n",
      "Training:- after 178 epochs, loss: 0.09476353973150253, auc_score: 0.6155114178964533\n",
      "Test:- after 178 epochs, loss: 0.09573394805192947, auc_score: 0.6086686083164534\n",
      "Training:- after 179 epochs, loss: 0.09423328936100006, auc_score: 0.6152650360462839\n",
      "Test:- after 179 epochs, loss: 0.0963885635137558, auc_score: 0.6093800709513525\n",
      "Training:- after 180 epochs, loss: 0.09233926981687546, auc_score: 0.6097519996334853\n",
      "Test:- after 180 epochs, loss: 0.0929163247346878, auc_score: 0.6131289875940827\n",
      "Training:- after 181 epochs, loss: 0.09702027589082718, auc_score: 0.6073961020425457\n",
      "Test:- after 181 epochs, loss: 0.09227403253316879, auc_score: 0.6068059892093264\n",
      "Training:- after 182 epochs, loss: 0.09166961908340454, auc_score: 0.6040707987935942\n",
      "Test:- after 182 epochs, loss: 0.09411796182394028, auc_score: 0.6096412486493006\n",
      "Training:- after 183 epochs, loss: 0.09306299686431885, auc_score: 0.6096541229530922\n",
      "Test:- after 183 epochs, loss: 0.09629787504673004, auc_score: 0.6050910890522785\n",
      "Training:- after 184 epochs, loss: 0.09324865788221359, auc_score: 0.6172970633567598\n",
      "Test:- after 184 epochs, loss: 0.09292588382959366, auc_score: 0.6110855954827887\n",
      "Training:- after 185 epochs, loss: 0.09243054687976837, auc_score: 0.6190918613966457\n",
      "Test:- after 185 epochs, loss: 0.09448082745075226, auc_score: 0.613315368565293\n",
      "Training:- after 186 epochs, loss: 0.09228092432022095, auc_score: 0.6168567630942496\n",
      "Test:- after 186 epochs, loss: 0.09434874355792999, auc_score: 0.613543638314725\n",
      "Training:- after 187 epochs, loss: 0.09272570163011551, auc_score: 0.6126552218988285\n",
      "Test:- after 187 epochs, loss: 0.09305302053689957, auc_score: 0.6067657075923916\n",
      "Training:- after 188 epochs, loss: 0.09270071238279343, auc_score: 0.610773120838929\n",
      "Test:- after 188 epochs, loss: 0.09288328140974045, auc_score: 0.6031185021878533\n",
      "Training:- after 189 epochs, loss: 0.09308480471372604, auc_score: 0.6049294798670631\n",
      "Test:- after 189 epochs, loss: 0.09523731470108032, auc_score: 0.601081063101442\n",
      "Training:- after 190 epochs, loss: 0.09183505922555923, auc_score: 0.608628352736673\n",
      "Test:- after 190 epochs, loss: 0.09299416840076447, auc_score: 0.6103517693695576\n",
      "Training:- after 191 epochs, loss: 0.09075575321912766, auc_score: 0.6121254862530517\n",
      "Test:- after 191 epochs, loss: 0.09429732710123062, auc_score: 0.6115237039192354\n",
      "Training:- after 192 epochs, loss: 0.09142675995826721, auc_score: 0.6195437711264629\n",
      "Test:- after 192 epochs, loss: 0.09311017394065857, auc_score: 0.622400495888527\n",
      "Training:- after 193 epochs, loss: 0.09123315662145615, auc_score: 0.6226597257147837\n",
      "Test:- after 193 epochs, loss: 0.09707148373126984, auc_score: 0.6212632101197071\n",
      "Training:- after 194 epochs, loss: 0.0908861756324768, auc_score: 0.6201234980855208\n",
      "Test:- after 194 epochs, loss: 0.09337183833122253, auc_score: 0.6178456578045866\n",
      "Training:- after 195 epochs, loss: 0.09066379070281982, auc_score: 0.6191814473671837\n",
      "Test:- after 195 epochs, loss: 0.0923694297671318, auc_score: 0.6139554073361162\n",
      "Training:- after 196 epochs, loss: 0.09149479866027832, auc_score: 0.6185093559935977\n",
      "Test:- after 196 epochs, loss: 0.09273329377174377, auc_score: 0.6114495040493004\n",
      "Training:- after 197 epochs, loss: 0.09004143625497818, auc_score: 0.6137313590062435\n",
      "Test:- after 197 epochs, loss: 0.0916358232498169, auc_score: 0.608980350976669\n",
      "Training:- after 198 epochs, loss: 0.09008514136075974, auc_score: 0.6160053856023797\n",
      "Test:- after 198 epochs, loss: 0.09220266342163086, auc_score: 0.611933871996598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 199 epochs, loss: 0.09765620529651642, auc_score: 0.6122256830855554\n",
      "Test:- after 199 epochs, loss: 0.09303610771894455, auc_score: 0.6088766253467676\n",
      "Training:- after 200 epochs, loss: 0.09226910769939423, auc_score: 0.6122250909273301\n",
      "Test:- after 200 epochs, loss: 0.09167144447565079, auc_score: 0.6115450602017127\n",
      "Training:- after 201 epochs, loss: 0.09162425249814987, auc_score: 0.6078363769763163\n",
      "Test:- after 201 epochs, loss: 0.09191092103719711, auc_score: 0.6153910220302333\n",
      "Training:- after 202 epochs, loss: 0.08979588001966476, auc_score: 0.6159571118942431\n",
      "Test:- after 202 epochs, loss: 0.09278969466686249, auc_score: 0.6102766120418347\n",
      "Training:- after 203 epochs, loss: 0.08983134478330612, auc_score: 0.6173407397008039\n",
      "Test:- after 203 epochs, loss: 0.09113442897796631, auc_score: 0.616819387401099\n",
      "Training:- after 204 epochs, loss: 0.09287319332361221, auc_score: 0.6214931265196904\n",
      "Test:- after 204 epochs, loss: 0.09171847999095917, auc_score: 0.6247756937527744\n",
      "Training:- after 205 epochs, loss: 0.09248077124357224, auc_score: 0.6224090798306907\n",
      "Test:- after 205 epochs, loss: 0.09183544665575027, auc_score: 0.6191077208401257\n",
      "Training:- after 206 epochs, loss: 0.0911913588643074, auc_score: 0.6226746369217956\n",
      "Test:- after 206 epochs, loss: 0.09468530118465424, auc_score: 0.6182681857915752\n",
      "Training:- after 207 epochs, loss: 0.09045127034187317, auc_score: 0.6188992202057803\n",
      "Test:- after 207 epochs, loss: 0.091175377368927, auc_score: 0.6150684333628031\n",
      "Training:- after 208 epochs, loss: 0.09104384481906891, auc_score: 0.6133785011707542\n",
      "Test:- after 208 epochs, loss: 0.08992717415094376, auc_score: 0.6071233242934396\n",
      "Training:- after 209 epochs, loss: 0.0892212986946106, auc_score: 0.6083706830743998\n",
      "Test:- after 209 epochs, loss: 0.0952259972691536, auc_score: 0.6112924840807099\n",
      "Training:- after 210 epochs, loss: 0.08870095014572144, auc_score: 0.615608046147024\n",
      "Test:- after 210 epochs, loss: 0.09021447598934174, auc_score: 0.6107161317959297\n",
      "Training:- after 211 epochs, loss: 0.08951076865196228, auc_score: 0.6127836766999328\n",
      "Test:- after 211 epochs, loss: 0.08940944820642471, auc_score: 0.6129988541592836\n",
      "Training:- after 212 epochs, loss: 0.09014269709587097, auc_score: 0.6158604295232797\n",
      "Test:- after 212 epochs, loss: 0.09070854634046555, auc_score: 0.6202512642794882\n",
      "Training:- after 213 epochs, loss: 0.0885278582572937, auc_score: 0.621735570839218\n",
      "Test:- after 213 epochs, loss: 0.09083618968725204, auc_score: 0.6192473013990075\n",
      "Training:- after 214 epochs, loss: 0.08910339325666428, auc_score: 0.620794574924363\n",
      "Test:- after 214 epochs, loss: 0.08927720040082932, auc_score: 0.6172752492188015\n",
      "Training:- after 215 epochs, loss: 0.08912524580955505, auc_score: 0.6272609823200501\n",
      "Test:- after 215 epochs, loss: 0.09028969705104828, auc_score: 0.6249477284003119\n",
      "Training:- after 216 epochs, loss: 0.0894937738776207, auc_score: 0.6251234857427073\n",
      "Test:- after 216 epochs, loss: 0.09135714173316956, auc_score: 0.6235979740441897\n",
      "Training:- after 217 epochs, loss: 0.08970069885253906, auc_score: 0.6249598155838225\n",
      "Test:- after 217 epochs, loss: 0.09109202027320862, auc_score: 0.6208119055523847\n",
      "Training:- after 218 epochs, loss: 0.08876077085733414, auc_score: 0.6235290969014695\n",
      "Test:- after 218 epochs, loss: 0.08960334956645966, auc_score: 0.6250473164447727\n",
      "Training:- after 219 epochs, loss: 0.08954451978206635, auc_score: 0.6203579526718553\n",
      "Test:- after 219 epochs, loss: 0.08992815762758255, auc_score: 0.6169860037079729\n",
      "Training:- after 220 epochs, loss: 0.08933062851428986, auc_score: 0.6210886528686808\n",
      "Test:- after 220 epochs, loss: 0.08984691649675369, auc_score: 0.6212297115316465\n",
      "Training:- after 221 epochs, loss: 0.08773977309465408, auc_score: 0.616336509697427\n",
      "Test:- after 221 epochs, loss: 0.0917186290025711, auc_score: 0.615512951792622\n",
      "Training:- after 222 epochs, loss: 0.08758676797151566, auc_score: 0.6109081635858024\n",
      "Test:- after 222 epochs, loss: 0.09023886919021606, auc_score: 0.6179210544967565\n",
      "Training:- after 223 epochs, loss: 0.08766356110572815, auc_score: 0.6137462795136519\n",
      "Test:- after 223 epochs, loss: 0.09033603966236115, auc_score: 0.6019975584826408\n",
      "Training:- after 224 epochs, loss: 0.08797402679920197, auc_score: 0.6141249513912055\n",
      "Test:- after 224 epochs, loss: 0.08954574167728424, auc_score: 0.6206523831373032\n",
      "Training:- after 225 epochs, loss: 0.08925419300794601, auc_score: 0.6196846997381082\n",
      "Test:- after 225 epochs, loss: 0.0942557081580162, auc_score: 0.6150995693926856\n",
      "Training:- after 226 epochs, loss: 0.08868175745010376, auc_score: 0.6233480629022821\n",
      "Test:- after 226 epochs, loss: 0.08912111818790436, auc_score: 0.6239743078015402\n",
      "Training:- after 227 epochs, loss: 0.08974352478981018, auc_score: 0.6244135551122378\n",
      "Test:- after 227 epochs, loss: 0.08761221915483475, auc_score: 0.6298574165053288\n",
      "Training:- after 228 epochs, loss: 0.08828464150428772, auc_score: 0.6251613057062153\n",
      "Test:- after 228 epochs, loss: 0.08849989622831345, auc_score: 0.6192588810427089\n",
      "Training:- after 229 epochs, loss: 0.08734126389026642, auc_score: 0.6252080415838933\n",
      "Test:- after 229 epochs, loss: 0.08862528949975967, auc_score: 0.6235272900338592\n",
      "Training:- after 230 epochs, loss: 0.08713220804929733, auc_score: 0.6195767892160953\n",
      "Test:- after 230 epochs, loss: 0.08872757852077484, auc_score: 0.6299422789733566\n",
      "Training:- after 231 epochs, loss: 0.08678030222654343, auc_score: 0.6246141876193428\n",
      "Test:- after 231 epochs, loss: 0.09087613224983215, auc_score: 0.6153361391820327\n",
      "Training:- after 232 epochs, loss: 0.08692313730716705, auc_score: 0.6255904711184621\n",
      "Test:- after 232 epochs, loss: 0.08740952610969543, auc_score: 0.6192023288606376\n",
      "Training:- after 233 epochs, loss: 0.08901899307966232, auc_score: 0.6226342974412942\n",
      "Test:- after 233 epochs, loss: 0.08826173096895218, auc_score: 0.6177734039365194\n",
      "Training:- after 234 epochs, loss: 0.08602160215377808, auc_score: 0.6217057131034756\n",
      "Test:- after 234 epochs, loss: 0.08754894137382507, auc_score: 0.6154853471654897\n",
      "Training:- after 235 epochs, loss: 0.08683058619499207, auc_score: 0.6234935815564311\n",
      "Test:- after 235 epochs, loss: 0.08836138993501663, auc_score: 0.6169081543073788\n",
      "Training:- after 236 epochs, loss: 0.08620230108499527, auc_score: 0.6207805523009802\n",
      "Test:- after 236 epochs, loss: 0.08700771629810333, auc_score: 0.6172850382920942\n",
      "Training:- after 237 epochs, loss: 0.08610336482524872, auc_score: 0.6262338810585844\n",
      "Test:- after 237 epochs, loss: 0.09110872447490692, auc_score: 0.6200942940489647\n",
      "Training:- after 238 epochs, loss: 0.08920677751302719, auc_score: 0.6284628984847027\n",
      "Test:- after 238 epochs, loss: 0.08807309716939926, auc_score: 0.6344890252955373\n",
      "Training:- after 239 epochs, loss: 0.08600295335054398, auc_score: 0.6287110369225297\n",
      "Test:- after 239 epochs, loss: 0.08851064741611481, auc_score: 0.6248115238127213\n",
      "Training:- after 240 epochs, loss: 0.08646255731582642, auc_score: 0.6278086570455483\n",
      "Test:- after 240 epochs, loss: 0.08932583779096603, auc_score: 0.630401392417183\n",
      "Training:- after 241 epochs, loss: 0.08593957871198654, auc_score: 0.6247128920350261\n",
      "Test:- after 241 epochs, loss: 0.08750118315219879, auc_score: 0.6153394560893694\n",
      "Training:- after 242 epochs, loss: 0.08628571778535843, auc_score: 0.6153735627690365\n",
      "Test:- after 242 epochs, loss: 0.08670677244663239, auc_score: 0.6132887462649821\n",
      "Training:- after 243 epochs, loss: 0.08725286275148392, auc_score: 0.6151675856010845\n",
      "Test:- after 243 epochs, loss: 0.0895005464553833, auc_score: 0.6144014925150426\n",
      "Training:- after 244 epochs, loss: 0.08828744292259216, auc_score: 0.6209781667304741\n",
      "Test:- after 244 epochs, loss: 0.08722012490034103, auc_score: 0.612571871506678\n",
      "Training:- after 245 epochs, loss: 0.0860925018787384, auc_score: 0.6255968967030534\n",
      "Test:- after 245 epochs, loss: 0.08810213953256607, auc_score: 0.6267664101425865\n",
      "Training:- after 246 epochs, loss: 0.08680000901222229, auc_score: 0.6314049476298877\n",
      "Test:- after 246 epochs, loss: 0.08786959946155548, auc_score: 0.6261560681063351\n",
      "Training:- after 247 epochs, loss: 0.08587837219238281, auc_score: 0.6330243033855834\n",
      "Test:- after 247 epochs, loss: 0.0882023423910141, auc_score: 0.6304729748213471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 248 epochs, loss: 0.08524315804243088, auc_score: 0.6320357795752399\n",
      "Test:- after 248 epochs, loss: 0.08841995894908905, auc_score: 0.6354472664580154\n",
      "Training:- after 249 epochs, loss: 0.08687662333250046, auc_score: 0.63168913796648\n",
      "Test:- after 249 epochs, loss: 0.08920032531023026, auc_score: 0.6266740372264561\n",
      "Training:- after 250 epochs, loss: 0.08492544293403625, auc_score: 0.625367717024592\n",
      "Test:- after 250 epochs, loss: 0.08948411792516708, auc_score: 0.633031715478362\n",
      "Training:- after 251 epochs, loss: 0.08505120128393173, auc_score: 0.6286809694331634\n",
      "Test:- after 251 epochs, loss: 0.08650042116641998, auc_score: 0.6347717551196015\n",
      "Training:- after 252 epochs, loss: 0.08566217869520187, auc_score: 0.6318970360620748\n",
      "Test:- after 252 epochs, loss: 0.08564861118793488, auc_score: 0.6247913021798952\n",
      "Training:- after 253 epochs, loss: 0.08466197550296783, auc_score: 0.6277984054361332\n",
      "Test:- after 253 epochs, loss: 0.08549889922142029, auc_score: 0.6307182332292564\n",
      "Training:- after 254 epochs, loss: 0.08537101745605469, auc_score: 0.6283375944402705\n",
      "Test:- after 254 epochs, loss: 0.09094300121068954, auc_score: 0.6243127069569878\n",
      "Training:- after 255 epochs, loss: 0.08642548322677612, auc_score: 0.6287601095743036\n",
      "Test:- after 255 epochs, loss: 0.08554939925670624, auc_score: 0.619509427228856\n",
      "Training:- after 256 epochs, loss: 0.08470888435840607, auc_score: 0.6291180682815225\n",
      "Test:- after 256 epochs, loss: 0.08702601492404938, auc_score: 0.6277218939509807\n",
      "Training:- after 257 epochs, loss: 0.08524090051651001, auc_score: 0.6291969324779192\n",
      "Test:- after 257 epochs, loss: 0.08670502156019211, auc_score: 0.6209073000560796\n",
      "Training:- after 258 epochs, loss: 0.08417478948831558, auc_score: 0.6263993007803592\n",
      "Test:- after 258 epochs, loss: 0.08604655414819717, auc_score: 0.6317641688209467\n",
      "Training:- after 259 epochs, loss: 0.0844099372625351, auc_score: 0.6291489867571703\n",
      "Test:- after 259 epochs, loss: 0.08579155802726746, auc_score: 0.6251557671910303\n",
      "Training:- after 260 epochs, loss: 0.08470720797777176, auc_score: 0.6261798110267272\n",
      "Test:- after 260 epochs, loss: 0.08545918762683868, auc_score: 0.6240817668950888\n",
      "Training:- after 261 epochs, loss: 0.08377762883901596, auc_score: 0.627084614646406\n",
      "Test:- after 261 epochs, loss: 0.08547166734933853, auc_score: 0.6204424418655257\n",
      "Training:- after 262 epochs, loss: 0.08450279384851456, auc_score: 0.6315039534179944\n",
      "Test:- after 262 epochs, loss: 0.0876012071967125, auc_score: 0.633352812003785\n",
      "Training:- after 263 epochs, loss: 0.08424387127161026, auc_score: 0.631046788568382\n",
      "Test:- after 263 epochs, loss: 0.08575213700532913, auc_score: 0.6253299840962532\n",
      "Training:- after 264 epochs, loss: 0.08471988141536713, auc_score: 0.629355669765854\n",
      "Test:- after 264 epochs, loss: 0.08565627038478851, auc_score: 0.6337519102526321\n",
      "Training:- after 265 epochs, loss: 0.08526137471199036, auc_score: 0.6317521788244229\n",
      "Test:- after 265 epochs, loss: 0.0873807817697525, auc_score: 0.6295094179029685\n",
      "Training:- after 266 epochs, loss: 0.08407510817050934, auc_score: 0.6328133468446987\n",
      "Test:- after 266 epochs, loss: 0.08850635588169098, auc_score: 0.6349767039329133\n",
      "Training:- after 267 epochs, loss: 0.08364979922771454, auc_score: 0.6339115718991468\n",
      "Test:- after 267 epochs, loss: 0.08473983407020569, auc_score: 0.6367355352375552\n",
      "Training:- after 268 epochs, loss: 0.08498208224773407, auc_score: 0.6333655594711158\n",
      "Test:- after 268 epochs, loss: 0.08635243028402328, auc_score: 0.631897423319444\n",
      "Training:- after 269 epochs, loss: 0.08309096097946167, auc_score: 0.6322915737235085\n",
      "Test:- after 269 epochs, loss: 0.08566021919250488, auc_score: 0.6363263805733058\n",
      "Training:- after 270 epochs, loss: 0.08328192681074142, auc_score: 0.6327559136311554\n",
      "Test:- after 270 epochs, loss: 0.09006775915622711, auc_score: 0.6366090762024489\n",
      "Training:- after 271 epochs, loss: 0.08305675536394119, auc_score: 0.6355756732476652\n",
      "Test:- after 271 epochs, loss: 0.08489517122507095, auc_score: 0.6331741435415742\n",
      "Training:- after 272 epochs, loss: 0.08398737013339996, auc_score: 0.6323947664709763\n",
      "Test:- after 272 epochs, loss: 0.08508533239364624, auc_score: 0.628533811937882\n",
      "Training:- after 273 epochs, loss: 0.0829661414027214, auc_score: 0.6312506779951961\n",
      "Test:- after 273 epochs, loss: 0.08511132746934891, auc_score: 0.6373667890223113\n",
      "Training:- after 274 epochs, loss: 0.08363323658704758, auc_score: 0.6340380407687729\n",
      "Test:- after 274 epochs, loss: 0.08668532222509384, auc_score: 0.6223073551409888\n",
      "Training:- after 275 epochs, loss: 0.08284686505794525, auc_score: 0.6322380287682932\n",
      "Test:- after 275 epochs, loss: 0.08505718410015106, auc_score: 0.6346317207008592\n",
      "Training:- after 276 epochs, loss: 0.08328118920326233, auc_score: 0.6348871728085257\n",
      "Test:- after 276 epochs, loss: 0.08533310890197754, auc_score: 0.6307889980639457\n",
      "Training:- after 277 epochs, loss: 0.08339322358369827, auc_score: 0.6341563094589995\n",
      "Test:- after 277 epochs, loss: 0.08365178853273392, auc_score: 0.6303524998974152\n",
      "Training:- after 278 epochs, loss: 0.08354230970144272, auc_score: 0.6346896342663098\n",
      "Test:- after 278 epochs, loss: 0.08412941545248032, auc_score: 0.631453470660136\n",
      "Training:- after 279 epochs, loss: 0.08349640667438507, auc_score: 0.6344413134813467\n",
      "Test:- after 279 epochs, loss: 0.08389566838741302, auc_score: 0.6277619051171766\n",
      "Training:- after 280 epochs, loss: 0.08298338949680328, auc_score: 0.6366915601508661\n",
      "Test:- after 280 epochs, loss: 0.08889956027269363, auc_score: 0.6327967497416729\n",
      "Training:- after 281 epochs, loss: 0.08274933695793152, auc_score: 0.6336108780089299\n",
      "Test:- after 281 epochs, loss: 0.0836789682507515, auc_score: 0.6373206352048524\n",
      "Training:- after 282 epochs, loss: 0.08467146754264832, auc_score: 0.6345976368216826\n",
      "Test:- after 282 epochs, loss: 0.0843081921339035, auc_score: 0.6342927184713503\n",
      "Training:- after 283 epochs, loss: 0.08356565982103348, auc_score: 0.6349455514964217\n",
      "Test:- after 283 epochs, loss: 0.08432696759700775, auc_score: 0.638177034566713\n",
      "Training:- after 284 epochs, loss: 0.08301285654306412, auc_score: 0.636778267153979\n",
      "Test:- after 284 epochs, loss: 0.08445391058921814, auc_score: 0.6329614915451504\n",
      "Training:- after 285 epochs, loss: 0.08299917727708817, auc_score: 0.6377404035627069\n",
      "Test:- after 285 epochs, loss: 0.08341239392757416, auc_score: 0.6322234998688159\n",
      "Training:- after 286 epochs, loss: 0.08238554000854492, auc_score: 0.6374800200645172\n",
      "Test:- after 286 epochs, loss: 0.0841929242014885, auc_score: 0.635436181086354\n",
      "Training:- after 287 epochs, loss: 0.08295108377933502, auc_score: 0.6410242455450321\n",
      "Test:- after 287 epochs, loss: 0.08510567992925644, auc_score: 0.6321257707846055\n",
      "Training:- after 288 epochs, loss: 0.0840136930346489, auc_score: 0.6418208156023294\n",
      "Test:- after 288 epochs, loss: 0.08436568081378937, auc_score: 0.6448811508891301\n",
      "Training:- after 289 epochs, loss: 0.08288346230983734, auc_score: 0.639802023943386\n",
      "Test:- after 289 epochs, loss: 0.08337737619876862, auc_score: 0.6320433299387103\n",
      "Training:- after 290 epochs, loss: 0.08348661661148071, auc_score: 0.6368381810998835\n",
      "Test:- after 290 epochs, loss: 0.0844230055809021, auc_score: 0.6328099520898071\n",
      "Training:- after 291 epochs, loss: 0.08198680728673935, auc_score: 0.6336624932308078\n",
      "Test:- after 291 epochs, loss: 0.08461777120828629, auc_score: 0.6381295999940315\n",
      "Training:- after 292 epochs, loss: 0.08224409073591232, auc_score: 0.6356895570977537\n",
      "Test:- after 292 epochs, loss: 0.08377914130687714, auc_score: 0.632345212027162\n",
      "Training:- after 293 epochs, loss: 0.08345009386539459, auc_score: 0.6312213363325199\n",
      "Test:- after 293 epochs, loss: 0.08342257142066956, auc_score: 0.6424401246933338\n",
      "Training:- after 294 epochs, loss: 0.08212245255708694, auc_score: 0.6363396224609899\n",
      "Test:- after 294 epochs, loss: 0.08342742919921875, auc_score: 0.631901859333286\n",
      "Training:- after 295 epochs, loss: 0.08216896653175354, auc_score: 0.6381817658513472\n",
      "Test:- after 295 epochs, loss: 0.08473208546638489, auc_score: 0.6341931863822148\n",
      "Training:- after 296 epochs, loss: 0.08307000994682312, auc_score: 0.6394947470544197\n",
      "Test:- after 296 epochs, loss: 0.08433380722999573, auc_score: 0.6336830634421478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 297 epochs, loss: 0.08321882039308548, auc_score: 0.6420781729097962\n",
      "Test:- after 297 epochs, loss: 0.0845031663775444, auc_score: 0.6343524290206699\n",
      "Training:- after 298 epochs, loss: 0.0819498673081398, auc_score: 0.6414155977217174\n",
      "Test:- after 298 epochs, loss: 0.08555373549461365, auc_score: 0.6302084553470287\n",
      "Training:- after 299 epochs, loss: 0.08201795071363449, auc_score: 0.6368086156340487\n",
      "Test:- after 299 epochs, loss: 0.08341510593891144, auc_score: 0.6373788411776482\n",
      "Training:- after 300 epochs, loss: 0.08149541169404984, auc_score: 0.640214420641767\n",
      "Test:- after 300 epochs, loss: 0.08584976941347122, auc_score: 0.637450967591919\n",
      "Training:- after 301 epochs, loss: 0.081771120429039, auc_score: 0.6385180889669896\n",
      "Test:- after 301 epochs, loss: 0.08694370090961456, auc_score: 0.6331033787068849\n",
      "Training:- after 302 epochs, loss: 0.08167664706707001, auc_score: 0.6394645307587092\n",
      "Test:- after 302 epochs, loss: 0.08467137068510056, auc_score: 0.6410367122889085\n",
      "Training:- after 303 epochs, loss: 0.08374378830194473, auc_score: 0.6417445849022537\n",
      "Test:- after 303 epochs, loss: 0.08279842138290405, auc_score: 0.638697876060198\n",
      "Training:- after 304 epochs, loss: 0.08249790221452713, auc_score: 0.6407102208226291\n",
      "Test:- after 304 epochs, loss: 0.08311592042446136, auc_score: 0.6363408885456963\n",
      "Training:- after 305 epochs, loss: 0.08100724965333939, auc_score: 0.6426171649236199\n",
      "Test:- after 305 epochs, loss: 0.08264800906181335, auc_score: 0.6424169281023808\n",
      "Training:- after 306 epochs, loss: 0.08144139498472214, auc_score: 0.639409749939101\n",
      "Test:- after 306 epochs, loss: 0.08222954720258713, auc_score: 0.6408837894935795\n",
      "Training:- after 307 epochs, loss: 0.08163812011480331, auc_score: 0.6402556425715935\n",
      "Test:- after 307 epochs, loss: 0.08585372567176819, auc_score: 0.6378564540737341\n",
      "Training:- after 308 epochs, loss: 0.08178988099098206, auc_score: 0.6405326681399517\n",
      "Test:- after 308 epochs, loss: 0.08359455317258835, auc_score: 0.6343640832714716\n",
      "Training:- after 309 epochs, loss: 0.08114413172006607, auc_score: 0.6404922881928314\n",
      "Test:- after 309 epochs, loss: 0.08251351118087769, auc_score: 0.6426882243883151\n",
      "Training:- after 310 epochs, loss: 0.08099940419197083, auc_score: 0.646353230078913\n",
      "Test:- after 310 epochs, loss: 0.08420796692371368, auc_score: 0.6426744003143445\n",
      "Training:- after 311 epochs, loss: 0.08200186491012573, auc_score: 0.6439974039229339\n",
      "Test:- after 311 epochs, loss: 0.08665049076080322, auc_score: 0.6393485307996762\n",
      "Training:- after 312 epochs, loss: 0.0806419625878334, auc_score: 0.6436787810449153\n",
      "Test:- after 312 epochs, loss: 0.0821906328201294, auc_score: 0.6454029156454819\n",
      "Training:- after 313 epochs, loss: 0.0813671350479126, auc_score: 0.6440230058368052\n",
      "Test:- after 313 epochs, loss: 0.08292949199676514, auc_score: 0.6339107487692937\n",
      "Training:- after 314 epochs, loss: 0.0817698985338211, auc_score: 0.6392951872590069\n",
      "Test:- after 314 epochs, loss: 0.08368165045976639, auc_score: 0.6406350773986493\n",
      "Training:- after 315 epochs, loss: 0.0813465565443039, auc_score: 0.6377393865544534\n",
      "Test:- after 315 epochs, loss: 0.08240538835525513, auc_score: 0.6349796229357147\n",
      "Training:- after 316 epochs, loss: 0.0807989090681076, auc_score: 0.6439796321514095\n",
      "Test:- after 316 epochs, loss: 0.08525331318378448, auc_score: 0.6438598325319287\n",
      "Training:- after 317 epochs, loss: 0.08020327985286713, auc_score: 0.6432488875303494\n",
      "Test:- after 317 epochs, loss: 0.08291603624820709, auc_score: 0.6433976601969876\n",
      "Training:- after 318 epochs, loss: 0.08082414418458939, auc_score: 0.6502826558206365\n",
      "Test:- after 318 epochs, loss: 0.08611063659191132, auc_score: 0.6484713782293995\n",
      "Training:- after 319 epochs, loss: 0.08386184275150299, auc_score: 0.6464635731493179\n",
      "Test:- after 319 epochs, loss: 0.08295099437236786, auc_score: 0.6470379799878887\n",
      "Training:- after 320 epochs, loss: 0.08073856681585312, auc_score: 0.6452525224122365\n",
      "Test:- after 320 epochs, loss: 0.08213379979133606, auc_score: 0.6470897604241662\n",
      "Training:- after 321 epochs, loss: 0.08188970386981964, auc_score: 0.6425560094737203\n",
      "Test:- after 321 epochs, loss: 0.08337824791669846, auc_score: 0.6452038949880193\n",
      "Training:- after 322 epochs, loss: 0.08135954290628433, auc_score: 0.6452878435372922\n",
      "Test:- after 322 epochs, loss: 0.08165988326072693, auc_score: 0.6418240721052756\n",
      "Training:- after 323 epochs, loss: 0.08068981766700745, auc_score: 0.639918788442886\n",
      "Test:- after 323 epochs, loss: 0.08231700956821442, auc_score: 0.6419730500501732\n",
      "Training:- after 324 epochs, loss: 0.08091791719198227, auc_score: 0.6405784948543999\n",
      "Test:- after 324 epochs, loss: 0.08235105872154236, auc_score: 0.6470250574163809\n",
      "Training:- after 325 epochs, loss: 0.08021814376115799, auc_score: 0.6433008338067672\n",
      "Test:- after 325 epochs, loss: 0.0823432207107544, auc_score: 0.634194594591234\n",
      "Training:- after 326 epochs, loss: 0.0807017907500267, auc_score: 0.6427089544944906\n",
      "Test:- after 326 epochs, loss: 0.08180031180381775, auc_score: 0.6392270207022268\n",
      "Training:- after 327 epochs, loss: 0.07993899285793304, auc_score: 0.643521188893037\n",
      "Test:- after 327 epochs, loss: 0.08179382979869843, auc_score: 0.6395285763846146\n",
      "Training:- after 328 epochs, loss: 0.0796087309718132, auc_score: 0.6420149294219375\n",
      "Test:- after 328 epochs, loss: 0.081155925989151, auc_score: 0.6392277605559722\n",
      "Training:- after 329 epochs, loss: 0.07979082316160202, auc_score: 0.6463631154110098\n",
      "Test:- after 329 epochs, loss: 0.08370456844568253, auc_score: 0.646044819593814\n",
      "Training:- after 330 epochs, loss: 0.07997310906648636, auc_score: 0.6446702160772502\n",
      "Test:- after 330 epochs, loss: 0.08223229646682739, auc_score: 0.6432370497616924\n",
      "Training:- after 331 epochs, loss: 0.0808422639966011, auc_score: 0.6477510655273833\n",
      "Test:- after 331 epochs, loss: 0.08206777274608612, auc_score: 0.6475117817045981\n",
      "Training:- after 332 epochs, loss: 0.07990206032991409, auc_score: 0.6456836351692099\n",
      "Test:- after 332 epochs, loss: 0.08278001844882965, auc_score: 0.6469053938446656\n",
      "Training:- after 333 epochs, loss: 0.07968411594629288, auc_score: 0.6463517805032809\n",
      "Test:- after 333 epochs, loss: 0.08116941154003143, auc_score: 0.646254117379351\n",
      "Training:- after 334 epochs, loss: 0.07985498011112213, auc_score: 0.6476007541018743\n",
      "Test:- after 334 epochs, loss: 0.0810513123869896, auc_score: 0.6472002038017292\n",
      "Training:- after 335 epochs, loss: 0.0801239162683487, auc_score: 0.650117306445478\n",
      "Test:- after 335 epochs, loss: 0.08135300129652023, auc_score: 0.6468252844706563\n",
      "Training:- after 336 epochs, loss: 0.08014210313558578, auc_score: 0.6493727957534626\n",
      "Test:- after 336 epochs, loss: 0.08301116526126862, auc_score: 0.6438297814136305\n",
      "Training:- after 337 epochs, loss: 0.07958836108446121, auc_score: 0.6494412229261561\n",
      "Test:- after 337 epochs, loss: 0.08107281476259232, auc_score: 0.6488076106703075\n",
      "Training:- after 338 epochs, loss: 0.07990298420190811, auc_score: 0.6496285903964334\n",
      "Test:- after 338 epochs, loss: 0.0823051854968071, auc_score: 0.6469608611151524\n",
      "Training:- after 339 epochs, loss: 0.07965517044067383, auc_score: 0.6450557417533965\n",
      "Test:- after 339 epochs, loss: 0.08049970120191574, auc_score: 0.6463600563532299\n",
      "Training:- after 340 epochs, loss: 0.07938223332166672, auc_score: 0.6501986305967542\n",
      "Test:- after 340 epochs, loss: 0.08106706291437149, auc_score: 0.6409126251378677\n",
      "Training:- after 341 epochs, loss: 0.07926961034536362, auc_score: 0.6516889851035796\n",
      "Test:- after 341 epochs, loss: 0.0829198881983757, auc_score: 0.6474130671849374\n",
      "Training:- after 342 epochs, loss: 0.07982715219259262, auc_score: 0.6497564208836862\n",
      "Test:- after 342 epochs, loss: 0.08269485086202621, auc_score: 0.6512086256999079\n",
      "Training:- after 343 epochs, loss: 0.07908744364976883, auc_score: 0.6477236719020165\n",
      "Test:- after 343 epochs, loss: 0.08069750666618347, auc_score: 0.6417326752987081\n",
      "Training:- after 344 epochs, loss: 0.08004932105541229, auc_score: 0.6481228905321712\n",
      "Test:- after 344 epochs, loss: 0.08136552572250366, auc_score: 0.6446900976482599\n",
      "Training:- after 345 epochs, loss: 0.08044502884149551, auc_score: 0.6450733239551366\n",
      "Test:- after 345 epochs, loss: 0.08144821226596832, auc_score: 0.6419813221124255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 346 epochs, loss: 0.07950153946876526, auc_score: 0.645211403578295\n",
      "Test:- after 346 epochs, loss: 0.08053459972143173, auc_score: 0.6467296506025145\n",
      "Training:- after 347 epochs, loss: 0.07900678366422653, auc_score: 0.6497889187447558\n",
      "Test:- after 347 epochs, loss: 0.08104990422725677, auc_score: 0.6458930594257989\n",
      "Training:- after 348 epochs, loss: 0.07957478612661362, auc_score: 0.6539799330786011\n",
      "Test:- after 348 epochs, loss: 0.08048408478498459, auc_score: 0.6546851611451195\n",
      "Training:- after 349 epochs, loss: 0.08133763074874878, auc_score: 0.6549910888102333\n",
      "Test:- after 349 epochs, loss: 0.08040433377027512, auc_score: 0.644108239981199\n",
      "Training:- after 350 epochs, loss: 0.0790388435125351, auc_score: 0.654660870811264\n",
      "Test:- after 350 epochs, loss: 0.08016574382781982, auc_score: 0.6505545297079256\n",
      "Training:- after 351 epochs, loss: 0.07925973832607269, auc_score: 0.6488814978549797\n",
      "Test:- after 351 epochs, loss: 0.07978527247905731, auc_score: 0.649325927956897\n",
      "Training:- after 352 epochs, loss: 0.07888554036617279, auc_score: 0.6523445496725496\n",
      "Test:- after 352 epochs, loss: 0.08079095184803009, auc_score: 0.6464891483972529\n",
      "Training:- after 353 epochs, loss: 0.078870490193367, auc_score: 0.6481273788639555\n",
      "Test:- after 353 epochs, loss: 0.08228722959756851, auc_score: 0.6529168951509116\n",
      "Training:- after 354 epochs, loss: 0.07942379266023636, auc_score: 0.6489935021345078\n",
      "Test:- after 354 epochs, loss: 0.08041782677173615, auc_score: 0.6467856339054455\n",
      "Training:- after 355 epochs, loss: 0.07888481765985489, auc_score: 0.656438283540783\n",
      "Test:- after 355 epochs, loss: 0.08310716599225998, auc_score: 0.6575554921395202\n",
      "Training:- after 356 epochs, loss: 0.07887472212314606, auc_score: 0.6528313722004391\n",
      "Test:- after 356 epochs, loss: 0.08042359352111816, auc_score: 0.6468193905097281\n",
      "Training:- after 357 epochs, loss: 0.07860399782657623, auc_score: 0.6532007505083595\n",
      "Test:- after 357 epochs, loss: 0.07999112457036972, auc_score: 0.6541541202392899\n",
      "Training:- after 358 epochs, loss: 0.07831213623285294, auc_score: 0.6551037156226858\n",
      "Test:- after 358 epochs, loss: 0.08045521378517151, auc_score: 0.6539009596960009\n",
      "Training:- after 359 epochs, loss: 0.07859662920236588, auc_score: 0.6516155606497434\n",
      "Test:- after 359 epochs, loss: 0.08036363124847412, auc_score: 0.6537370727655484\n",
      "Training:- after 360 epochs, loss: 0.07900936901569366, auc_score: 0.6498296700151541\n",
      "Test:- after 360 epochs, loss: 0.08135271072387695, auc_score: 0.6564929782284047\n",
      "Training:- after 361 epochs, loss: 0.07889243215322495, auc_score: 0.6535616269676355\n",
      "Test:- after 361 epochs, loss: 0.08087599277496338, auc_score: 0.6549722803535879\n",
      "Training:- after 362 epochs, loss: 0.0784095972776413, auc_score: 0.6562085822485934\n",
      "Test:- after 362 epochs, loss: 0.08057407289743423, auc_score: 0.6539222009591985\n",
      "Training:- after 363 epochs, loss: 0.07879787683486938, auc_score: 0.6514621907789448\n",
      "Test:- after 363 epochs, loss: 0.08395005017518997, auc_score: 0.6497184390205082\n",
      "Training:- after 364 epochs, loss: 0.07841013371944427, auc_score: 0.6552745106768281\n",
      "Test:- after 364 epochs, loss: 0.08014252036809921, auc_score: 0.648614617644828\n",
      "Training:- after 365 epochs, loss: 0.07978188246488571, auc_score: 0.6558627023818845\n",
      "Test:- after 365 epochs, loss: 0.07973411679267883, auc_score: 0.6491994720304197\n",
      "Training:- after 366 epochs, loss: 0.07841689884662628, auc_score: 0.6540506178730795\n",
      "Test:- after 366 epochs, loss: 0.08092664182186127, auc_score: 0.6533944893952224\n",
      "Training:- after 367 epochs, loss: 0.07852616161108017, auc_score: 0.6551435500125038\n",
      "Test:- after 367 epochs, loss: 0.0806882232427597, auc_score: 0.6548161059321349\n",
      "Training:- after 368 epochs, loss: 0.07804905623197556, auc_score: 0.6546299081092626\n",
      "Test:- after 368 epochs, loss: 0.08004865050315857, auc_score: 0.6469260289251728\n",
      "Training:- after 369 epochs, loss: 0.07830983400344849, auc_score: 0.6585057106339235\n",
      "Test:- after 369 epochs, loss: 0.08102348446846008, auc_score: 0.6544960787751504\n",
      "Training:- after 370 epochs, loss: 0.07815039157867432, auc_score: 0.6580356146712943\n",
      "Test:- after 370 epochs, loss: 0.08059753477573395, auc_score: 0.6536292810486775\n",
      "Training:- after 371 epochs, loss: 0.07852253317832947, auc_score: 0.6585941635391321\n",
      "Test:- after 371 epochs, loss: 0.0815763920545578, auc_score: 0.6535631947009064\n",
      "Training:- after 372 epochs, loss: 0.07802941650152206, auc_score: 0.6545482201541779\n",
      "Test:- after 372 epochs, loss: 0.08025196939706802, auc_score: 0.6496882480138968\n",
      "Training:- after 373 epochs, loss: 0.07917976379394531, auc_score: 0.6538595095656533\n",
      "Test:- after 373 epochs, loss: 0.08137015998363495, auc_score: 0.6520196079894256\n",
      "Training:- after 374 epochs, loss: 0.07790357619524002, auc_score: 0.652502659084779\n",
      "Test:- after 374 epochs, loss: 0.07925121486186981, auc_score: 0.654094645945788\n",
      "Training:- after 375 epochs, loss: 0.07791867852210999, auc_score: 0.6520111612277708\n",
      "Test:- after 375 epochs, loss: 0.079243965446949, auc_score: 0.652523028724977\n",
      "Training:- after 376 epochs, loss: 0.07885632663965225, auc_score: 0.6501155828049697\n",
      "Test:- after 376 epochs, loss: 0.07902993261814117, auc_score: 0.6457699825792421\n",
      "Training:- after 377 epochs, loss: 0.08159288763999939, auc_score: 0.6541982275333995\n",
      "Test:- after 377 epochs, loss: 0.08173798024654388, auc_score: 0.6502449164586993\n",
      "Training:- after 378 epochs, loss: 0.07876808941364288, auc_score: 0.6543973453620968\n",
      "Test:- after 378 epochs, loss: 0.07956697046756744, auc_score: 0.6612465758449564\n",
      "Training:- after 379 epochs, loss: 0.078861765563488, auc_score: 0.6567136653135266\n",
      "Test:- after 379 epochs, loss: 0.07927539199590683, auc_score: 0.6606541799249701\n",
      "Training:- after 380 epochs, loss: 0.0787782296538353, auc_score: 0.6624131753691326\n",
      "Test:- after 380 epochs, loss: 0.08030116558074951, auc_score: 0.6589755263841793\n",
      "Training:- after 381 epochs, loss: 0.07774779200553894, auc_score: 0.6615923707541335\n",
      "Test:- after 381 epochs, loss: 0.07906774431467056, auc_score: 0.6631029279556535\n",
      "Training:- after 382 epochs, loss: 0.07813946902751923, auc_score: 0.6630683224096631\n",
      "Test:- after 382 epochs, loss: 0.0802779272198677, auc_score: 0.660378021742996\n",
      "Training:- after 383 epochs, loss: 0.07812930643558502, auc_score: 0.6630257402473754\n",
      "Test:- after 383 epochs, loss: 0.08030583709478378, auc_score: 0.6575156892514794\n",
      "Training:- after 384 epochs, loss: 0.07786744832992554, auc_score: 0.6600042608678313\n",
      "Test:- after 384 epochs, loss: 0.07937172800302505, auc_score: 0.6631464332210496\n",
      "Training:- after 385 epochs, loss: 0.0775587260723114, auc_score: 0.660011614810088\n",
      "Test:- after 385 epochs, loss: 0.07921697199344635, auc_score: 0.6612492492660527\n",
      "Training:- after 386 epochs, loss: 0.07815999537706375, auc_score: 0.6587426011326231\n",
      "Test:- after 386 epochs, loss: 0.0793866217136383, auc_score: 0.6587439179670063\n",
      "Training:- after 387 epochs, loss: 0.07775253802537918, auc_score: 0.6555028010790775\n",
      "Test:- after 387 epochs, loss: 0.08139452338218689, auc_score: 0.6587609719066965\n",
      "Training:- after 388 epochs, loss: 0.0775710865855217, auc_score: 0.6554191181889393\n",
      "Test:- after 388 epochs, loss: 0.07991937547922134, auc_score: 0.6516449497832042\n",
      "Training:- after 389 epochs, loss: 0.07785620540380478, auc_score: 0.6510779069036146\n",
      "Test:- after 389 epochs, loss: 0.07919225841760635, auc_score: 0.652397020441102\n",
      "Training:- after 390 epochs, loss: 0.07778018712997437, auc_score: 0.6548483666072251\n",
      "Test:- after 390 epochs, loss: 0.07910516113042831, auc_score: 0.6513531241101549\n",
      "Training:- after 391 epochs, loss: 0.07837197184562683, auc_score: 0.6527088454127123\n",
      "Test:- after 391 epochs, loss: 0.0788431242108345, auc_score: 0.6541577759872074\n",
      "Training:- after 392 epochs, loss: 0.07792134582996368, auc_score: 0.6559162877047784\n",
      "Test:- after 392 epochs, loss: 0.07899583131074905, auc_score: 0.6550740941765427\n",
      "Training:- after 393 epochs, loss: 0.0769643634557724, auc_score: 0.6578769056803107\n",
      "Test:- after 393 epochs, loss: 0.07841368764638901, auc_score: 0.6519224322412097\n",
      "Training:- after 394 epochs, loss: 0.077472984790802, auc_score: 0.6614094366047847\n",
      "Test:- after 394 epochs, loss: 0.07933202385902405, auc_score: 0.655064441882934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 395 epochs, loss: 0.07757380604743958, auc_score: 0.661751187985902\n",
      "Test:- after 395 epochs, loss: 0.07845903933048248, auc_score: 0.6518488820747737\n",
      "Training:- after 396 epochs, loss: 0.07743453979492188, auc_score: 0.6623727331885081\n",
      "Test:- after 396 epochs, loss: 0.0784558430314064, auc_score: 0.6644889973178747\n",
      "Training:- after 397 epochs, loss: 0.0771944671869278, auc_score: 0.6654879659077542\n",
      "Test:- after 397 epochs, loss: 0.07880149036645889, auc_score: 0.6597505169650328\n",
      "Training:- after 398 epochs, loss: 0.07893939316272736, auc_score: 0.6640163968167334\n",
      "Test:- after 398 epochs, loss: 0.0786006823182106, auc_score: 0.6639267053628828\n",
      "Training:- after 399 epochs, loss: 0.07714327424764633, auc_score: 0.6609672073015197\n",
      "Test:- after 399 epochs, loss: 0.07870136201381683, auc_score: 0.6666774349581516\n",
      "Training:- after 400 epochs, loss: 0.07679887115955353, auc_score: 0.6645963828017285\n",
      "Test:- after 400 epochs, loss: 0.07860210537910461, auc_score: 0.6543731604686818\n",
      "Training:- after 401 epochs, loss: 0.0768340453505516, auc_score: 0.6594558076793562\n",
      "Test:- after 401 epochs, loss: 0.07976038008928299, auc_score: 0.6598532229645628\n",
      "Training:- after 402 epochs, loss: 0.07714661210775375, auc_score: 0.6634882377860478\n",
      "Test:- after 402 epochs, loss: 0.07836885005235672, auc_score: 0.6588208472133626\n",
      "Training:- after 403 epochs, loss: 0.07700236886739731, auc_score: 0.6592118091052653\n",
      "Test:- after 403 epochs, loss: 0.07972659170627594, auc_score: 0.6570890330049378\n",
      "Training:- after 404 epochs, loss: 0.07698255032300949, auc_score: 0.6593483322971718\n",
      "Test:- after 404 epochs, loss: 0.07799568772315979, auc_score: 0.6610125520229093\n",
      "Training:- after 405 epochs, loss: 0.0767674595117569, auc_score: 0.6639250454528434\n",
      "Test:- after 405 epochs, loss: 0.07822588831186295, auc_score: 0.6560608725549077\n",
      "Training:- after 406 epochs, loss: 0.0770200565457344, auc_score: 0.6595054733798188\n",
      "Test:- after 406 epochs, loss: 0.0784192904829979, auc_score: 0.6543009749904565\n",
      "Training:- after 407 epochs, loss: 0.07706035673618317, auc_score: 0.6616821228455836\n",
      "Test:- after 407 epochs, loss: 0.07907819002866745, auc_score: 0.6643049633616964\n",
      "Training:- after 408 epochs, loss: 0.076805479824543, auc_score: 0.6610817515787015\n",
      "Test:- after 408 epochs, loss: 0.07858037203550339, auc_score: 0.6620123648834326\n",
      "Training:- after 409 epochs, loss: 0.07663590461015701, auc_score: 0.6603669459574093\n",
      "Test:- after 409 epochs, loss: 0.0779528021812439, auc_score: 0.6632019253605699\n",
      "Training:- after 410 epochs, loss: 0.07710178196430206, auc_score: 0.6626510640774118\n",
      "Test:- after 410 epochs, loss: 0.07817813754081726, auc_score: 0.6615885312721879\n",
      "Training:- after 411 epochs, loss: 0.07674545794725418, auc_score: 0.6629746563353838\n",
      "Test:- after 411 epochs, loss: 0.07845015823841095, auc_score: 0.6639718986139245\n",
      "Training:- after 412 epochs, loss: 0.07658452540636063, auc_score: 0.6667180412984999\n",
      "Test:- after 412 epochs, loss: 0.07808610796928406, auc_score: 0.6570095173791023\n",
      "Training:- after 413 epochs, loss: 0.07648950815200806, auc_score: 0.6637298288436649\n",
      "Test:- after 413 epochs, loss: 0.0784444734454155, auc_score: 0.6584047976095886\n",
      "Training:- after 414 epochs, loss: 0.07664119452238083, auc_score: 0.6643027171420095\n",
      "Test:- after 414 epochs, loss: 0.07834609597921371, auc_score: 0.6612133694680389\n",
      "Training:- after 415 epochs, loss: 0.07696598023176193, auc_score: 0.6628393859266767\n",
      "Test:- after 415 epochs, loss: 0.07851576805114746, auc_score: 0.6630630473518832\n",
      "Training:- after 416 epochs, loss: 0.07648485898971558, auc_score: 0.6640458689817821\n",
      "Test:- after 416 epochs, loss: 0.0780876949429512, auc_score: 0.6611027364640959\n",
      "Training:- after 417 epochs, loss: 0.07658859342336655, auc_score: 0.6625479880796026\n",
      "Test:- after 417 epochs, loss: 0.0792744979262352, auc_score: 0.6649181964230868\n",
      "Training:- after 418 epochs, loss: 0.07681523263454437, auc_score: 0.6632139676085691\n",
      "Test:- after 418 epochs, loss: 0.07780233770608902, auc_score: 0.661064749015497\n",
      "Training:- after 419 epochs, loss: 0.07641302049160004, auc_score: 0.6644150819603133\n",
      "Test:- after 419 epochs, loss: 0.07763150334358215, auc_score: 0.6648994016510552\n",
      "Training:- after 420 epochs, loss: 0.07627638429403305, auc_score: 0.6636016748213416\n",
      "Test:- after 420 epochs, loss: 0.07832394540309906, auc_score: 0.6608016564019732\n",
      "Training:- after 421 epochs, loss: 0.07633093744516373, auc_score: 0.6651182847433045\n",
      "Test:- after 421 epochs, loss: 0.07785273343324661, auc_score: 0.6608194470867793\n",
      "Training:- after 422 epochs, loss: 0.0767894983291626, auc_score: 0.6661368404244743\n",
      "Test:- after 422 epochs, loss: 0.0792543813586235, auc_score: 0.6671847818923594\n",
      "Training:- after 423 epochs, loss: 0.07641614973545074, auc_score: 0.6659558244324374\n",
      "Test:- after 423 epochs, loss: 0.07793519645929337, auc_score: 0.6641543254088158\n",
      "Training:- after 424 epochs, loss: 0.07600277662277222, auc_score: 0.6681511937165294\n",
      "Test:- after 424 epochs, loss: 0.07959404587745667, auc_score: 0.670741955178541\n",
      "Training:- after 425 epochs, loss: 0.07649283111095428, auc_score: 0.6674945803794412\n",
      "Test:- after 425 epochs, loss: 0.07781060039997101, auc_score: 0.6642120681958634\n",
      "Training:- after 426 epochs, loss: 0.07630753517150879, auc_score: 0.6684485895278357\n",
      "Test:- after 426 epochs, loss: 0.07890459895133972, auc_score: 0.6640142443606358\n",
      "Training:- after 427 epochs, loss: 0.07657268643379211, auc_score: 0.6674906277109203\n",
      "Test:- after 427 epochs, loss: 0.07753454893827438, auc_score: 0.6657241054297804\n",
      "Training:- after 428 epochs, loss: 0.0762779489159584, auc_score: 0.6670764018026365\n",
      "Test:- after 428 epochs, loss: 0.07794979214668274, auc_score: 0.662145501254021\n",
      "Training:- after 429 epochs, loss: 0.0767991691827774, auc_score: 0.6692606189218971\n",
      "Test:- after 429 epochs, loss: 0.07808507233858109, auc_score: 0.668692721953015\n",
      "Training:- after 430 epochs, loss: 0.0764927938580513, auc_score: 0.6681802958445249\n",
      "Test:- after 430 epochs, loss: 0.07817946374416351, auc_score: 0.6630629385498618\n",
      "Training:- after 431 epochs, loss: 0.07604371011257172, auc_score: 0.6645513870876035\n",
      "Test:- after 431 epochs, loss: 0.07875217497348785, auc_score: 0.6635191765116952\n",
      "Training:- after 432 epochs, loss: 0.07579898089170456, auc_score: 0.6656405795771634\n",
      "Test:- after 432 epochs, loss: 0.0785566195845604, auc_score: 0.6611647349644934\n",
      "Training:- after 433 epochs, loss: 0.07604385912418365, auc_score: 0.6680748842599046\n",
      "Test:- after 433 epochs, loss: 0.07748184353113174, auc_score: 0.6711788761186401\n",
      "Training:- after 434 epochs, loss: 0.07659611850976944, auc_score: 0.6674363948231836\n",
      "Test:- after 434 epochs, loss: 0.07757396996021271, auc_score: 0.6642567018936526\n",
      "Training:- after 435 epochs, loss: 0.07598923146724701, auc_score: 0.6666910710390554\n",
      "Test:- after 435 epochs, loss: 0.07687771320343018, auc_score: 0.6667354388700506\n",
      "Training:- after 436 epochs, loss: 0.07597433775663376, auc_score: 0.6682526117702484\n",
      "Test:- after 436 epochs, loss: 0.07802411168813705, auc_score: 0.6609486603673405\n",
      "Training:- after 437 epochs, loss: 0.07618466764688492, auc_score: 0.6658285929302967\n",
      "Test:- after 437 epochs, loss: 0.0780445784330368, auc_score: 0.6600139328759917\n",
      "Training:- after 438 epochs, loss: 0.07569295912981033, auc_score: 0.6692933061548704\n",
      "Test:- after 438 epochs, loss: 0.07714901864528656, auc_score: 0.6684076886347274\n",
      "Training:- after 439 epochs, loss: 0.07583361119031906, auc_score: 0.6676646256633193\n",
      "Test:- after 439 epochs, loss: 0.0780043825507164, auc_score: 0.6641772919612092\n",
      "Training:- after 440 epochs, loss: 0.07616733014583588, auc_score: 0.6684339942374842\n",
      "Test:- after 440 epochs, loss: 0.07758451253175735, auc_score: 0.6697658673759315\n",
      "Training:- after 441 epochs, loss: 0.07578001916408539, auc_score: 0.6724884026652582\n",
      "Test:- after 441 epochs, loss: 0.0775085836648941, auc_score: 0.6705182520053767\n",
      "Training:- after 442 epochs, loss: 0.07613091915845871, auc_score: 0.6692156989961098\n",
      "Test:- after 442 epochs, loss: 0.07671910524368286, auc_score: 0.6644423678801511\n",
      "Training:- after 443 epochs, loss: 0.07728700339794159, auc_score: 0.6679714692923243\n",
      "Test:- after 443 epochs, loss: 0.07700146734714508, auc_score: 0.6726968632688106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 444 epochs, loss: 0.07579950243234634, auc_score: 0.6672751773965301\n",
      "Test:- after 444 epochs, loss: 0.077422596514225, auc_score: 0.6666273860283283\n",
      "Training:- after 445 epochs, loss: 0.07570653408765793, auc_score: 0.6704402713224467\n",
      "Test:- after 445 epochs, loss: 0.07777953892946243, auc_score: 0.6679941570205903\n",
      "Training:- after 446 epochs, loss: 0.07550624758005142, auc_score: 0.6722170446002345\n",
      "Test:- after 446 epochs, loss: 0.0772705078125, auc_score: 0.6700655951843604\n",
      "Training:- after 447 epochs, loss: 0.0767359510064125, auc_score: 0.6719135494107978\n",
      "Test:- after 447 epochs, loss: 0.07767263799905777, auc_score: 0.6700476490680952\n",
      "Training:- after 448 epochs, loss: 0.07701226323843002, auc_score: 0.6714567809163818\n",
      "Test:- after 448 epochs, loss: 0.07706533372402191, auc_score: 0.6728755224051339\n",
      "Training:- after 449 epochs, loss: 0.07588144391775131, auc_score: 0.6687585410723245\n",
      "Test:- after 449 epochs, loss: 0.0769466757774353, auc_score: 0.6697291762257014\n",
      "Training:- after 450 epochs, loss: 0.07576780766248703, auc_score: 0.6725874532733609\n",
      "Test:- after 450 epochs, loss: 0.0776146873831749, auc_score: 0.6722708567257679\n",
      "Training:- after 451 epochs, loss: 0.0754048153758049, auc_score: 0.6717475403011288\n",
      "Test:- after 451 epochs, loss: 0.07685896754264832, auc_score: 0.6715784935085605\n",
      "Training:- after 452 epochs, loss: 0.07534942775964737, auc_score: 0.6707899752351713\n",
      "Test:- after 452 epochs, loss: 0.07782871276140213, auc_score: 0.669979352484976\n",
      "Training:- after 453 epochs, loss: 0.07561484724283218, auc_score: 0.6698348581523064\n",
      "Test:- after 453 epochs, loss: 0.0768565833568573, auc_score: 0.6702948192829512\n",
      "Training:- after 454 epochs, loss: 0.07629644125699997, auc_score: 0.6739275706589092\n",
      "Test:- after 454 epochs, loss: 0.07699789106845856, auc_score: 0.6686720278085532\n",
      "Training:- after 455 epochs, loss: 0.07556542009115219, auc_score: 0.6709880700202514\n",
      "Test:- after 455 epochs, loss: 0.07677719742059708, auc_score: 0.6667872503926199\n",
      "Training:- after 456 epochs, loss: 0.0752473846077919, auc_score: 0.670115285390162\n",
      "Test:- after 456 epochs, loss: 0.0765693187713623, auc_score: 0.6722280571191961\n",
      "Training:- after 457 epochs, loss: 0.07547250390052795, auc_score: 0.6696541463030238\n",
      "Test:- after 457 epochs, loss: 0.07769731432199478, auc_score: 0.6719688471835198\n",
      "Training:- after 458 epochs, loss: 0.07557578384876251, auc_score: 0.6692283043973675\n",
      "Test:- after 458 epochs, loss: 0.0785435363650322, auc_score: 0.6704549727497566\n",
      "Training:- after 459 epochs, loss: 0.07549125701189041, auc_score: 0.6719106613408572\n",
      "Test:- after 459 epochs, loss: 0.07698234170675278, auc_score: 0.6691221137932364\n",
      "Training:- after 460 epochs, loss: 0.07638265937566757, auc_score: 0.672295056919886\n",
      "Test:- after 460 epochs, loss: 0.07699955254793167, auc_score: 0.6689287788185468\n",
      "Training:- after 461 epochs, loss: 0.07542061060667038, auc_score: 0.6727850880845749\n",
      "Test:- after 461 epochs, loss: 0.07687001675367355, auc_score: 0.6652167864732353\n",
      "Training:- after 462 epochs, loss: 0.07569897919893265, auc_score: 0.6728498621802438\n",
      "Test:- after 462 epochs, loss: 0.07904857397079468, auc_score: 0.6748906446426506\n",
      "Training:- after 463 epochs, loss: 0.07499052584171295, auc_score: 0.6737035955417046\n",
      "Test:- after 463 epochs, loss: 0.07652094215154648, auc_score: 0.6684755935305696\n",
      "Training:- after 464 epochs, loss: 0.07532192021608353, auc_score: 0.6741856778355805\n",
      "Test:- after 464 epochs, loss: 0.07669395953416824, auc_score: 0.6755878479954938\n",
      "Training:- after 465 epochs, loss: 0.07529564946889877, auc_score: 0.6744275413750277\n",
      "Test:- after 465 epochs, loss: 0.07794062048196793, auc_score: 0.6698374342369496\n",
      "Training:- after 466 epochs, loss: 0.0751538798213005, auc_score: 0.6739389020047841\n",
      "Test:- after 466 epochs, loss: 0.0767538994550705, auc_score: 0.668987127788285\n",
      "Training:- after 467 epochs, loss: 0.07533837854862213, auc_score: 0.6739597070907396\n",
      "Test:- after 467 epochs, loss: 0.07711688429117203, auc_score: 0.670915043651371\n",
      "Training:- after 468 epochs, loss: 0.07513903081417084, auc_score: 0.6730389763441397\n",
      "Test:- after 468 epochs, loss: 0.07671356201171875, auc_score: 0.6718685441543472\n",
      "Training:- after 469 epochs, loss: 0.07537686079740524, auc_score: 0.6736684244102779\n",
      "Test:- after 469 epochs, loss: 0.07669196277856827, auc_score: 0.6647007229428024\n",
      "Training:- after 470 epochs, loss: 0.07496646791696548, auc_score: 0.672538337879339\n",
      "Test:- after 470 epochs, loss: 0.07690735906362534, auc_score: 0.6705317900854625\n",
      "Training:- after 471 epochs, loss: 0.07496248185634613, auc_score: 0.6743047404234843\n",
      "Test:- after 471 epochs, loss: 0.07723526656627655, auc_score: 0.6746634629134322\n",
      "Training:- after 472 epochs, loss: 0.07545601576566696, auc_score: 0.6780622155862683\n",
      "Test:- after 472 epochs, loss: 0.07643536478281021, auc_score: 0.6821567855779501\n",
      "Training:- after 473 epochs, loss: 0.07517222315073013, auc_score: 0.6751290976910137\n",
      "Test:- after 473 epochs, loss: 0.07689610123634338, auc_score: 0.6714676770954958\n",
      "Training:- after 474 epochs, loss: 0.0758817121386528, auc_score: 0.6787845833203948\n",
      "Test:- after 474 epochs, loss: 0.07690731436014175, auc_score: 0.6738342267533601\n",
      "Training:- after 475 epochs, loss: 0.07485375553369522, auc_score: 0.675958602233315\n",
      "Test:- after 475 epochs, loss: 0.07749178260564804, auc_score: 0.6715340618716683\n",
      "Training:- after 476 epochs, loss: 0.07519727200269699, auc_score: 0.6755321655969834\n",
      "Test:- after 476 epochs, loss: 0.07649560272693634, auc_score: 0.6696451934997321\n",
      "Training:- after 477 epochs, loss: 0.07600764185190201, auc_score: 0.67703119687906\n",
      "Test:- after 477 epochs, loss: 0.07665501534938812, auc_score: 0.6690661740111139\n",
      "Training:- after 478 epochs, loss: 0.07516451925039291, auc_score: 0.6765368437013799\n",
      "Test:- after 478 epochs, loss: 0.07834947854280472, auc_score: 0.668003137850296\n",
      "Training:- after 479 epochs, loss: 0.07485225051641464, auc_score: 0.6729651363406717\n",
      "Test:- after 479 epochs, loss: 0.07656732201576233, auc_score: 0.6684034919853322\n",
      "Training:- after 480 epochs, loss: 0.0749414786696434, auc_score: 0.6739700162834608\n",
      "Test:- after 480 epochs, loss: 0.07741831988096237, auc_score: 0.6734199273078152\n",
      "Training:- after 481 epochs, loss: 0.07509065419435501, auc_score: 0.6749744881960876\n",
      "Test:- after 481 epochs, loss: 0.07665032148361206, auc_score: 0.6753055285104816\n",
      "Training:- after 482 epochs, loss: 0.07475513964891434, auc_score: 0.6737580200769737\n",
      "Test:- after 482 epochs, loss: 0.07905768603086472, auc_score: 0.665276618259093\n",
      "Training:- after 483 epochs, loss: 0.0749048963189125, auc_score: 0.6763960156131693\n",
      "Test:- after 483 epochs, loss: 0.07573004066944122, auc_score: 0.6760788248884313\n",
      "Training:- after 484 epochs, loss: 0.07487629354000092, auc_score: 0.6781342326130781\n",
      "Test:- after 484 epochs, loss: 0.07679902017116547, auc_score: 0.6747249267296102\n",
      "Training:- after 485 epochs, loss: 0.07461296766996384, auc_score: 0.6787715339736138\n",
      "Test:- after 485 epochs, loss: 0.07717087119817734, auc_score: 0.6766381107990048\n",
      "Training:- after 486 epochs, loss: 0.07521864026784897, auc_score: 0.6787163001059666\n",
      "Test:- after 486 epochs, loss: 0.07582216709852219, auc_score: 0.6820293566505391\n",
      "Training:- after 487 epochs, loss: 0.07834848016500473, auc_score: 0.6787668170895321\n",
      "Test:- after 487 epochs, loss: 0.07658778131008148, auc_score: 0.6757625653900149\n",
      "Training:- after 488 epochs, loss: 0.07509221136569977, auc_score: 0.6791302140552055\n",
      "Test:- after 488 epochs, loss: 0.07705231010913849, auc_score: 0.6800647216595604\n",
      "Training:- after 489 epochs, loss: 0.07465298473834991, auc_score: 0.6785450398341177\n",
      "Test:- after 489 epochs, loss: 0.07636813819408417, auc_score: 0.680604339273302\n",
      "Training:- after 490 epochs, loss: 0.07474219799041748, auc_score: 0.6798346914872219\n",
      "Test:- after 490 epochs, loss: 0.07675103098154068, auc_score: 0.6795522921166407\n",
      "Training:- after 491 epochs, loss: 0.074941486120224, auc_score: 0.6797547964309174\n",
      "Test:- after 491 epochs, loss: 0.07582107931375504, auc_score: 0.6766267425420878\n",
      "Training:- after 492 epochs, loss: 0.07479249686002731, auc_score: 0.6771642581467727\n",
      "Test:- after 492 epochs, loss: 0.07625113427639008, auc_score: 0.6718484903874968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 493 epochs, loss: 0.07453890144824982, auc_score: 0.6772622969904624\n",
      "Test:- after 493 epochs, loss: 0.07637976855039597, auc_score: 0.6739922290487719\n",
      "Training:- after 494 epochs, loss: 0.07461044192314148, auc_score: 0.6752598996549548\n",
      "Test:- after 494 epochs, loss: 0.07609038800001144, auc_score: 0.6751091688395985\n",
      "Training:- after 495 epochs, loss: 0.07478809356689453, auc_score: 0.6753344262057788\n",
      "Test:- after 495 epochs, loss: 0.07777148485183716, auc_score: 0.6750969581441733\n",
      "Training:- after 496 epochs, loss: 0.0746728852391243, auc_score: 0.6785649243786984\n",
      "Test:- after 496 epochs, loss: 0.0760960504412651, auc_score: 0.6756194316679784\n",
      "Training:- after 497 epochs, loss: 0.07465435564517975, auc_score: 0.6776490745593446\n",
      "Test:- after 497 epochs, loss: 0.07578849792480469, auc_score: 0.6735833976819574\n",
      "Training:- after 498 epochs, loss: 0.07460049539804459, auc_score: 0.6782188592955823\n",
      "Test:- after 498 epochs, loss: 0.07696156203746796, auc_score: 0.6737691382755563\n",
      "Training:- after 499 epochs, loss: 0.07453060150146484, auc_score: 0.6808124401945546\n",
      "Test:- after 499 epochs, loss: 0.07561662048101425, auc_score: 0.6780032715213506\n",
      "Training:- after 500 epochs, loss: 0.0746535137295723, auc_score: 0.6797902912952953\n",
      "Test:- after 500 epochs, loss: 0.07591480761766434, auc_score: 0.6804544909122334\n",
      "Training:- after 501 epochs, loss: 0.07486847043037415, auc_score: 0.6818692250566791\n",
      "Test:- after 501 epochs, loss: 0.07621197402477264, auc_score: 0.6829206192886711\n",
      "Training:- after 502 epochs, loss: 0.07705789059400558, auc_score: 0.6801875426937052\n",
      "Test:- after 502 epochs, loss: 0.07617808133363724, auc_score: 0.6820047705023421\n",
      "Training:- after 503 epochs, loss: 0.07498602569103241, auc_score: 0.6809597230547713\n",
      "Test:- after 503 epochs, loss: 0.07629894465208054, auc_score: 0.6752353760757411\n",
      "Training:- after 504 epochs, loss: 0.0750197321176529, auc_score: 0.6805691442951028\n",
      "Test:- after 504 epochs, loss: 0.07581031322479248, auc_score: 0.6752362744695746\n",
      "Training:- after 505 epochs, loss: 0.07434379309415817, auc_score: 0.6790902035514959\n",
      "Test:- after 505 epochs, loss: 0.07564010471105576, auc_score: 0.6770207333131895\n",
      "Training:- after 506 epochs, loss: 0.07446897029876709, auc_score: 0.6789889929757716\n",
      "Test:- after 506 epochs, loss: 0.07556861639022827, auc_score: 0.6714609904341262\n",
      "Training:- after 507 epochs, loss: 0.07486161589622498, auc_score: 0.67958466724559\n",
      "Test:- after 507 epochs, loss: 0.07592802494764328, auc_score: 0.6719538977857855\n",
      "Training:- after 508 epochs, loss: 0.0745035782456398, auc_score: 0.6784346602547094\n",
      "Test:- after 508 epochs, loss: 0.07592906057834625, auc_score: 0.6720290084840708\n",
      "Training:- after 509 epochs, loss: 0.07456432282924652, auc_score: 0.6787213011468443\n",
      "Test:- after 509 epochs, loss: 0.07738353312015533, auc_score: 0.6767282517193828\n",
      "Training:- after 510 epochs, loss: 0.07444974780082703, auc_score: 0.6782845686747438\n",
      "Test:- after 510 epochs, loss: 0.07592962682247162, auc_score: 0.6764053708408095\n",
      "Training:- after 511 epochs, loss: 0.07496389746665955, auc_score: 0.6780586436403624\n",
      "Test:- after 511 epochs, loss: 0.0766238272190094, auc_score: 0.6718218680871859\n",
      "Training:- after 512 epochs, loss: 0.07501804083585739, auc_score: 0.6818774297873368\n",
      "Test:- after 512 epochs, loss: 0.0757828801870346, auc_score: 0.6807172104902557\n",
      "Training:- after 513 epochs, loss: 0.07454926520586014, auc_score: 0.6844613681539256\n",
      "Test:- after 513 epochs, loss: 0.07562420517206192, auc_score: 0.6789705121653095\n",
      "Training:- after 514 epochs, loss: 0.07427381724119186, auc_score: 0.6849553163685955\n",
      "Test:- after 514 epochs, loss: 0.0761416107416153, auc_score: 0.6808463553809749\n",
      "Training:- after 515 epochs, loss: 0.07436425238847733, auc_score: 0.683625985068441\n",
      "Test:- after 515 epochs, loss: 0.07543560862541199, auc_score: 0.679407644492193\n",
      "Training:- after 516 epochs, loss: 0.07524413615465164, auc_score: 0.6834626090593313\n",
      "Test:- after 516 epochs, loss: 0.07567042857408524, auc_score: 0.6837051626869995\n",
      "Training:- after 517 epochs, loss: 0.07413562387228012, auc_score: 0.6797291951106885\n",
      "Test:- after 517 epochs, loss: 0.07585933804512024, auc_score: 0.6797758491842335\n",
      "Training:- after 518 epochs, loss: 0.07417917251586914, auc_score: 0.681961581555976\n",
      "Test:- after 518 epochs, loss: 0.07575757801532745, auc_score: 0.6804869854130684\n",
      "Training:- after 519 epochs, loss: 0.0742713212966919, auc_score: 0.6779458397246144\n",
      "Test:- after 519 epochs, loss: 0.07559195160865784, auc_score: 0.674190898431137\n",
      "Training:- after 520 epochs, loss: 0.07409272342920303, auc_score: 0.6798907544753249\n",
      "Test:- after 520 epochs, loss: 0.07527609914541245, auc_score: 0.6739477072616334\n",
      "Training:- after 521 epochs, loss: 0.07432390004396439, auc_score: 0.6801115530124159\n",
      "Test:- after 521 epochs, loss: 0.07577896118164062, auc_score: 0.6753252620885263\n",
      "Training:- after 522 epochs, loss: 0.07431569695472717, auc_score: 0.6816600268843791\n",
      "Test:- after 522 epochs, loss: 0.0756649374961853, auc_score: 0.6821783283781784\n",
      "Training:- after 523 epochs, loss: 0.07423099875450134, auc_score: 0.6831192537555756\n",
      "Test:- after 523 epochs, loss: 0.07586421817541122, auc_score: 0.6820618760204076\n",
      "Training:- after 524 epochs, loss: 0.07403995096683502, auc_score: 0.6835803648425837\n",
      "Test:- after 524 epochs, loss: 0.07601601630449295, auc_score: 0.6787002199666009\n",
      "Training:- after 525 epochs, loss: 0.07417098432779312, auc_score: 0.6835326429249937\n",
      "Test:- after 525 epochs, loss: 0.07547150552272797, auc_score: 0.6797077608792695\n",
      "Training:- after 526 epochs, loss: 0.07403194159269333, auc_score: 0.6846053733169516\n",
      "Test:- after 526 epochs, loss: 0.07551752775907516, auc_score: 0.6766883058343997\n",
      "Training:- after 527 epochs, loss: 0.0740310475230217, auc_score: 0.6811365158752649\n",
      "Test:- after 527 epochs, loss: 0.07540503144264221, auc_score: 0.6767391350301475\n",
      "Training:- after 528 epochs, loss: 0.07400853931903839, auc_score: 0.6829609950423\n",
      "Test:- after 528 epochs, loss: 0.07541750371456146, auc_score: 0.68060324503583\n",
      "Training:- after 529 epochs, loss: 0.0739194005727768, auc_score: 0.6834133771135319\n",
      "Test:- after 529 epochs, loss: 0.0750809833407402, auc_score: 0.6806475958483635\n",
      "Training:- after 530 epochs, loss: 0.07402366399765015, auc_score: 0.682735807113813\n",
      "Test:- after 530 epochs, loss: 0.07588258385658264, auc_score: 0.6738878599326298\n",
      "Training:- after 531 epochs, loss: 0.07437197864055634, auc_score: 0.6829532890701407\n",
      "Test:- after 531 epochs, loss: 0.07520800083875656, auc_score: 0.6804127016101456\n",
      "Training:- after 532 epochs, loss: 0.07386539876461029, auc_score: 0.6815724821529967\n",
      "Test:- after 532 epochs, loss: 0.07563000917434692, auc_score: 0.6851126815905737\n",
      "Training:- after 533 epochs, loss: 0.07385104149580002, auc_score: 0.6862232722743667\n",
      "Test:- after 533 epochs, loss: 0.07518983632326126, auc_score: 0.6827524673189814\n",
      "Training:- after 534 epochs, loss: 0.07376321405172348, auc_score: 0.687248843620605\n",
      "Test:- after 534 epochs, loss: 0.07612092792987823, auc_score: 0.6802073238060066\n",
      "Training:- after 535 epochs, loss: 0.0738423764705658, auc_score: 0.6874546342859247\n",
      "Test:- after 535 epochs, loss: 0.07537029683589935, auc_score: 0.6865041350985372\n",
      "Training:- after 536 epochs, loss: 0.07394661009311676, auc_score: 0.6862865764126836\n",
      "Test:- after 536 epochs, loss: 0.07548335939645767, auc_score: 0.6812538127336912\n",
      "Training:- after 537 epochs, loss: 0.07387770712375641, auc_score: 0.6858826270467928\n",
      "Test:- after 537 epochs, loss: 0.07529423385858536, auc_score: 0.6854707552601115\n",
      "Training:- after 538 epochs, loss: 0.07392420619726181, auc_score: 0.6859826971366587\n",
      "Test:- after 538 epochs, loss: 0.07839206606149673, auc_score: 0.6810254901375631\n",
      "Training:- after 539 epochs, loss: 0.07390999048948288, auc_score: 0.684732227559391\n",
      "Test:- after 539 epochs, loss: 0.07567820698022842, auc_score: 0.6833618363542991\n",
      "Training:- after 540 epochs, loss: 0.07376009225845337, auc_score: 0.6832999116823463\n",
      "Test:- after 540 epochs, loss: 0.07560521364212036, auc_score: 0.6855410911039737\n",
      "Training:- after 541 epochs, loss: 0.07385274022817612, auc_score: 0.6837448316694767\n",
      "Test:- after 541 epochs, loss: 0.07527525722980499, auc_score: 0.6774651242892119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 542 epochs, loss: 0.07378853112459183, auc_score: 0.6815958977811031\n",
      "Test:- after 542 epochs, loss: 0.07540738582611084, auc_score: 0.6851597959744495\n",
      "Training:- after 543 epochs, loss: 0.0739305317401886, auc_score: 0.6817644569803456\n",
      "Test:- after 543 epochs, loss: 0.07619242370128632, auc_score: 0.6862345858622032\n",
      "Training:- after 544 epochs, loss: 0.07361745089292526, auc_score: 0.6822646083616136\n",
      "Test:- after 544 epochs, loss: 0.07512577623128891, auc_score: 0.6817594716822534\n",
      "Training:- after 545 epochs, loss: 0.07374637573957443, auc_score: 0.6859942713811874\n",
      "Test:- after 545 epochs, loss: 0.07597773522138596, auc_score: 0.6834568547138631\n",
      "Training:- after 546 epochs, loss: 0.07405301183462143, auc_score: 0.6851965196788303\n",
      "Test:- after 546 epochs, loss: 0.07548359781503677, auc_score: 0.6803540106911975\n",
      "Training:- after 547 epochs, loss: 0.07376378774642944, auc_score: 0.6850261249374999\n",
      "Test:- after 547 epochs, loss: 0.07484999299049377, auc_score: 0.6861357656491501\n",
      "Training:- after 548 epochs, loss: 0.0736231729388237, auc_score: 0.684569749434307\n",
      "Test:- after 548 epochs, loss: 0.0749112069606781, auc_score: 0.6833413411621051\n",
      "Training:- after 549 epochs, loss: 0.07368853688240051, auc_score: 0.6850556527070468\n",
      "Test:- after 549 epochs, loss: 0.07503658533096313, auc_score: 0.6805801199433483\n",
      "Training:- after 550 epochs, loss: 0.07369901239871979, auc_score: 0.6874176872734645\n",
      "Test:- after 550 epochs, loss: 0.07548334449529648, auc_score: 0.6852678332730259\n",
      "Training:- after 551 epochs, loss: 0.0738891139626503, auc_score: 0.687457794046172\n",
      "Test:- after 551 epochs, loss: 0.0768246129155159, auc_score: 0.6931156515748936\n",
      "Training:- after 552 epochs, loss: 0.07378517836332321, auc_score: 0.6861617679606574\n",
      "Test:- after 552 epochs, loss: 0.07600362598896027, auc_score: 0.6795138912203608\n",
      "Training:- after 553 epochs, loss: 0.07362398505210876, auc_score: 0.686787061519882\n",
      "Test:- after 553 epochs, loss: 0.0753159150481224, auc_score: 0.6816078389680346\n",
      "Training:- after 554 epochs, loss: 0.07425855845212936, auc_score: 0.6869806259235126\n",
      "Test:- after 554 epochs, loss: 0.07489468902349472, auc_score: 0.6842490671003827\n",
      "Training:- after 555 epochs, loss: 0.07352475076913834, auc_score: 0.6852460057035473\n",
      "Test:- after 555 epochs, loss: 0.07531621307134628, auc_score: 0.6844969522999504\n",
      "Training:- after 556 epochs, loss: 0.07369376718997955, auc_score: 0.6881964528099688\n",
      "Test:- after 556 epochs, loss: 0.07516492158174515, auc_score: 0.6846843529015323\n",
      "Training:- after 557 epochs, loss: 0.07389695942401886, auc_score: 0.6881796189933271\n",
      "Test:- after 557 epochs, loss: 0.075164794921875, auc_score: 0.6839895804967092\n",
      "Training:- after 558 epochs, loss: 0.07372115552425385, auc_score: 0.6836109951048797\n",
      "Test:- after 558 epochs, loss: 0.07484401762485504, auc_score: 0.68612843550154\n",
      "Training:- after 559 epochs, loss: 0.07389293611049652, auc_score: 0.6861557908728471\n",
      "Test:- after 559 epochs, loss: 0.07481296360492706, auc_score: 0.685557722270095\n",
      "Training:- after 560 epochs, loss: 0.07403535395860672, auc_score: 0.6868058552466794\n",
      "Test:- after 560 epochs, loss: 0.07496409118175507, auc_score: 0.6865764262701548\n",
      "Training:- after 561 epochs, loss: 0.07351753860712051, auc_score: 0.6884841852124695\n",
      "Test:- after 561 epochs, loss: 0.07487122714519501, auc_score: 0.682789730456981\n",
      "Training:- after 562 epochs, loss: 0.07463400065898895, auc_score: 0.6905760097191914\n",
      "Test:- after 562 epochs, loss: 0.07533439993858337, auc_score: 0.6841553792341084\n",
      "Training:- after 563 epochs, loss: 0.07352997362613678, auc_score: 0.6900698233699859\n",
      "Test:- after 563 epochs, loss: 0.07504398375749588, auc_score: 0.6833865095441134\n",
      "Training:- after 564 epochs, loss: 0.0736732929944992, auc_score: 0.6887256126226842\n",
      "Test:- after 564 epochs, loss: 0.07645475119352341, auc_score: 0.6821746974992944\n",
      "Training:- after 565 epochs, loss: 0.07368766516447067, auc_score: 0.6889118447520032\n",
      "Test:- after 565 epochs, loss: 0.07508588582277298, auc_score: 0.6828357910155642\n",
      "Training:- after 566 epochs, loss: 0.07347704470157623, auc_score: 0.6882723736287475\n",
      "Test:- after 566 epochs, loss: 0.07532531768083572, auc_score: 0.6826043411384795\n",
      "Training:- after 567 epochs, loss: 0.07339974492788315, auc_score: 0.6867823924240078\n",
      "Test:- after 567 epochs, loss: 0.07540743052959442, auc_score: 0.680284476873664\n",
      "Training:- after 568 epochs, loss: 0.07408486306667328, auc_score: 0.6870458172507999\n",
      "Test:- after 568 epochs, loss: 0.0758044496178627, auc_score: 0.6812846410092849\n",
      "Training:- after 569 epochs, loss: 0.07362917810678482, auc_score: 0.6900531661619379\n",
      "Test:- after 569 epochs, loss: 0.07487652450799942, auc_score: 0.6844289665797494\n",
      "Training:- after 570 epochs, loss: 0.0734051838517189, auc_score: 0.6858194862590575\n",
      "Test:- after 570 epochs, loss: 0.07492922991514206, auc_score: 0.6856631110166088\n",
      "Training:- after 571 epochs, loss: 0.07337547093629837, auc_score: 0.687827324029708\n",
      "Test:- after 571 epochs, loss: 0.07517518848180771, auc_score: 0.683368457734456\n",
      "Training:- after 572 epochs, loss: 0.07356864959001541, auc_score: 0.6885426934133341\n",
      "Test:- after 572 epochs, loss: 0.07521045207977295, auc_score: 0.6872360618393385\n",
      "Training:- after 573 epochs, loss: 0.0733027458190918, auc_score: 0.6895413434756201\n",
      "Test:- after 573 epochs, loss: 0.07538240402936935, auc_score: 0.684341558144422\n",
      "Training:- after 574 epochs, loss: 0.07376501709222794, auc_score: 0.6913987601948115\n",
      "Test:- after 574 epochs, loss: 0.07591260969638824, auc_score: 0.687633730118762\n",
      "Training:- after 575 epochs, loss: 0.07404063642024994, auc_score: 0.688102066944363\n",
      "Test:- after 575 epochs, loss: 0.07527221739292145, auc_score: 0.6847049755475229\n",
      "Training:- after 576 epochs, loss: 0.07337447255849838, auc_score: 0.6885752218469836\n",
      "Test:- after 576 epochs, loss: 0.07476720213890076, auc_score: 0.6871227523056702\n",
      "Training:- after 577 epochs, loss: 0.07333000004291534, auc_score: 0.6878901562223718\n",
      "Test:- after 577 epochs, loss: 0.07507266104221344, auc_score: 0.6856004255091623\n",
      "Training:- after 578 epochs, loss: 0.07334679365158081, auc_score: 0.6872270937528795\n",
      "Test:- after 578 epochs, loss: 0.07535679638385773, auc_score: 0.6873119434776608\n",
      "Training:- after 579 epochs, loss: 0.07321111857891083, auc_score: 0.687126222542688\n",
      "Test:- after 579 epochs, loss: 0.07476379722356796, auc_score: 0.6872453037938954\n",
      "Training:- after 580 epochs, loss: 0.07334782183170319, auc_score: 0.6882859832749485\n",
      "Test:- after 580 epochs, loss: 0.07499229907989502, auc_score: 0.6834944038457473\n",
      "Training:- after 581 epochs, loss: 0.07374076545238495, auc_score: 0.6876225010013881\n",
      "Test:- after 581 epochs, loss: 0.07511817663908005, auc_score: 0.6887087158501541\n",
      "Training:- after 582 epochs, loss: 0.07350052148103714, auc_score: 0.6887549543843006\n",
      "Test:- after 582 epochs, loss: 0.07496462017297745, auc_score: 0.6861133244550884\n",
      "Training:- after 583 epochs, loss: 0.07329444587230682, auc_score: 0.6868235405443043\n",
      "Test:- after 583 epochs, loss: 0.07468929886817932, auc_score: 0.6847478777388578\n",
      "Training:- after 584 epochs, loss: 0.07322795689105988, auc_score: 0.690943607199059\n",
      "Test:- after 584 epochs, loss: 0.07458044588565826, auc_score: 0.6869702678270557\n",
      "Training:- after 585 epochs, loss: 0.07324544340372086, auc_score: 0.6925818886680302\n",
      "Test:- after 585 epochs, loss: 0.0748869851231575, auc_score: 0.6944262869413949\n",
      "Training:- after 586 epochs, loss: 0.07313977926969528, auc_score: 0.6924086333621875\n",
      "Test:- after 586 epochs, loss: 0.07513841241598129, auc_score: 0.6906600987549318\n",
      "Training:- after 587 epochs, loss: 0.0733155608177185, auc_score: 0.6930269781400462\n",
      "Test:- after 587 epochs, loss: 0.07489797472953796, auc_score: 0.6953806640778003\n",
      "Training:- after 588 epochs, loss: 0.07322487235069275, auc_score: 0.6906006050135499\n",
      "Test:- after 588 epochs, loss: 0.07469113171100616, auc_score: 0.6900445155698801\n",
      "Training:- after 589 epochs, loss: 0.07350704073905945, auc_score: 0.6931376805619422\n",
      "Test:- after 589 epochs, loss: 0.07473906874656677, auc_score: 0.6823113497294871\n",
      "Training:- after 590 epochs, loss: 0.07314346730709076, auc_score: 0.6897954798776794\n",
      "Test:- after 590 epochs, loss: 0.07476913928985596, auc_score: 0.686832707877142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 591 epochs, loss: 0.07323615998029709, auc_score: 0.6902615525283502\n",
      "Test:- after 591 epochs, loss: 0.07451394200325012, auc_score: 0.6932750714052124\n",
      "Training:- after 592 epochs, loss: 0.0734214186668396, auc_score: 0.691057186609572\n",
      "Test:- after 592 epochs, loss: 0.07459930330514908, auc_score: 0.6878799366585718\n",
      "Training:- after 593 epochs, loss: 0.07319696992635727, auc_score: 0.6890390793212959\n",
      "Test:- after 593 epochs, loss: 0.07468564063310623, auc_score: 0.6844787947969008\n",
      "Training:- after 594 epochs, loss: 0.07304184883832932, auc_score: 0.6905784864939369\n",
      "Test:- after 594 epochs, loss: 0.07555746287107468, auc_score: 0.6912851850193917\n",
      "Training:- after 595 epochs, loss: 0.07319098711013794, auc_score: 0.6893192487204991\n",
      "Test:- after 595 epochs, loss: 0.074934221804142, auc_score: 0.6871817230012447\n",
      "Training:- after 596 epochs, loss: 0.0730520710349083, auc_score: 0.6931134033609329\n",
      "Test:- after 596 epochs, loss: 0.07491352409124374, auc_score: 0.6853115530338355\n",
      "Training:- after 597 epochs, loss: 0.07311940938234329, auc_score: 0.6912497456799152\n",
      "Test:- after 597 epochs, loss: 0.07532057166099548, auc_score: 0.6872768346196841\n",
      "Training:- after 598 epochs, loss: 0.07343471050262451, auc_score: 0.6918093383688517\n",
      "Test:- after 598 epochs, loss: 0.07462417334318161, auc_score: 0.6852642272631753\n",
      "Training:- after 599 epochs, loss: 0.0731319710612297, auc_score: 0.6892297076688977\n",
      "Test:- after 599 epochs, loss: 0.07486215233802795, auc_score: 0.6916999010212468\n",
      "Training:- after 600 epochs, loss: 0.07316959649324417, auc_score: 0.6881522523786864\n",
      "Test:- after 600 epochs, loss: 0.07429514080286026, auc_score: 0.6919201536160197\n",
      "Training:- after 601 epochs, loss: 0.07360873371362686, auc_score: 0.6905459602369759\n",
      "Test:- after 601 epochs, loss: 0.07488943636417389, auc_score: 0.6880842077907221\n",
      "Training:- after 602 epochs, loss: 0.07289581745862961, auc_score: 0.6917924853577747\n",
      "Test:- after 602 epochs, loss: 0.07451453804969788, auc_score: 0.693269553588415\n",
      "Training:- after 603 epochs, loss: 0.07339592278003693, auc_score: 0.6900584604621272\n",
      "Test:- after 603 epochs, loss: 0.07448277622461319, auc_score: 0.6880675766246007\n",
      "Training:- after 604 epochs, loss: 0.07318666577339172, auc_score: 0.6927898020004449\n",
      "Test:- after 604 epochs, loss: 0.07459279894828796, auc_score: 0.6893773384663018\n",
      "Training:- after 605 epochs, loss: 0.07311158627271652, auc_score: 0.6914529423261289\n",
      "Test:- after 605 epochs, loss: 0.07446849346160889, auc_score: 0.6942451626621305\n",
      "Training:- after 606 epochs, loss: 0.07314706593751907, auc_score: 0.6919201595192137\n",
      "Test:- after 606 epochs, loss: 0.07469186186790466, auc_score: 0.6867750863266323\n",
      "Training:- after 607 epochs, loss: 0.07400879263877869, auc_score: 0.6929492261325569\n",
      "Test:- after 607 epochs, loss: 0.07479774951934814, auc_score: 0.691667030376281\n",
      "Training:- after 608 epochs, loss: 0.07347415387630463, auc_score: 0.6925193949504358\n",
      "Test:- after 608 epochs, loss: 0.07461204379796982, auc_score: 0.6989393357232474\n",
      "Training:- after 609 epochs, loss: 0.07289490103721619, auc_score: 0.6929734996727719\n",
      "Test:- after 609 epochs, loss: 0.07470985502004623, auc_score: 0.6931252230441438\n",
      "Training:- after 610 epochs, loss: 0.07294341921806335, auc_score: 0.6930833604087829\n",
      "Test:- after 610 epochs, loss: 0.07450420409440994, auc_score: 0.6945864746031214\n",
      "Training:- after 611 epochs, loss: 0.0736318975687027, auc_score: 0.693216548122312\n",
      "Test:- after 611 epochs, loss: 0.07432462275028229, auc_score: 0.691636882890478\n",
      "Training:- after 612 epochs, loss: 0.07278452813625336, auc_score: 0.6938843008609213\n",
      "Test:- after 612 epochs, loss: 0.07446237653493881, auc_score: 0.6916957696530645\n",
      "Training:- after 613 epochs, loss: 0.07322675734758377, auc_score: 0.6946399498661137\n",
      "Test:- after 613 epochs, loss: 0.0745859369635582, auc_score: 0.683983826424094\n",
      "Training:- after 614 epochs, loss: 0.07325689494609833, auc_score: 0.6935413306331579\n",
      "Test:- after 614 epochs, loss: 0.07507754862308502, auc_score: 0.6887696822856632\n",
      "Training:- after 615 epochs, loss: 0.07311106473207474, auc_score: 0.6934984168226878\n",
      "Test:- after 615 epochs, loss: 0.07476896792650223, auc_score: 0.6888820405788019\n",
      "Training:- after 616 epochs, loss: 0.07285219430923462, auc_score: 0.6904481397547235\n",
      "Test:- after 616 epochs, loss: 0.0741828978061676, auc_score: 0.6931546990660434\n",
      "Training:- after 617 epochs, loss: 0.07305595278739929, auc_score: 0.693503982318482\n",
      "Test:- after 617 epochs, loss: 0.07444426417350769, auc_score: 0.6937230808256022\n",
      "Training:- after 618 epochs, loss: 0.07300829142332077, auc_score: 0.6916963954418579\n",
      "Test:- after 618 epochs, loss: 0.07509154081344604, auc_score: 0.6872083577360724\n",
      "Training:- after 619 epochs, loss: 0.07312696427106857, auc_score: 0.6937114403272288\n",
      "Test:- after 619 epochs, loss: 0.07408326119184494, auc_score: 0.69262895215571\n",
      "Training:- after 620 epochs, loss: 0.0729239284992218, auc_score: 0.6913356699656146\n",
      "Test:- after 620 epochs, loss: 0.07441934943199158, auc_score: 0.6880526054664623\n",
      "Training:- after 621 epochs, loss: 0.07283537089824677, auc_score: 0.6925549336454059\n",
      "Test:- after 621 epochs, loss: 0.07428108155727386, auc_score: 0.6925542828827685\n",
      "Training:- after 622 epochs, loss: 0.07283101975917816, auc_score: 0.6966969334054853\n",
      "Test:- after 622 epochs, loss: 0.07459366321563721, auc_score: 0.6910003133498215\n",
      "Training:- after 623 epochs, loss: 0.07307127863168716, auc_score: 0.6952614657823647\n",
      "Test:- after 623 epochs, loss: 0.07465553283691406, auc_score: 0.6931096425946857\n",
      "Training:- after 624 epochs, loss: 0.07303178310394287, auc_score: 0.6956466674287385\n",
      "Test:- after 624 epochs, loss: 0.07446245104074478, auc_score: 0.6903311187459042\n",
      "Training:- after 625 epochs, loss: 0.07325176894664764, auc_score: 0.6940660357538211\n",
      "Test:- after 625 epochs, loss: 0.07394898682832718, auc_score: 0.689756715571621\n",
      "Training:- after 626 epochs, loss: 0.07285428792238235, auc_score: 0.6962729402009883\n",
      "Test:- after 626 epochs, loss: 0.07437355071306229, auc_score: 0.6914888997069185\n",
      "Training:- after 627 epochs, loss: 0.07268861681222916, auc_score: 0.6927904931979992\n",
      "Test:- after 627 epochs, loss: 0.0743652880191803, auc_score: 0.6861312674627245\n",
      "Training:- after 628 epochs, loss: 0.07291249930858612, auc_score: 0.6939964815511621\n",
      "Test:- after 628 epochs, loss: 0.07421506941318512, auc_score: 0.687902334331825\n",
      "Training:- after 629 epochs, loss: 0.07304475456476212, auc_score: 0.693006043244301\n",
      "Test:- after 629 epochs, loss: 0.07470948994159698, auc_score: 0.6875873555886313\n",
      "Training:- after 630 epochs, loss: 0.07289482653141022, auc_score: 0.6928389598398934\n",
      "Test:- after 630 epochs, loss: 0.07492334395647049, auc_score: 0.6891813704826956\n",
      "Training:- after 631 epochs, loss: 0.07283665239810944, auc_score: 0.6937343703559083\n",
      "Test:- after 631 epochs, loss: 0.07431543618440628, auc_score: 0.6890406086447247\n",
      "Training:- after 632 epochs, loss: 0.07274242490530014, auc_score: 0.6951186873812156\n",
      "Test:- after 632 epochs, loss: 0.07458564639091492, auc_score: 0.6950048245924898\n",
      "Training:- after 633 epochs, loss: 0.07266943156719208, auc_score: 0.6965093601392001\n",
      "Test:- after 633 epochs, loss: 0.07450848817825317, auc_score: 0.6915429401166109\n",
      "Training:- after 634 epochs, loss: 0.07275886833667755, auc_score: 0.6972773523536204\n",
      "Test:- after 634 epochs, loss: 0.07453516125679016, auc_score: 0.6912163413175365\n",
      "Training:- after 635 epochs, loss: 0.07283265143632889, auc_score: 0.6970032186149375\n",
      "Test:- after 635 epochs, loss: 0.07447785139083862, auc_score: 0.6892757702250523\n",
      "Training:- after 636 epochs, loss: 0.07296182215213776, auc_score: 0.6936459781011577\n",
      "Test:- after 636 epochs, loss: 0.07457467168569565, auc_score: 0.6965792862090018\n",
      "Training:- after 637 epochs, loss: 0.07271179556846619, auc_score: 0.6938683105110919\n",
      "Test:- after 637 epochs, loss: 0.07410112023353577, auc_score: 0.6936710112868109\n",
      "Training:- after 638 epochs, loss: 0.07251732051372528, auc_score: 0.6928088062723892\n",
      "Test:- after 638 epochs, loss: 0.07412435114383698, auc_score: 0.6937939482450546\n",
      "Training:- after 639 epochs, loss: 0.0726911872625351, auc_score: 0.6959154081247245\n",
      "Test:- after 639 epochs, loss: 0.07410495728254318, auc_score: 0.6897029549385549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 640 epochs, loss: 0.07270725071430206, auc_score: 0.6932668001435169\n",
      "Test:- after 640 epochs, loss: 0.07445012032985687, auc_score: 0.6953140523716976\n",
      "Training:- after 641 epochs, loss: 0.07267214357852936, auc_score: 0.6961052253590212\n",
      "Test:- after 641 epochs, loss: 0.07415865361690521, auc_score: 0.6850335825210485\n",
      "Training:- after 642 epochs, loss: 0.07263798266649246, auc_score: 0.6957506723778555\n",
      "Test:- after 642 epochs, loss: 0.07402978837490082, auc_score: 0.6943774938977608\n",
      "Training:- after 643 epochs, loss: 0.07260862737894058, auc_score: 0.693970591127118\n",
      "Test:- after 643 epochs, loss: 0.07384825497865677, auc_score: 0.6896782257934154\n",
      "Training:- after 644 epochs, loss: 0.072539784014225, auc_score: 0.697819360070486\n",
      "Test:- after 644 epochs, loss: 0.07503463327884674, auc_score: 0.6934564723524739\n",
      "Training:- after 645 epochs, loss: 0.07259820401668549, auc_score: 0.697963937207898\n",
      "Test:- after 645 epochs, loss: 0.07421485334634781, auc_score: 0.6936051021309031\n",
      "Training:- after 646 epochs, loss: 0.07262538373470306, auc_score: 0.698245633554117\n",
      "Test:- after 646 epochs, loss: 0.07433699816465378, auc_score: 0.6957825849619442\n",
      "Training:- after 647 epochs, loss: 0.07306692749261856, auc_score: 0.6964828522281913\n",
      "Test:- after 647 epochs, loss: 0.07434554398059845, auc_score: 0.6918428513341615\n",
      "Training:- after 648 epochs, loss: 0.0736779272556305, auc_score: 0.6973776612855843\n",
      "Test:- after 648 epochs, loss: 0.07407835125923157, auc_score: 0.6969485571608516\n",
      "Training:- after 649 epochs, loss: 0.07284178584814072, auc_score: 0.6964724751623635\n",
      "Test:- after 649 epochs, loss: 0.07468147575855255, auc_score: 0.695932044744365\n",
      "Training:- after 650 epochs, loss: 0.07289784401655197, auc_score: 0.6949773398559651\n",
      "Test:- after 650 epochs, loss: 0.07494165003299713, auc_score: 0.6916823092887083\n",
      "Training:- after 651 epochs, loss: 0.0724378153681755, auc_score: 0.6954599972903196\n",
      "Test:- after 651 epochs, loss: 0.07386263459920883, auc_score: 0.6952988511749997\n",
      "Training:- after 652 epochs, loss: 0.0726836547255516, auc_score: 0.695800847126617\n",
      "Test:- after 652 epochs, loss: 0.07468250393867493, auc_score: 0.6964627716786472\n",
      "Training:- after 653 epochs, loss: 0.07297611236572266, auc_score: 0.6977660242752518\n",
      "Test:- after 653 epochs, loss: 0.07386651635169983, auc_score: 0.693719568074627\n",
      "Training:- after 654 epochs, loss: 0.07295622676610947, auc_score: 0.6979799523917649\n",
      "Test:- after 654 epochs, loss: 0.07385797053575516, auc_score: 0.6902843991579345\n",
      "Training:- after 655 epochs, loss: 0.07266178727149963, auc_score: 0.6987067619556931\n",
      "Test:- after 655 epochs, loss: 0.07416576147079468, auc_score: 0.7006648798266131\n",
      "Training:- after 656 epochs, loss: 0.07269599288702011, auc_score: 0.6984071776819335\n",
      "Test:- after 656 epochs, loss: 0.0745348334312439, auc_score: 0.6905095851472185\n",
      "Training:- after 657 epochs, loss: 0.07261262089014053, auc_score: 0.6982935968862548\n",
      "Test:- after 657 epochs, loss: 0.07508688420057297, auc_score: 0.6932193367926158\n",
      "Training:- after 658 epochs, loss: 0.07243668287992477, auc_score: 0.6961940284142648\n",
      "Test:- after 658 epochs, loss: 0.07424847781658173, auc_score: 0.6950729097888246\n",
      "Training:- after 659 epochs, loss: 0.07250405102968216, auc_score: 0.6981578685814297\n",
      "Test:- after 659 epochs, loss: 0.07431191205978394, auc_score: 0.6977024059546414\n",
      "Training:- after 660 epochs, loss: 0.07254894822835922, auc_score: 0.6980962910518327\n",
      "Test:- after 660 epochs, loss: 0.07406295835971832, auc_score: 0.6978324212615314\n",
      "Training:- after 661 epochs, loss: 0.07344261556863785, auc_score: 0.6967616811830109\n",
      "Test:- after 661 epochs, loss: 0.07420426607131958, auc_score: 0.6999363352743615\n",
      "Training:- after 662 epochs, loss: 0.07301745563745499, auc_score: 0.6972385195373554\n",
      "Test:- after 662 epochs, loss: 0.07388722151517868, auc_score: 0.6984725843775219\n",
      "Training:- after 663 epochs, loss: 0.07247057557106018, auc_score: 0.6961072378065234\n",
      "Test:- after 663 epochs, loss: 0.07450434565544128, auc_score: 0.69670558670402\n",
      "Training:- after 664 epochs, loss: 0.07260791212320328, auc_score: 0.6974006903535926\n",
      "Test:- after 664 epochs, loss: 0.07521402090787888, auc_score: 0.6942137934850594\n",
      "Training:- after 665 epochs, loss: 0.07267825305461884, auc_score: 0.6976846048443817\n",
      "Test:- after 665 epochs, loss: 0.07400745898485184, auc_score: 0.6963034109122832\n",
      "Training:- after 666 epochs, loss: 0.07270084321498871, auc_score: 0.6958517239563754\n",
      "Test:- after 666 epochs, loss: 0.07446984201669693, auc_score: 0.691602659991818\n",
      "Training:- after 667 epochs, loss: 0.07258199900388718, auc_score: 0.6971642232208155\n",
      "Test:- after 667 epochs, loss: 0.07402334362268448, auc_score: 0.6894394955067874\n",
      "Training:- after 668 epochs, loss: 0.07248446345329285, auc_score: 0.6966619247341764\n",
      "Test:- after 668 epochs, loss: 0.07403799146413803, auc_score: 0.6923266441850604\n",
      "Training:- after 669 epochs, loss: 0.07247096300125122, auc_score: 0.697531608275669\n",
      "Test:- after 669 epochs, loss: 0.07386714220046997, auc_score: 0.6934401271802371\n",
      "Training:- after 670 epochs, loss: 0.07302132993936539, auc_score: 0.6987534084902005\n",
      "Test:- after 670 epochs, loss: 0.0752037838101387, auc_score: 0.6964935564334325\n",
      "Training:- after 671 epochs, loss: 0.07252047210931778, auc_score: 0.6971734671223736\n",
      "Test:- after 671 epochs, loss: 0.07410310953855515, auc_score: 0.6954649514494295\n",
      "Training:- after 672 epochs, loss: 0.07257559150457382, auc_score: 0.698511184313037\n",
      "Test:- after 672 epochs, loss: 0.07408145070075989, auc_score: 0.6920128591554726\n",
      "Training:- after 673 epochs, loss: 0.07241866737604141, auc_score: 0.6967024337985037\n",
      "Test:- after 673 epochs, loss: 0.07431826740503311, auc_score: 0.6950834604762669\n",
      "Training:- after 674 epochs, loss: 0.07275116443634033, auc_score: 0.6959414309310085\n",
      "Test:- after 674 epochs, loss: 0.07391635328531265, auc_score: 0.694395094956187\n",
      "Training:- after 675 epochs, loss: 0.07261350005865097, auc_score: 0.6994298060463153\n",
      "Test:- after 675 epochs, loss: 0.07380837202072144, auc_score: 0.6933809046856989\n",
      "Training:- after 676 epochs, loss: 0.07264931499958038, auc_score: 0.6989213459480416\n",
      "Test:- after 676 epochs, loss: 0.07388739287853241, auc_score: 0.696380517350503\n",
      "Training:- after 677 epochs, loss: 0.07240928709506989, auc_score: 0.6990430160109443\n",
      "Test:- after 677 epochs, loss: 0.07362697273492813, auc_score: 0.6958335105251968\n",
      "Training:- after 678 epochs, loss: 0.07233516871929169, auc_score: 0.6996188838001484\n",
      "Test:- after 678 epochs, loss: 0.0739881843328476, auc_score: 0.702101175310521\n",
      "Training:- after 679 epochs, loss: 0.0723276361823082, auc_score: 0.7002026879936762\n",
      "Test:- after 679 epochs, loss: 0.0741109699010849, auc_score: 0.7015601898999395\n",
      "Training:- after 680 epochs, loss: 0.07235872000455856, auc_score: 0.7011348764330272\n",
      "Test:- after 680 epochs, loss: 0.0738455131649971, auc_score: 0.7001166855049594\n",
      "Training:- after 681 epochs, loss: 0.07229913771152496, auc_score: 0.6988490450612571\n",
      "Test:- after 681 epochs, loss: 0.0737704485654831, auc_score: 0.6997022586056182\n",
      "Training:- after 682 epochs, loss: 0.07245689630508423, auc_score: 0.6982620265913277\n",
      "Test:- after 682 epochs, loss: 0.07368667423725128, auc_score: 0.7005391077985559\n",
      "Training:- after 683 epochs, loss: 0.07239823043346405, auc_score: 0.6996483795130094\n",
      "Test:- after 683 epochs, loss: 0.07373237609863281, auc_score: 0.7003047358100404\n",
      "Training:- after 684 epochs, loss: 0.07226730138063431, auc_score: 0.700629255231321\n",
      "Test:- after 684 epochs, loss: 0.07417626678943634, auc_score: 0.696644194386313\n",
      "Training:- after 685 epochs, loss: 0.0722297728061676, auc_score: 0.6991610205303336\n",
      "Test:- after 685 epochs, loss: 0.07418867945671082, auc_score: 0.6947383218127536\n",
      "Training:- after 686 epochs, loss: 0.07240010797977448, auc_score: 0.6987985087843159\n",
      "Test:- after 686 epochs, loss: 0.0740462988615036, auc_score: 0.6950177658157726\n",
      "Training:- after 687 epochs, loss: 0.07245694100856781, auc_score: 0.6982238353045416\n",
      "Test:- after 687 epochs, loss: 0.07364299893379211, auc_score: 0.6909166072918492\n",
      "Training:- after 688 epochs, loss: 0.07236860692501068, auc_score: 0.7002857283649316\n",
      "Test:- after 688 epochs, loss: 0.07361800223588943, auc_score: 0.6986546163765073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 689 epochs, loss: 0.0728728175163269, auc_score: 0.6996989603131253\n",
      "Test:- after 689 epochs, loss: 0.07397924363613129, auc_score: 0.6998969116390807\n",
      "Training:- after 690 epochs, loss: 0.07237821817398071, auc_score: 0.6987242354219463\n",
      "Test:- after 690 epochs, loss: 0.07366956770420074, auc_score: 0.6898428681207591\n",
      "Training:- after 691 epochs, loss: 0.07235967367887497, auc_score: 0.6992405447580617\n",
      "Test:- after 691 epochs, loss: 0.07399413734674454, auc_score: 0.6966811093578443\n",
      "Training:- after 692 epochs, loss: 0.07244588434696198, auc_score: 0.6988997270773907\n",
      "Test:- after 692 epochs, loss: 0.07403574883937836, auc_score: 0.6957399283523147\n",
      "Training:- after 693 epochs, loss: 0.07246148586273193, auc_score: 0.6987627870496274\n",
      "Test:- after 693 epochs, loss: 0.07385885715484619, auc_score: 0.696296062112898\n",
      "Training:- after 694 epochs, loss: 0.07253589481115341, auc_score: 0.7000461424332278\n",
      "Test:- after 694 epochs, loss: 0.07403845340013504, auc_score: 0.6997743819112598\n",
      "Training:- after 695 epochs, loss: 0.07247330993413925, auc_score: 0.699581003680884\n",
      "Test:- after 695 epochs, loss: 0.07421080768108368, auc_score: 0.6912440018999941\n",
      "Training:- after 696 epochs, loss: 0.07216714322566986, auc_score: 0.6986838754607847\n",
      "Test:- after 696 epochs, loss: 0.07414256781339645, auc_score: 0.6975391220982501\n",
      "Training:- after 697 epochs, loss: 0.07239169627428055, auc_score: 0.6991000354557829\n",
      "Test:- after 697 epochs, loss: 0.07358554750680923, auc_score: 0.6960147156288197\n",
      "Training:- after 698 epochs, loss: 0.07248054444789886, auc_score: 0.6998074464703186\n",
      "Test:- after 698 epochs, loss: 0.07364358007907867, auc_score: 0.6983017993989153\n",
      "Training:- after 699 epochs, loss: 0.07226676493883133, auc_score: 0.6998267296552182\n",
      "Test:- after 699 epochs, loss: 0.0739302858710289, auc_score: 0.6950252078740333\n",
      "Training:- after 700 epochs, loss: 0.07234000414609909, auc_score: 0.6986162793873546\n",
      "Test:- after 700 epochs, loss: 0.07385581731796265, auc_score: 0.7009947271431822\n",
      "Training:- after 701 epochs, loss: 0.07222657650709152, auc_score: 0.6998766345935402\n",
      "Test:- after 701 epochs, loss: 0.0736207365989685, auc_score: 0.697899713757425\n",
      "Training:- after 702 epochs, loss: 0.07226085662841797, auc_score: 0.7000204518687684\n",
      "Test:- after 702 epochs, loss: 0.07367890328168869, auc_score: 0.7008891549875468\n",
      "Training:- after 703 epochs, loss: 0.07264647632837296, auc_score: 0.7006375771073985\n",
      "Test:- after 703 epochs, loss: 0.07392212003469467, auc_score: 0.6956749144816112\n",
      "Training:- after 704 epochs, loss: 0.0724535584449768, auc_score: 0.6983242193322603\n",
      "Test:- after 704 epochs, loss: 0.07394981384277344, auc_score: 0.7018462397399694\n",
      "Training:- after 705 epochs, loss: 0.07221973687410355, auc_score: 0.7022599830963315\n",
      "Test:- after 705 epochs, loss: 0.07560962438583374, auc_score: 0.6918581955278017\n",
      "Training:- after 706 epochs, loss: 0.07212692499160767, auc_score: 0.7000149577089945\n",
      "Test:- after 706 epochs, loss: 0.07369144260883331, auc_score: 0.6925370175562942\n",
      "Training:- after 707 epochs, loss: 0.07222594320774078, auc_score: 0.7013358553304325\n",
      "Test:- after 707 epochs, loss: 0.07366853207349777, auc_score: 0.7021333682743254\n",
      "Training:- after 708 epochs, loss: 0.07227562367916107, auc_score: 0.7023690262879122\n",
      "Test:- after 708 epochs, loss: 0.07379338145256042, auc_score: 0.6970857969219598\n",
      "Training:- after 709 epochs, loss: 0.0723271518945694, auc_score: 0.7006102412632187\n",
      "Test:- after 709 epochs, loss: 0.0735630914568901, auc_score: 0.6972677760742491\n",
      "Training:- after 710 epochs, loss: 0.07225918769836426, auc_score: 0.7026264634402725\n",
      "Test:- after 710 epochs, loss: 0.0743068978190422, auc_score: 0.6982926569204924\n",
      "Training:- after 711 epochs, loss: 0.07222653180360794, auc_score: 0.698501017495535\n",
      "Test:- after 711 epochs, loss: 0.07447527348995209, auc_score: 0.6943839691723461\n",
      "Training:- after 712 epochs, loss: 0.07223273068666458, auc_score: 0.7004201687627196\n",
      "Test:- after 712 epochs, loss: 0.07354168593883514, auc_score: 0.6947795453443304\n",
      "Training:- after 713 epochs, loss: 0.0721835196018219, auc_score: 0.6999139317560353\n",
      "Test:- after 713 epochs, loss: 0.07400736212730408, auc_score: 0.6989758590075017\n",
      "Training:- after 714 epochs, loss: 0.0723409503698349, auc_score: 0.699842988529262\n",
      "Test:- after 714 epochs, loss: 0.0735429897904396, auc_score: 0.7000242628507621\n",
      "Training:- after 715 epochs, loss: 0.07223561406135559, auc_score: 0.7011599718710496\n",
      "Test:- after 715 epochs, loss: 0.07354072481393814, auc_score: 0.6990073090089317\n",
      "Training:- after 716 epochs, loss: 0.07207069545984268, auc_score: 0.7000398335982949\n",
      "Test:- after 716 epochs, loss: 0.07381676137447357, auc_score: 0.6941326054167242\n",
      "Training:- after 717 epochs, loss: 0.07226881384849548, auc_score: 0.7016778799849032\n",
      "Test:- after 717 epochs, loss: 0.07383070141077042, auc_score: 0.695185930219979\n",
      "Training:- after 718 epochs, loss: 0.07239177078008652, auc_score: 0.700477601976263\n",
      "Test:- after 718 epochs, loss: 0.0736565887928009, auc_score: 0.6995333854339585\n",
      "Training:- after 719 epochs, loss: 0.07224797457456589, auc_score: 0.7014986725242279\n",
      "Test:- after 719 epochs, loss: 0.07391316443681717, auc_score: 0.7025722103472588\n",
      "Training:- after 720 epochs, loss: 0.0724959671497345, auc_score: 0.7019879548091161\n",
      "Test:- after 720 epochs, loss: 0.0739055648446083, auc_score: 0.6973249126786063\n",
      "Training:- after 721 epochs, loss: 0.07203538715839386, auc_score: 0.7005024957737737\n",
      "Test:- after 721 epochs, loss: 0.07447706162929535, auc_score: 0.6964366467590054\n",
      "Training:- after 722 epochs, loss: 0.07211771607398987, auc_score: 0.7003668203031159\n",
      "Test:- after 722 epochs, loss: 0.07350276410579681, auc_score: 0.7033667137934849\n",
      "Training:- after 723 epochs, loss: 0.07226800173521042, auc_score: 0.70266295651423\n",
      "Test:- after 723 epochs, loss: 0.073739193379879, auc_score: 0.6965982892591887\n",
      "Training:- after 724 epochs, loss: 0.07213198393583298, auc_score: 0.7016054035778695\n",
      "Test:- after 724 epochs, loss: 0.0734490305185318, auc_score: 0.6996598320345481\n",
      "Training:- after 725 epochs, loss: 0.07206761091947556, auc_score: 0.7008107820525835\n",
      "Test:- after 725 epochs, loss: 0.07423203438520432, auc_score: 0.6985260434735574\n",
      "Training:- after 726 epochs, loss: 0.0722946971654892, auc_score: 0.7035996128047048\n",
      "Test:- after 726 epochs, loss: 0.073726125061512, auc_score: 0.6978905339754518\n",
      "Training:- after 727 epochs, loss: 0.07249633967876434, auc_score: 0.7000692874593716\n",
      "Test:- after 727 epochs, loss: 0.07386951148509979, auc_score: 0.6968162663374007\n",
      "Training:- after 728 epochs, loss: 0.07220611721277237, auc_score: 0.7015285427264595\n",
      "Test:- after 728 epochs, loss: 0.07350253313779831, auc_score: 0.6939676304660581\n",
      "Training:- after 729 epochs, loss: 0.07207971811294556, auc_score: 0.701433478228729\n",
      "Test:- after 729 epochs, loss: 0.07399445027112961, auc_score: 0.7013174370471504\n",
      "Training:- after 730 epochs, loss: 0.07211454957723618, auc_score: 0.7037252733313568\n",
      "Test:- after 730 epochs, loss: 0.07373318821191788, auc_score: 0.6991661692859976\n",
      "Training:- after 731 epochs, loss: 0.07248351722955704, auc_score: 0.7024444239099165\n",
      "Test:- after 731 epochs, loss: 0.07371797412633896, auc_score: 0.6972016493142985\n",
      "Training:- after 732 epochs, loss: 0.07247398048639297, auc_score: 0.7010784716058819\n",
      "Test:- after 732 epochs, loss: 0.07374361902475357, auc_score: 0.7031785453604953\n",
      "Training:- after 733 epochs, loss: 0.07214129716157913, auc_score: 0.70292700219196\n",
      "Test:- after 733 epochs, loss: 0.07412576675415039, auc_score: 0.6995758959380165\n",
      "Training:- after 734 epochs, loss: 0.07204052805900574, auc_score: 0.7007618693874178\n",
      "Test:- after 734 epochs, loss: 0.07348954677581787, auc_score: 0.6995148113745985\n",
      "Training:- after 735 epochs, loss: 0.07211773097515106, auc_score: 0.7021691334591517\n",
      "Test:- after 735 epochs, loss: 0.07345506548881531, auc_score: 0.6989074971431697\n",
      "Training:- after 736 epochs, loss: 0.07211275398731232, auc_score: 0.7020145411798528\n",
      "Test:- after 736 epochs, loss: 0.07368583232164383, auc_score: 0.699100962680285\n",
      "Training:- after 737 epochs, loss: 0.07204677909612656, auc_score: 0.7003868112086142\n",
      "Test:- after 737 epochs, loss: 0.07377803325653076, auc_score: 0.698914348561886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 738 epochs, loss: 0.0720830038189888, auc_score: 0.7022711570280481\n",
      "Test:- after 738 epochs, loss: 0.07353359460830688, auc_score: 0.7015329707428255\n",
      "Training:- after 739 epochs, loss: 0.0721689760684967, auc_score: 0.6997110827863467\n",
      "Test:- after 739 epochs, loss: 0.07370014488697052, auc_score: 0.7012827851576635\n",
      "Training:- after 740 epochs, loss: 0.07201804965734482, auc_score: 0.7024616597213563\n",
      "Test:- after 740 epochs, loss: 0.07374453544616699, auc_score: 0.6982503484773314\n",
      "Training:- after 741 epochs, loss: 0.07197398692369461, auc_score: 0.7026077762722733\n",
      "Test:- after 741 epochs, loss: 0.07392030209302902, auc_score: 0.6963151708564771\n",
      "Training:- after 742 epochs, loss: 0.07206875085830688, auc_score: 0.6992284570129167\n",
      "Test:- after 742 epochs, loss: 0.07345521450042725, auc_score: 0.702947651928034\n",
      "Training:- after 743 epochs, loss: 0.07261679321527481, auc_score: 0.7010291145004911\n",
      "Test:- after 743 epochs, loss: 0.07370730489492416, auc_score: 0.7006043765768522\n",
      "Training:- after 744 epochs, loss: 0.07203061133623123, auc_score: 0.7044389108624224\n",
      "Test:- after 744 epochs, loss: 0.07342648506164551, auc_score: 0.7046425822512195\n",
      "Training:- after 745 epochs, loss: 0.07220719754695892, auc_score: 0.7045845971215896\n",
      "Test:- after 745 epochs, loss: 0.07362044602632523, auc_score: 0.7031209362445023\n",
      "Training:- after 746 epochs, loss: 0.07216524332761765, auc_score: 0.704905720223226\n",
      "Test:- after 746 epochs, loss: 0.07353338599205017, auc_score: 0.6969082568921418\n",
      "Training:- after 747 epochs, loss: 0.0721111074090004, auc_score: 0.7044631399784029\n",
      "Test:- after 747 epochs, loss: 0.07370217144489288, auc_score: 0.6977761426388283\n",
      "Training:- after 748 epochs, loss: 0.07208248227834702, auc_score: 0.7017575654854646\n",
      "Test:- after 748 epochs, loss: 0.07330452650785446, auc_score: 0.6999730761626584\n",
      "Training:- after 749 epochs, loss: 0.07208756357431412, auc_score: 0.7021446630275634\n",
      "Test:- after 749 epochs, loss: 0.07371750473976135, auc_score: 0.7000007429623745\n",
      "Training:- after 750 epochs, loss: 0.07201641798019409, auc_score: 0.7042492134449362\n",
      "Test:- after 750 epochs, loss: 0.07303375750780106, auc_score: 0.7025069322430749\n",
      "Training:- after 751 epochs, loss: 0.07215948402881622, auc_score: 0.7026440768082348\n",
      "Test:- after 751 epochs, loss: 0.07371760904788971, auc_score: 0.7008889031885831\n",
      "Training:- after 752 epochs, loss: 0.07215775549411774, auc_score: 0.7020223514351815\n",
      "Test:- after 752 epochs, loss: 0.0750146135687828, auc_score: 0.6990036252833516\n",
      "Training:- after 753 epochs, loss: 0.072097048163414, auc_score: 0.7011473927879353\n",
      "Test:- after 753 epochs, loss: 0.07347585260868073, auc_score: 0.7007707783883126\n",
      "Training:- after 754 epochs, loss: 0.07202736288309097, auc_score: 0.7026072153792109\n",
      "Test:- after 754 epochs, loss: 0.07364599406719208, auc_score: 0.69972367395205\n",
      "Training:- after 755 epochs, loss: 0.07201813906431198, auc_score: 0.7032078513116321\n",
      "Test:- after 755 epochs, loss: 0.0736348107457161, auc_score: 0.701160671986153\n",
      "Training:- after 756 epochs, loss: 0.07197471708059311, auc_score: 0.7026224057959991\n",
      "Test:- after 756 epochs, loss: 0.07356686145067215, auc_score: 0.698855999592148\n",
      "Training:- after 757 epochs, loss: 0.07204234600067139, auc_score: 0.7039554462723786\n",
      "Test:- after 757 epochs, loss: 0.07331275939941406, auc_score: 0.7045155823146356\n",
      "Training:- after 758 epochs, loss: 0.07205808162689209, auc_score: 0.702729082135606\n",
      "Test:- after 758 epochs, loss: 0.07378330081701279, auc_score: 0.7005335775472419\n",
      "Training:- after 759 epochs, loss: 0.07198049873113632, auc_score: 0.7033040824154836\n",
      "Test:- after 759 epochs, loss: 0.07384365797042847, auc_score: 0.7014510086258243\n",
      "Training:- after 760 epochs, loss: 0.07220438867807388, auc_score: 0.7027608896895848\n",
      "Test:- after 760 epochs, loss: 0.07395340502262115, auc_score: 0.702474114444805\n",
      "Training:- after 761 epochs, loss: 0.07197470217943192, auc_score: 0.7020925695278474\n",
      "Test:- after 761 epochs, loss: 0.07354152947664261, auc_score: 0.7003616641362426\n",
      "Training:- after 762 epochs, loss: 0.07184159755706787, auc_score: 0.7031441318215644\n",
      "Test:- after 762 epochs, loss: 0.07334697246551514, auc_score: 0.7039676242487998\n",
      "Training:- after 763 epochs, loss: 0.07195255160331726, auc_score: 0.7019490637169622\n",
      "Test:- after 763 epochs, loss: 0.07332450151443481, auc_score: 0.6968137172614718\n",
      "Training:- after 764 epochs, loss: 0.07221537083387375, auc_score: 0.70294301054894\n",
      "Test:- after 764 epochs, loss: 0.0738610103726387, auc_score: 0.7048163390793235\n",
      "Training:- after 765 epochs, loss: 0.07188202440738678, auc_score: 0.7015370951336423\n",
      "Test:- after 765 epochs, loss: 0.07372842729091644, auc_score: 0.7023042371859196\n",
      "Training:- after 766 epochs, loss: 0.07234765589237213, auc_score: 0.703368840087048\n",
      "Test:- after 766 epochs, loss: 0.0740252435207367, auc_score: 0.7014301124204657\n",
      "Training:- after 767 epochs, loss: 0.07190696150064468, auc_score: 0.7026920941618251\n",
      "Test:- after 767 epochs, loss: 0.07325674593448639, auc_score: 0.702812208954593\n",
      "Training:- after 768 epochs, loss: 0.07218563556671143, auc_score: 0.7033336381851604\n",
      "Test:- after 768 epochs, loss: 0.0735357478260994, auc_score: 0.7030586455329622\n",
      "Training:- after 769 epochs, loss: 0.0721968337893486, auc_score: 0.7022245680768471\n",
      "Test:- after 769 epochs, loss: 0.07359275221824646, auc_score: 0.6973179244802061\n",
      "Training:- after 770 epochs, loss: 0.0721588134765625, auc_score: 0.7051210669470295\n",
      "Test:- after 770 epochs, loss: 0.07397525012493134, auc_score: 0.7016637072516859\n",
      "Training:- after 771 epochs, loss: 0.07206593453884125, auc_score: 0.7021571072549282\n",
      "Test:- after 771 epochs, loss: 0.07344988733530045, auc_score: 0.7036593663618966\n",
      "Training:- after 772 epochs, loss: 0.07188668102025986, auc_score: 0.7040464835994755\n",
      "Test:- after 772 epochs, loss: 0.07365100830793381, auc_score: 0.7009058265658474\n",
      "Training:- after 773 epochs, loss: 0.07203169912099838, auc_score: 0.7054807874857465\n",
      "Test:- after 773 epochs, loss: 0.07358238846063614, auc_score: 0.6985072145066047\n",
      "Training:- after 774 epochs, loss: 0.07224716246128082, auc_score: 0.7021485013209953\n",
      "Test:- after 774 epochs, loss: 0.07330898940563202, auc_score: 0.7068459910496347\n",
      "Training:- after 775 epochs, loss: 0.07196341454982758, auc_score: 0.7047993046904834\n",
      "Test:- after 775 epochs, loss: 0.07308011502027512, auc_score: 0.6960477759001658\n",
      "Training:- after 776 epochs, loss: 0.07194730639457703, auc_score: 0.7057198414149813\n",
      "Test:- after 776 epochs, loss: 0.07326243072748184, auc_score: 0.7002225996098049\n",
      "Training:- after 777 epochs, loss: 0.07195339351892471, auc_score: 0.7032178074850471\n",
      "Test:- after 777 epochs, loss: 0.07357630133628845, auc_score: 0.7036418368019418\n",
      "Training:- after 778 epochs, loss: 0.07187777012586594, auc_score: 0.7035930969864792\n",
      "Test:- after 778 epochs, loss: 0.07370590418577194, auc_score: 0.7004743643785913\n",
      "Training:- after 779 epochs, loss: 0.071957528591156, auc_score: 0.7026010879020101\n",
      "Test:- after 779 epochs, loss: 0.07349110394716263, auc_score: 0.7014654637515186\n",
      "Training:- after 780 epochs, loss: 0.07217483222484589, auc_score: 0.7036987738302811\n",
      "Test:- after 780 epochs, loss: 0.07307613641023636, auc_score: 0.6998862583668753\n",
      "Training:- after 781 epochs, loss: 0.07197525352239609, auc_score: 0.703221023344495\n",
      "Test:- after 781 epochs, loss: 0.07337237149477005, auc_score: 0.7043910133260716\n",
      "Training:- after 782 epochs, loss: 0.07205513119697571, auc_score: 0.7043684413622292\n",
      "Test:- after 782 epochs, loss: 0.07342436909675598, auc_score: 0.7037210477821174\n",
      "Training:- after 783 epochs, loss: 0.07202158868312836, auc_score: 0.70384882296482\n",
      "Test:- after 783 epochs, loss: 0.07355502247810364, auc_score: 0.7013787982785655\n",
      "Training:- after 784 epochs, loss: 0.07210959494113922, auc_score: 0.7044583804510137\n",
      "Test:- after 784 epochs, loss: 0.07322532683610916, auc_score: 0.7020620345604958\n",
      "Training:- after 785 epochs, loss: 0.07189696282148361, auc_score: 0.7041977041882144\n",
      "Test:- after 785 epochs, loss: 0.07353561371564865, auc_score: 0.7014053708408095\n",
      "Training:- after 786 epochs, loss: 0.07189541310071945, auc_score: 0.7050303920385756\n",
      "Test:- after 786 epochs, loss: 0.07400066405534744, auc_score: 0.7038764201772416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 787 epochs, loss: 0.07201655209064484, auc_score: 0.7035207310958594\n",
      "Test:- after 787 epochs, loss: 0.07315082103013992, auc_score: 0.7057439384839589\n",
      "Training:- after 788 epochs, loss: 0.07197056710720062, auc_score: 0.7036865273847529\n",
      "Test:- after 788 epochs, loss: 0.07380282878875732, auc_score: 0.7001422975007865\n",
      "Training:- after 789 epochs, loss: 0.07198435068130493, auc_score: 0.7036091170184251\n",
      "Test:- after 789 epochs, loss: 0.07372340559959412, auc_score: 0.7066430473021451\n",
      "Training:- after 790 epochs, loss: 0.07220727950334549, auc_score: 0.7032849078671308\n",
      "Test:- after 790 epochs, loss: 0.07351721078157425, auc_score: 0.6992889881163323\n",
      "Training:- after 791 epochs, loss: 0.07204592227935791, auc_score: 0.7045880819010134\n",
      "Test:- after 791 epochs, loss: 0.07393934577703476, auc_score: 0.7029133792913071\n",
      "Training:- after 792 epochs, loss: 0.07199979573488235, auc_score: 0.7041456128651871\n",
      "Test:- after 792 epochs, loss: 0.07331634312868118, auc_score: 0.6989645871180894\n",
      "Training:- after 793 epochs, loss: 0.07186423242092133, auc_score: 0.7037838702817499\n",
      "Test:- after 793 epochs, loss: 0.0736326053738594, auc_score: 0.7049084695223777\n",
      "Training:- after 794 epochs, loss: 0.07190340757369995, auc_score: 0.7060873146257209\n",
      "Test:- after 794 epochs, loss: 0.07354333251714706, auc_score: 0.7034340373756703\n",
      "Training:- after 795 epochs, loss: 0.07187213748693466, auc_score: 0.7046039607450248\n",
      "Test:- after 795 epochs, loss: 0.07340268045663834, auc_score: 0.7026010522088053\n",
      "Training:- after 796 epochs, loss: 0.07198486477136612, auc_score: 0.7048289232873068\n",
      "Test:- after 796 epochs, loss: 0.07360214740037918, auc_score: 0.7021381306942315\n",
      "Training:- after 797 epochs, loss: 0.0720219835639, auc_score: 0.7066869712461769\n",
      "Test:- after 797 epochs, loss: 0.07432133704423904, auc_score: 0.6988823980711578\n",
      "Training:- after 798 epochs, loss: 0.07203872501850128, auc_score: 0.7065714547807376\n",
      "Test:- after 798 epochs, loss: 0.07409872859716415, auc_score: 0.6999527426191818\n",
      "Training:- after 799 epochs, loss: 0.0720023512840271, auc_score: 0.7073825461209755\n",
      "Test:- after 799 epochs, loss: 0.07356224954128265, auc_score: 0.7023870199810249\n",
      "Training:- after 800 epochs, loss: 0.07215044647455215, auc_score: 0.7074597809670541\n",
      "Test:- after 800 epochs, loss: 0.07343515008687973, auc_score: 0.7010486463163366\n",
      "Training:- after 801 epochs, loss: 0.07195040583610535, auc_score: 0.7036533731531459\n",
      "Test:- after 801 epochs, loss: 0.07320719957351685, auc_score: 0.699417215961443\n",
      "Training:- after 802 epochs, loss: 0.07189802080392838, auc_score: 0.7030106432303139\n",
      "Test:- after 802 epochs, loss: 0.07378925383090973, auc_score: 0.6999490930885226\n",
      "Training:- after 803 epochs, loss: 0.0718960091471672, auc_score: 0.7019244904863102\n",
      "Test:- after 803 epochs, loss: 0.07328446209430695, auc_score: 0.7013789288409913\n",
      "Training:- after 804 epochs, loss: 0.071865975856781, auc_score: 0.703736834713635\n",
      "Test:- after 804 epochs, loss: 0.07344567775726318, auc_score: 0.706246243221634\n",
      "Training:- after 805 epochs, loss: 0.07201263308525085, auc_score: 0.7042726667693306\n",
      "Test:- after 805 epochs, loss: 0.07347660511732101, auc_score: 0.7022637690512339\n",
      "Training:- after 806 epochs, loss: 0.07212527096271515, auc_score: 0.7067633858764347\n",
      "Test:- after 806 epochs, loss: 0.07345552742481232, auc_score: 0.7072096820121038\n",
      "Training:- after 807 epochs, loss: 0.07215327024459839, auc_score: 0.7047673949310831\n",
      "Test:- after 807 epochs, loss: 0.07334814220666885, auc_score: 0.7006211445226576\n",
      "Training:- after 808 epochs, loss: 0.07210417091846466, auc_score: 0.7053268965948623\n",
      "Test:- after 808 epochs, loss: 0.07333269715309143, auc_score: 0.7077830686646448\n",
      "Training:- after 809 epochs, loss: 0.07178814709186554, auc_score: 0.7049730577654207\n",
      "Test:- after 809 epochs, loss: 0.07348193228244781, auc_score: 0.7028835209080182\n",
      "Training:- after 810 epochs, loss: 0.07186800986528397, auc_score: 0.7070161738199389\n",
      "Test:- after 810 epochs, loss: 0.07352595776319504, auc_score: 0.7038674642165694\n",
      "Training:- after 811 epochs, loss: 0.07202525436878204, auc_score: 0.7034636273538099\n",
      "Test:- after 811 epochs, loss: 0.07330900430679321, auc_score: 0.7041203760695238\n",
      "Training:- after 812 epochs, loss: 0.07187497615814209, auc_score: 0.7058866559983532\n",
      "Test:- after 812 epochs, loss: 0.07340671122074127, auc_score: 0.704570325274523\n",
      "Training:- after 813 epochs, loss: 0.07188331335783005, auc_score: 0.7068275963087104\n",
      "Test:- after 813 epochs, loss: 0.07315748184919357, auc_score: 0.7017852981734938\n",
      "Training:- after 814 epochs, loss: 0.07175973057746887, auc_score: 0.7045020776714799\n",
      "Test:- after 814 epochs, loss: 0.07387929409742355, auc_score: 0.7045710309333473\n",
      "Training:- after 815 epochs, loss: 0.07184318453073502, auc_score: 0.7056984149833859\n",
      "Test:- after 815 epochs, loss: 0.07321857661008835, auc_score: 0.7062729214772703\n",
      "Training:- after 816 epochs, loss: 0.07192054390907288, auc_score: 0.7039259173155471\n",
      "Test:- after 816 epochs, loss: 0.07353334128856659, auc_score: 0.7054663410066736\n",
      "Training:- after 817 epochs, loss: 0.07206021249294281, auc_score: 0.7045110647237894\n",
      "Test:- after 817 epochs, loss: 0.07326891273260117, auc_score: 0.7064074380792154\n",
      "Training:- after 818 epochs, loss: 0.07176751643419266, auc_score: 0.7053265981906505\n",
      "Test:- after 818 epochs, loss: 0.0733494833111763, auc_score: 0.7044755151931142\n",
      "Training:- after 819 epochs, loss: 0.0718909502029419, auc_score: 0.7043327532672726\n",
      "Test:- after 819 epochs, loss: 0.07355768233537674, auc_score: 0.7065695810686969\n",
      "Training:- after 820 epochs, loss: 0.07179712504148483, auc_score: 0.7047571563817993\n",
      "Test:- after 820 epochs, loss: 0.07332024723291397, auc_score: 0.7070807143132478\n",
      "Training:- after 821 epochs, loss: 0.07184910029172897, auc_score: 0.7068934887275905\n",
      "Test:- after 821 epochs, loss: 0.0733526274561882, auc_score: 0.7069997562834721\n",
      "Training:- after 822 epochs, loss: 0.0720846951007843, auc_score: 0.7067938930568873\n",
      "Test:- after 822 epochs, loss: 0.07299008965492249, auc_score: 0.6997733684981466\n",
      "Training:- after 823 epochs, loss: 0.07179967314004898, auc_score: 0.7046219423691135\n",
      "Test:- after 823 epochs, loss: 0.07339627295732498, auc_score: 0.7033693468024018\n",
      "Training:- after 824 epochs, loss: 0.07187893986701965, auc_score: 0.7064401537614767\n",
      "Test:- after 824 epochs, loss: 0.0733669251203537, auc_score: 0.7029532381346734\n",
      "Training:- after 825 epochs, loss: 0.07180606573820114, auc_score: 0.7041024894989741\n",
      "Test:- after 825 epochs, loss: 0.07324530184268951, auc_score: 0.7066999569765721\n",
      "Training:- after 826 epochs, loss: 0.07167032361030579, auc_score: 0.7047944184204564\n",
      "Test:- after 826 epochs, loss: 0.07340472936630249, auc_score: 0.6985885020510735\n",
      "Training:- after 827 epochs, loss: 0.07172762602567673, auc_score: 0.7068207601215065\n",
      "Test:- after 827 epochs, loss: 0.07333861291408539, auc_score: 0.7054876568769717\n",
      "Training:- after 828 epochs, loss: 0.07168462127447128, auc_score: 0.7038536742099494\n",
      "Test:- after 828 epochs, loss: 0.07313411682844162, auc_score: 0.7030416195709345\n",
      "Training:- after 829 epochs, loss: 0.07175590842962265, auc_score: 0.7060319103827248\n",
      "Test:- after 829 epochs, loss: 0.07354533672332764, auc_score: 0.6990705416351142\n",
      "Training:- after 830 epochs, loss: 0.0719808042049408, auc_score: 0.7048458141925525\n",
      "Test:- after 830 epochs, loss: 0.07337244600057602, auc_score: 0.7059446906478756\n",
      "Training:- after 831 epochs, loss: 0.07199562340974808, auc_score: 0.7049577499063913\n",
      "Test:- after 831 epochs, loss: 0.07321016490459442, auc_score: 0.7050554050979031\n",
      "Training:- after 832 epochs, loss: 0.0719808042049408, auc_score: 0.7069565836069855\n",
      "Test:- after 832 epochs, loss: 0.07369312644004822, auc_score: 0.7050718621807904\n",
      "Training:- after 833 epochs, loss: 0.0719292089343071, auc_score: 0.7060669165805239\n",
      "Test:- after 833 epochs, loss: 0.07352497428655624, auc_score: 0.7025142468475392\n",
      "Training:- after 834 epochs, loss: 0.07186415791511536, auc_score: 0.7052137622182167\n",
      "Test:- after 834 epochs, loss: 0.07325201481580734, auc_score: 0.7015526918863535\n",
      "Training:- after 835 epochs, loss: 0.07180949300527573, auc_score: 0.708381738673412\n",
      "Test:- after 835 epochs, loss: 0.0732729583978653, auc_score: 0.7036097868350798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 836 epochs, loss: 0.07174822688102722, auc_score: 0.7065984101001832\n",
      "Test:- after 836 epochs, loss: 0.07319731265306473, auc_score: 0.7020399912709692\n",
      "Training:- after 837 epochs, loss: 0.07187935709953308, auc_score: 0.7065809584008155\n",
      "Test:- after 837 epochs, loss: 0.07366513460874557, auc_score: 0.703235551402427\n",
      "Training:- after 838 epochs, loss: 0.07172126322984695, auc_score: 0.7067142965037352\n",
      "Test:- after 838 epochs, loss: 0.0735841915011406, auc_score: 0.7000792980217927\n",
      "Training:- after 839 epochs, loss: 0.0719093307852745, auc_score: 0.7051809168785027\n",
      "Test:- after 839 epochs, loss: 0.07297084480524063, auc_score: 0.699825950960753\n",
      "Training:- after 840 epochs, loss: 0.07174398750066757, auc_score: 0.7054067440608398\n",
      "Test:- after 840 epochs, loss: 0.07328087836503983, auc_score: 0.6995621620142922\n",
      "Training:- after 841 epochs, loss: 0.0718575268983841, auc_score: 0.7050297830604842\n",
      "Test:- after 841 epochs, loss: 0.07488159090280533, auc_score: 0.7033264477196961\n",
      "Training:- after 842 epochs, loss: 0.0716734528541565, auc_score: 0.705020474649793\n",
      "Test:- after 842 epochs, loss: 0.07335595041513443, auc_score: 0.700330994400737\n",
      "Training:- after 843 epochs, loss: 0.07172606140375137, auc_score: 0.7059484848365369\n",
      "Test:- after 843 epochs, loss: 0.07310086488723755, auc_score: 0.6979481182224112\n",
      "Training:- after 844 epochs, loss: 0.07170447707176208, auc_score: 0.7055388126596345\n",
      "Test:- after 844 epochs, loss: 0.0731649324297905, auc_score: 0.7047724359093922\n",
      "Training:- after 845 epochs, loss: 0.07172021269798279, auc_score: 0.7067692154441257\n",
      "Test:- after 845 epochs, loss: 0.07351315021514893, auc_score: 0.7029460851789264\n",
      "Training:- after 846 epochs, loss: 0.07171556353569031, auc_score: 0.7049503642042697\n",
      "Test:- after 846 epochs, loss: 0.07338625937700272, auc_score: 0.7036682321723225\n",
      "Training:- after 847 epochs, loss: 0.07178224623203278, auc_score: 0.7068680631254917\n",
      "Test:- after 847 epochs, loss: 0.07389743626117706, auc_score: 0.7038004079764938\n",
      "Training:- after 848 epochs, loss: 0.07175106555223465, auc_score: 0.7077878638324393\n",
      "Test:- after 848 epochs, loss: 0.07339892536401749, auc_score: 0.7113571000468781\n",
      "Training:- after 849 epochs, loss: 0.07180599123239517, auc_score: 0.7052090094187738\n",
      "Test:- after 849 epochs, loss: 0.07322810590267181, auc_score: 0.705107944039701\n",
      "Training:- after 850 epochs, loss: 0.07180049270391464, auc_score: 0.7063647775105965\n",
      "Test:- after 850 epochs, loss: 0.07341247797012329, auc_score: 0.7017583401412312\n",
      "Training:- after 851 epochs, loss: 0.07174189388751984, auc_score: 0.7082639528122814\n",
      "Test:- after 851 epochs, loss: 0.0731702670454979, auc_score: 0.7039256732979945\n",
      "Training:- after 852 epochs, loss: 0.07171370089054108, auc_score: 0.7051405236733703\n",
      "Test:- after 852 epochs, loss: 0.07325541228055954, auc_score: 0.7023016632409573\n",
      "Training:- after 853 epochs, loss: 0.07182066142559052, auc_score: 0.7068093112344501\n",
      "Test:- after 853 epochs, loss: 0.07313397526741028, auc_score: 0.7056466135215421\n",
      "Training:- after 854 epochs, loss: 0.07198145240545273, auc_score: 0.7069037032343598\n",
      "Test:- after 854 epochs, loss: 0.07328958064317703, auc_score: 0.7014583543165802\n",
      "Training:- after 855 epochs, loss: 0.07167018949985504, auc_score: 0.7066883574999603\n",
      "Test:- after 855 epochs, loss: 0.07327654212713242, auc_score: 0.7039445955238226\n",
      "Training:- after 856 epochs, loss: 0.07166312634944916, auc_score: 0.7077201714900114\n",
      "Test:- after 856 epochs, loss: 0.07332419604063034, auc_score: 0.7039007327660707\n",
      "Training:- after 857 epochs, loss: 0.07177800685167313, auc_score: 0.7069691611070537\n",
      "Test:- after 857 epochs, loss: 0.07309376448392868, auc_score: 0.7038781361405497\n",
      "Training:- after 858 epochs, loss: 0.07173068821430206, auc_score: 0.7077821115371918\n",
      "Test:- after 858 epochs, loss: 0.07343738526105881, auc_score: 0.7031364762817811\n",
      "Training:- after 859 epochs, loss: 0.07169832289218903, auc_score: 0.7068321768529366\n",
      "Test:- after 859 epochs, loss: 0.07333439588546753, auc_score: 0.7057830885598717\n",
      "Training:- after 860 epochs, loss: 0.0718354806303978, auc_score: 0.7056946064710111\n",
      "Test:- after 860 epochs, loss: 0.07330331951379776, auc_score: 0.700134410908553\n",
      "Training:- after 861 epochs, loss: 0.0715552344918251, auc_score: 0.7077696078466535\n",
      "Test:- after 861 epochs, loss: 0.07322421669960022, auc_score: 0.70399687023214\n",
      "Training:- after 862 epochs, loss: 0.07168564945459366, auc_score: 0.7058048066714949\n",
      "Test:- after 862 epochs, loss: 0.07315708696842194, auc_score: 0.701133999947775\n",
      "Training:- after 863 epochs, loss: 0.0716254934668541, auc_score: 0.7063914038532503\n",
      "Test:- after 863 epochs, loss: 0.07317196577787399, auc_score: 0.7071956962894157\n",
      "Training:- after 864 epochs, loss: 0.07167594879865646, auc_score: 0.7072515627993023\n",
      "Test:- after 864 epochs, loss: 0.07323803752660751, auc_score: 0.7040590552502881\n",
      "Training:- after 865 epochs, loss: 0.07169850915670395, auc_score: 0.7078720879265027\n",
      "Test:- after 865 epochs, loss: 0.07333807647228241, auc_score: 0.7070965962997366\n",
      "Training:- after 866 epochs, loss: 0.07175570726394653, auc_score: 0.7056886123654539\n",
      "Test:- after 866 epochs, loss: 0.07304921001195908, auc_score: 0.7060277967404158\n",
      "Training:- after 867 epochs, loss: 0.07185494154691696, auc_score: 0.7048499171515236\n",
      "Test:- after 867 epochs, loss: 0.0730382651090622, auc_score: 0.7046633043733439\n",
      "Training:- after 868 epochs, loss: 0.07176961749792099, auc_score: 0.7058857440647923\n",
      "Test:- after 868 epochs, loss: 0.07315019518136978, auc_score: 0.7062091292978353\n",
      "Training:- after 869 epochs, loss: 0.07164555788040161, auc_score: 0.7053282265515646\n",
      "Test:- after 869 epochs, loss: 0.07354819774627686, auc_score: 0.705241860676214\n",
      "Training:- after 870 epochs, loss: 0.07176055759191513, auc_score: 0.706095812318869\n",
      "Test:- after 870 epochs, loss: 0.07350572943687439, auc_score: 0.7076158088715303\n",
      "Training:- after 871 epochs, loss: 0.07176072895526886, auc_score: 0.7064679208868103\n",
      "Test:- after 871 epochs, loss: 0.0735364481806755, auc_score: 0.6982580516604431\n",
      "Training:- after 872 epochs, loss: 0.07174838334321976, auc_score: 0.7074848353448153\n",
      "Test:- after 872 epochs, loss: 0.07333248108625412, auc_score: 0.7103949606634063\n",
      "Training:- after 873 epochs, loss: 0.07179126888513565, auc_score: 0.7082324629558898\n",
      "Test:- after 873 epochs, loss: 0.07326136529445648, auc_score: 0.7028419958394108\n",
      "Training:- after 874 epochs, loss: 0.0716678723692894, auc_score: 0.7090932198976502\n",
      "Test:- after 874 epochs, loss: 0.07331119477748871, auc_score: 0.7045741457797872\n",
      "Training:- after 875 epochs, loss: 0.07165127992630005, auc_score: 0.7076917632309605\n",
      "Test:- after 875 epochs, loss: 0.07311233133077621, auc_score: 0.7073882416722933\n",
      "Training:- after 876 epochs, loss: 0.07178658246994019, auc_score: 0.708398422892186\n",
      "Test:- after 876 epochs, loss: 0.07358315587043762, auc_score: 0.7058345892195226\n",
      "Training:- after 877 epochs, loss: 0.07163489609956741, auc_score: 0.7059607235647148\n",
      "Test:- after 877 epochs, loss: 0.07333305478096008, auc_score: 0.7039402714206311\n",
      "Training:- after 878 epochs, loss: 0.07161638885736465, auc_score: 0.7066517120578043\n",
      "Test:- after 878 epochs, loss: 0.07343456894159317, auc_score: 0.7045494508295688\n",
      "Training:- after 879 epochs, loss: 0.07163354754447937, auc_score: 0.7071974525976474\n",
      "Test:- after 879 epochs, loss: 0.0730731263756752, auc_score: 0.7026218209603674\n",
      "Training:- after 880 epochs, loss: 0.0717458426952362, auc_score: 0.7077644225787725\n",
      "Test:- after 880 epochs, loss: 0.07356047630310059, auc_score: 0.7071876356139482\n",
      "Training:- after 881 epochs, loss: 0.07181869447231293, auc_score: 0.707739065839184\n",
      "Test:- after 881 epochs, loss: 0.07359927892684937, auc_score: 0.7042655241832698\n",
      "Training:- after 882 epochs, loss: 0.07156301289796829, auc_score: 0.7061172203475521\n",
      "Test:- after 882 epochs, loss: 0.07328639179468155, auc_score: 0.7042759971549825\n",
      "Training:- after 883 epochs, loss: 0.0716652050614357, auc_score: 0.707492177809987\n",
      "Test:- after 883 epochs, loss: 0.07335735857486725, auc_score: 0.7085937867206823\n",
      "Training:- after 884 epochs, loss: 0.07162228226661682, auc_score: 0.7094081240022263\n",
      "Test:- after 884 epochs, loss: 0.0731443390250206, auc_score: 0.7017341674407154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 885 epochs, loss: 0.07167796045541763, auc_score: 0.705589696118399\n",
      "Test:- after 885 epochs, loss: 0.07312213629484177, auc_score: 0.7047446261127338\n",
      "Training:- after 886 epochs, loss: 0.07178007811307907, auc_score: 0.706560103943606\n",
      "Test:- after 886 epochs, loss: 0.07311741262674332, auc_score: 0.7058335695891512\n",
      "Training:- after 887 epochs, loss: 0.07162037491798401, auc_score: 0.706944047266119\n",
      "Test:- after 887 epochs, loss: 0.07303730398416519, auc_score: 0.7040797742637833\n",
      "Training:- after 888 epochs, loss: 0.072003573179245, auc_score: 0.707765588591251\n",
      "Test:- after 888 epochs, loss: 0.07317615300416946, auc_score: 0.7077531605432889\n",
      "Training:- after 889 epochs, loss: 0.07167273014783859, auc_score: 0.7075743235622493\n",
      "Test:- after 889 epochs, loss: 0.07328885048627853, auc_score: 0.7048851454776285\n",
      "Training:- after 890 epochs, loss: 0.07163666933774948, auc_score: 0.7069533977264755\n",
      "Test:- after 890 epochs, loss: 0.07301867753267288, auc_score: 0.7062895029053249\n",
      "Training:- after 891 epochs, loss: 0.07166951894760132, auc_score: 0.7080190120288707\n",
      "Test:- after 891 epochs, loss: 0.07350438088178635, auc_score: 0.7045512040964271\n",
      "Training:- after 892 epochs, loss: 0.07169543206691742, auc_score: 0.7073006453451152\n",
      "Test:- after 892 epochs, loss: 0.0733964592218399, auc_score: 0.705785836588068\n",
      "Training:- after 893 epochs, loss: 0.07158409804105759, auc_score: 0.709151865130953\n",
      "Test:- after 893 epochs, loss: 0.0734172835946083, auc_score: 0.7076020127752224\n",
      "Training:- after 894 epochs, loss: 0.07163599878549576, auc_score: 0.7069044176829052\n",
      "Test:- after 894 epochs, loss: 0.07313793152570724, auc_score: 0.706001367175114\n",
      "Training:- after 895 epochs, loss: 0.07162263989448547, auc_score: 0.7084464592423306\n",
      "Test:- after 895 epochs, loss: 0.07289234548807144, auc_score: 0.7058907652574629\n",
      "Training:- after 896 epochs, loss: 0.07182428240776062, auc_score: 0.707547790817203\n",
      "Test:- after 896 epochs, loss: 0.07350639253854752, auc_score: 0.702241700892674\n",
      "Training:- after 897 epochs, loss: 0.07160548120737076, auc_score: 0.7072686309067839\n",
      "Test:- after 897 epochs, loss: 0.07307019084692001, auc_score: 0.7043591343338145\n",
      "Training:- after 898 epochs, loss: 0.07174120098352432, auc_score: 0.7067601819887739\n",
      "Test:- after 898 epochs, loss: 0.07343737781047821, auc_score: 0.7084460024893903\n",
      "Training:- after 899 epochs, loss: 0.07169631123542786, auc_score: 0.706532913146036\n",
      "Test:- after 899 epochs, loss: 0.07323944568634033, auc_score: 0.7062214643384277\n",
      "Training:- after 900 epochs, loss: 0.07168050110340118, auc_score: 0.706879816847885\n",
      "Test:- after 900 epochs, loss: 0.07322288304567337, auc_score: 0.7023398185555318\n",
      "Training:- after 901 epochs, loss: 0.07158096134662628, auc_score: 0.706736771802389\n",
      "Test:- after 901 epochs, loss: 0.07314631342887878, auc_score: 0.7045823401263098\n",
      "Training:- after 902 epochs, loss: 0.07166808098554611, auc_score: 0.7069405900910637\n",
      "Test:- after 902 epochs, loss: 0.07345234602689743, auc_score: 0.7061229798573264\n",
      "Training:- after 903 epochs, loss: 0.07166402786970139, auc_score: 0.7063681723532069\n",
      "Test:- after 903 epochs, loss: 0.07313965260982513, auc_score: 0.6997053392571371\n",
      "Training:- after 904 epochs, loss: 0.0720401406288147, auc_score: 0.7069972066506404\n",
      "Test:- after 904 epochs, loss: 0.0731484517455101, auc_score: 0.7029719178874254\n",
      "Training:- after 905 epochs, loss: 0.07181310653686523, auc_score: 0.7086698958270006\n",
      "Test:- after 905 epochs, loss: 0.07291293144226074, auc_score: 0.7057742227494457\n",
      "Training:- after 906 epochs, loss: 0.07174108922481537, auc_score: 0.708081812065908\n",
      "Test:- after 906 epochs, loss: 0.07313188910484314, auc_score: 0.703251542190937\n",
      "Training:- after 907 epochs, loss: 0.07173948734998703, auc_score: 0.7075362500145257\n",
      "Test:- after 907 epochs, loss: 0.07294230163097382, auc_score: 0.7057381315646476\n",
      "Training:- after 908 epochs, loss: 0.07167923450469971, auc_score: 0.7078538095801891\n",
      "Test:- after 908 epochs, loss: 0.07313177734613419, auc_score: 0.7044844618278987\n",
      "Training:- after 909 epochs, loss: 0.07175985723733902, auc_score: 0.7069436473490688\n",
      "Test:- after 909 epochs, loss: 0.07317323237657547, auc_score: 0.7021489891359627\n",
      "Training:- after 910 epochs, loss: 0.07191161811351776, auc_score: 0.7071685653681757\n",
      "Test:- after 910 epochs, loss: 0.07315865904092789, auc_score: 0.707621709049717\n",
      "Training:- after 911 epochs, loss: 0.07170210033655167, auc_score: 0.7071596017647384\n",
      "Test:- after 911 epochs, loss: 0.07358955591917038, auc_score: 0.7035969357620432\n",
      "Training:- after 912 epochs, loss: 0.07149608433246613, auc_score: 0.7060316409680468\n",
      "Test:- after 912 epochs, loss: 0.07409355789422989, auc_score: 0.7104833016874883\n",
      "Training:- after 913 epochs, loss: 0.07170481979846954, auc_score: 0.707327549017678\n",
      "Test:- after 913 epochs, loss: 0.0731581449508667, auc_score: 0.7059689006519418\n",
      "Training:- after 914 epochs, loss: 0.07202403992414474, auc_score: 0.706534368855972\n",
      "Test:- after 914 epochs, loss: 0.07330255955457687, auc_score: 0.709744971170573\n",
      "Training:- after 915 epochs, loss: 0.0720212534070015, auc_score: 0.7053779905987734\n",
      "Test:- after 915 epochs, loss: 0.07332958281040192, auc_score: 0.7076068435849707\n",
      "Training:- after 916 epochs, loss: 0.0719563290476799, auc_score: 0.709245218949366\n",
      "Test:- after 916 epochs, loss: 0.07339397072792053, auc_score: 0.707969601958685\n",
      "Training:- after 917 epochs, loss: 0.07162044197320938, auc_score: 0.7085932990474875\n",
      "Test:- after 917 epochs, loss: 0.07324478775262833, auc_score: 0.7086629319595679\n",
      "Training:- after 918 epochs, loss: 0.07190386950969696, auc_score: 0.7074740473795542\n",
      "Test:- after 918 epochs, loss: 0.07313093543052673, auc_score: 0.6978950787913152\n",
      "Training:- after 919 epochs, loss: 0.07174337655305862, auc_score: 0.7078127775169683\n",
      "Test:- after 919 epochs, loss: 0.07328714430332184, auc_score: 0.7060766519566334\n",
      "Training:- after 920 epochs, loss: 0.07176250219345093, auc_score: 0.7061166566841586\n",
      "Test:- after 920 epochs, loss: 0.07333964854478836, auc_score: 0.7054917136380536\n",
      "Training:- after 921 epochs, loss: 0.07189631462097168, auc_score: 0.7066743834563083\n",
      "Test:- after 921 epochs, loss: 0.07368891686201096, auc_score: 0.7080809375128231\n",
      "Training:- after 922 epochs, loss: 0.07172895222902298, auc_score: 0.7075785754265053\n",
      "Test:- after 922 epochs, loss: 0.07376416027545929, auc_score: 0.6998441861795321\n",
      "Training:- after 923 epochs, loss: 0.0715717300772667, auc_score: 0.7082923563221936\n",
      "Test:- after 923 epochs, loss: 0.07334266602993011, auc_score: 0.7040477211882922\n",
      "Training:- after 924 epochs, loss: 0.07157202064990997, auc_score: 0.7070641166714163\n",
      "Test:- after 924 epochs, loss: 0.07313217967748642, auc_score: 0.7098397035362521\n",
      "Training:- after 925 epochs, loss: 0.0718027725815773, auc_score: 0.7081728366296947\n",
      "Test:- after 925 epochs, loss: 0.07336188107728958, auc_score: 0.7046707588661213\n",
      "Training:- after 926 epochs, loss: 0.0717383399605751, auc_score: 0.707446154006285\n",
      "Test:- after 926 epochs, loss: 0.07302414625883102, auc_score: 0.7043570826385548\n",
      "Training:- after 927 epochs, loss: 0.07157883793115616, auc_score: 0.708021483164014\n",
      "Test:- after 927 epochs, loss: 0.07316754013299942, auc_score: 0.7051266610960032\n",
      "Training:- after 928 epochs, loss: 0.07167460024356842, auc_score: 0.7088886835985759\n",
      "Test:- after 928 epochs, loss: 0.0735614076256752, auc_score: 0.7092052074512598\n",
      "Training:- after 929 epochs, loss: 0.07156985253095627, auc_score: 0.7077508846643531\n",
      "Test:- after 929 epochs, loss: 0.07315162569284439, auc_score: 0.7089602350372352\n",
      "Training:- after 930 epochs, loss: 0.07166258245706558, auc_score: 0.7091837851801536\n",
      "Test:- after 930 epochs, loss: 0.07332786917686462, auc_score: 0.7104617495613723\n",
      "Training:- after 931 epochs, loss: 0.07165428251028061, auc_score: 0.709230798981383\n",
      "Test:- after 931 epochs, loss: 0.0731603279709816, auc_score: 0.7106504433526939\n",
      "Training:- after 932 epochs, loss: 0.07157982140779495, auc_score: 0.7081579283908944\n",
      "Test:- after 932 epochs, loss: 0.07321231067180634, auc_score: 0.707178116991394\n",
      "Training:- after 933 epochs, loss: 0.07174817472696304, auc_score: 0.7091528183226558\n",
      "Test:- after 933 epochs, loss: 0.07297932356595993, auc_score: 0.7042870856352733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 934 epochs, loss: 0.07153160125017166, auc_score: 0.7056264760205428\n",
      "Test:- after 934 epochs, loss: 0.07341409474611282, auc_score: 0.7033728813137814\n",
      "Training:- after 935 epochs, loss: 0.07167135924100876, auc_score: 0.7066838609561237\n",
      "Test:- after 935 epochs, loss: 0.0737447738647461, auc_score: 0.7059803186469256\n",
      "Training:- after 936 epochs, loss: 0.0716237872838974, auc_score: 0.7065074678547996\n",
      "Test:- after 936 epochs, loss: 0.07328560948371887, auc_score: 0.702853932975468\n",
      "Training:- after 937 epochs, loss: 0.07152293622493744, auc_score: 0.7088005450269818\n",
      "Test:- after 937 epochs, loss: 0.07329583168029785, auc_score: 0.7041710529424419\n",
      "Training:- after 938 epochs, loss: 0.07164042443037033, auc_score: 0.7073960870036067\n",
      "Test:- after 938 epochs, loss: 0.07306408137083054, auc_score: 0.7070643660323819\n",
      "Training:- after 939 epochs, loss: 0.07179688662290573, auc_score: 0.7067180753339936\n",
      "Test:- after 939 epochs, loss: 0.07312721759080887, auc_score: 0.7070619195412161\n",
      "Training:- after 940 epochs, loss: 0.07213041186332703, auc_score: 0.7078554249799122\n",
      "Test:- after 940 epochs, loss: 0.07349340617656708, auc_score: 0.7040276207920041\n",
      "Training:- after 941 epochs, loss: 0.07149819284677505, auc_score: 0.7101818665330867\n",
      "Test:- after 941 epochs, loss: 0.07306371629238129, auc_score: 0.7082009585768945\n",
      "Training:- after 942 epochs, loss: 0.07169017195701599, auc_score: 0.7080037648202994\n",
      "Test:- after 942 epochs, loss: 0.0729999989271164, auc_score: 0.7037634463755249\n",
      "Training:- after 943 epochs, loss: 0.07177788764238358, auc_score: 0.7092780205574283\n",
      "Test:- after 943 epochs, loss: 0.07346484810113907, auc_score: 0.7074479646561296\n",
      "Training:- after 944 epochs, loss: 0.07170972228050232, auc_score: 0.7085252954385973\n",
      "Test:- after 944 epochs, loss: 0.07313486933708191, auc_score: 0.7049493697565198\n",
      "Training:- after 945 epochs, loss: 0.07162997871637344, auc_score: 0.7101771164050342\n",
      "Test:- after 945 epochs, loss: 0.07323253154754639, auc_score: 0.7076620932514147\n",
      "Training:- after 946 epochs, loss: 0.07154985517263412, auc_score: 0.7077878957901849\n",
      "Test:- after 946 epochs, loss: 0.07305847108364105, auc_score: 0.7034321566550156\n",
      "Training:- after 947 epochs, loss: 0.07163097709417343, auc_score: 0.7078432057429908\n",
      "Test:- after 947 epochs, loss: 0.073605015873909, auc_score: 0.7058969700813094\n",
      "Training:- after 948 epochs, loss: 0.07172512263059616, auc_score: 0.7089747490722101\n",
      "Test:- after 948 epochs, loss: 0.07304438203573227, auc_score: 0.7059931355250412\n",
      "Training:- after 949 epochs, loss: 0.07155293971300125, auc_score: 0.7077385910242595\n",
      "Test:- after 949 epochs, loss: 0.07335073500871658, auc_score: 0.7002452770596843\n",
      "Training:- after 950 epochs, loss: 0.07161011546850204, auc_score: 0.7081510725145536\n",
      "Test:- after 950 epochs, loss: 0.07301612198352814, auc_score: 0.7060761048378974\n",
      "Training:- after 951 epochs, loss: 0.07185892015695572, auc_score: 0.708180214614466\n",
      "Test:- after 951 epochs, loss: 0.07311177253723145, auc_score: 0.7039401595099806\n",
      "Training:- after 952 epochs, loss: 0.07165802270174026, auc_score: 0.7075734904841782\n",
      "Test:- after 952 epochs, loss: 0.07312147319316864, auc_score: 0.7047936398690396\n",
      "Training:- after 953 epochs, loss: 0.07162834703922272, auc_score: 0.7079978513511589\n",
      "Test:- after 953 epochs, loss: 0.07319393754005432, auc_score: 0.7076362139134781\n",
      "Training:- after 954 epochs, loss: 0.07160354405641556, auc_score: 0.7083264402966314\n",
      "Test:- after 954 epochs, loss: 0.07315728068351746, auc_score: 0.7066249581889376\n",
      "Training:- after 955 epochs, loss: 0.07158038765192032, auc_score: 0.707932421775416\n",
      "Test:- after 955 epochs, loss: 0.07306746393442154, auc_score: 0.7017742780830452\n",
      "Training:- after 956 epochs, loss: 0.07179971784353256, auc_score: 0.7082581749904135\n",
      "Test:- after 956 epochs, loss: 0.07327926158905029, auc_score: 0.708570978708377\n",
      "Training:- after 957 epochs, loss: 0.07163166254758835, auc_score: 0.707824269542034\n",
      "Test:- after 957 epochs, loss: 0.07285689562559128, auc_score: 0.701910283718368\n",
      "Training:- after 958 epochs, loss: 0.07155252248048782, auc_score: 0.7084508656514733\n",
      "Test:- after 958 epochs, loss: 0.0731036588549614, auc_score: 0.7077264760703943\n",
      "Training:- after 959 epochs, loss: 0.0716567113995552, auc_score: 0.7082624071655319\n",
      "Test:- after 959 epochs, loss: 0.0734521821141243, auc_score: 0.7070320518320394\n",
      "Training:- after 960 epochs, loss: 0.07159923762083054, auc_score: 0.7089184275528718\n",
      "Test:- after 960 epochs, loss: 0.07297436147928238, auc_score: 0.7062141901461428\n",
      "Training:- after 961 epochs, loss: 0.07166623324155807, auc_score: 0.7059005251651935\n",
      "Test:- after 961 epochs, loss: 0.07429887354373932, auc_score: 0.7042210023961313\n",
      "Training:- after 962 epochs, loss: 0.07155681401491165, auc_score: 0.706642693740332\n",
      "Test:- after 962 epochs, loss: 0.07339559495449066, auc_score: 0.7059274626249512\n",
      "Training:- after 963 epochs, loss: 0.07169611006975174, auc_score: 0.7090083268676202\n",
      "Test:- after 963 epochs, loss: 0.07322236895561218, auc_score: 0.7033174544554739\n",
      "Training:- after 964 epochs, loss: 0.07167153060436249, auc_score: 0.707847217281043\n",
      "Test:- after 964 epochs, loss: 0.07396426051855087, auc_score: 0.7050643051032499\n",
      "Training:- after 965 epochs, loss: 0.07156967371702194, auc_score: 0.7083353671931847\n",
      "Test:- after 965 epochs, loss: 0.07299453765153885, auc_score: 0.7050162923255405\n",
      "Training:- after 966 epochs, loss: 0.07183035463094711, auc_score: 0.7077184038210302\n",
      "Test:- after 966 epochs, loss: 0.07329508662223816, auc_score: 0.703130106700588\n",
      "Training:- after 967 epochs, loss: 0.0717492401599884, auc_score: 0.7069880386363602\n",
      "Test:- after 967 epochs, loss: 0.0732603445649147, auc_score: 0.7095492891808513\n",
      "Training:- after 968 epochs, loss: 0.07162140309810638, auc_score: 0.7076562480838031\n",
      "Test:- after 968 epochs, loss: 0.0732273980975151, auc_score: 0.7103907142759442\n",
      "Training:- after 969 epochs, loss: 0.07171383500099182, auc_score: 0.7099598855594124\n",
      "Test:- after 969 epochs, loss: 0.07297171652317047, auc_score: 0.7078171734353959\n",
      "Training:- after 970 epochs, loss: 0.07170363515615463, auc_score: 0.7092129857538356\n",
      "Test:- after 970 epochs, loss: 0.07325588911771774, auc_score: 0.7114575491816222\n",
      "Training:- after 971 epochs, loss: 0.07148473709821701, auc_score: 0.708626297052221\n",
      "Test:- after 971 epochs, loss: 0.0731436014175415, auc_score: 0.7062914799934843\n",
      "Training:- after 972 epochs, loss: 0.07156486809253693, auc_score: 0.7080389306089451\n",
      "Test:- after 972 epochs, loss: 0.0732489749789238, auc_score: 0.7092853634547067\n",
      "Training:- after 973 epochs, loss: 0.0715707466006279, auc_score: 0.7079956466624817\n",
      "Test:- after 973 epochs, loss: 0.07315288484096527, auc_score: 0.705570697688299\n",
      "Training:- after 974 epochs, loss: 0.07165057212114334, auc_score: 0.7100494591624018\n",
      "Test:- after 974 epochs, loss: 0.0731203705072403, auc_score: 0.702618715439815\n",
      "Training:- after 975 epochs, loss: 0.07171755284070969, auc_score: 0.7070488381976823\n",
      "Test:- after 975 epochs, loss: 0.073130764067173, auc_score: 0.7050535492462817\n",
      "Training:- after 976 epochs, loss: 0.07160279154777527, auc_score: 0.7060585662096144\n",
      "Test:- after 976 epochs, loss: 0.07305652648210526, auc_score: 0.7065972634115589\n",
      "Training:- after 977 epochs, loss: 0.07158330827951431, auc_score: 0.7087021133899496\n",
      "Test:- after 977 epochs, loss: 0.07315327972173691, auc_score: 0.7037924934065974\n",
      "Training:- after 978 epochs, loss: 0.07146506011486053, auc_score: 0.7073944797169954\n",
      "Test:- after 978 epochs, loss: 0.07320259511470795, auc_score: 0.7066984897035984\n",
      "Training:- after 979 epochs, loss: 0.07150352746248245, auc_score: 0.707594789480553\n",
      "Test:- after 979 epochs, loss: 0.07306455820798874, auc_score: 0.7062363671067242\n",
      "Training:- after 980 epochs, loss: 0.07151658087968826, auc_score: 0.7084502855639755\n",
      "Test:- after 980 epochs, loss: 0.07279165089130402, auc_score: 0.705389613821214\n",
      "Training:- after 981 epochs, loss: 0.07162602245807648, auc_score: 0.7108153062502589\n",
      "Test:- after 981 epochs, loss: 0.07306492328643799, auc_score: 0.7110143923313849\n",
      "Training:- after 982 epochs, loss: 0.07159938663244247, auc_score: 0.7094469094260454\n",
      "Test:- after 982 epochs, loss: 0.07308603823184967, auc_score: 0.7110341632129797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:- after 983 epochs, loss: 0.07153873890638351, auc_score: 0.7106608448690941\n",
      "Test:- after 983 epochs, loss: 0.07338330149650574, auc_score: 0.7081245733406449\n",
      "Training:- after 984 epochs, loss: 0.0716761127114296, auc_score: 0.709509667017656\n",
      "Test:- after 984 epochs, loss: 0.07281828671693802, auc_score: 0.707928580488005\n",
      "Training:- after 985 epochs, loss: 0.07160894572734833, auc_score: 0.710307154351295\n",
      "Test:- after 985 epochs, loss: 0.07294487953186035, auc_score: 0.7086090438727054\n",
      "Training:- after 986 epochs, loss: 0.07164595276117325, auc_score: 0.7080036540070641\n",
      "Test:- after 986 epochs, loss: 0.07301667332649231, auc_score: 0.7059291257415635\n",
      "Training:- after 987 epochs, loss: 0.07173942774534225, auc_score: 0.7080312676758549\n",
      "Test:- after 987 epochs, loss: 0.07299644500017166, auc_score: 0.7069121115923269\n",
      "Training:- after 988 epochs, loss: 0.07155027985572815, auc_score: 0.7072961952043209\n",
      "Test:- after 988 epochs, loss: 0.07367369532585144, auc_score: 0.7077683617399868\n",
      "Training:- after 989 epochs, loss: 0.07147377729415894, auc_score: 0.7066992719110379\n",
      "Test:- after 989 epochs, loss: 0.07298864424228668, auc_score: 0.7074278051958871\n",
      "Training:- after 990 epochs, loss: 0.07163600623607635, auc_score: 0.7082688994359453\n",
      "Test:- after 990 epochs, loss: 0.07326751202344894, auc_score: 0.7051468765115709\n",
      "Training:- after 991 epochs, loss: 0.07151228934526443, auc_score: 0.7075475643426539\n",
      "Test:- after 991 epochs, loss: 0.0731903463602066, auc_score: 0.7042449015372794\n",
      "Training:- after 992 epochs, loss: 0.07156011462211609, auc_score: 0.7071735336597849\n",
      "Test:- after 992 epochs, loss: 0.07293134927749634, auc_score: 0.7066739750538725\n",
      "Training:- after 993 epochs, loss: 0.07150831073522568, auc_score: 0.7067823075331544\n",
      "Test:- after 993 epochs, loss: 0.07287948578596115, auc_score: 0.708844087325124\n",
      "Training:- after 994 epochs, loss: 0.07151539623737335, auc_score: 0.7095207741646106\n",
      "Test:- after 994 epochs, loss: 0.07303979992866516, auc_score: 0.7076928748975706\n",
      "Training:- after 995 epochs, loss: 0.07149399071931839, auc_score: 0.7096644183930992\n",
      "Test:- after 995 epochs, loss: 0.07342348992824554, auc_score: 0.7047711675886862\n",
      "Training:- after 996 epochs, loss: 0.0716266855597496, auc_score: 0.7096617081190368\n",
      "Test:- after 996 epochs, loss: 0.0730048194527626, auc_score: 0.7074276248953946\n",
      "Training:- after 997 epochs, loss: 0.0716564729809761, auc_score: 0.7099624067583924\n",
      "Test:- after 997 epochs, loss: 0.07289088517427444, auc_score: 0.7081106902027199\n",
      "Training:- after 998 epochs, loss: 0.07149671763181686, auc_score: 0.7084837834155517\n",
      "Test:- after 998 epochs, loss: 0.0730205699801445, auc_score: 0.7063884008341074\n",
      "Training:- after 999 epochs, loss: 0.07149185240268707, auc_score: 0.7092443043444145\n",
      "Test:- after 999 epochs, loss: 0.07318234443664551, auc_score: 0.7097429909737842\n",
      "Training:- after 1000 epochs, loss: 0.07157854735851288, auc_score: 0.7077452216133359\n",
      "Test:- after 1000 epochs, loss: 0.07305308431386948, auc_score: 0.7092420074035113\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, path2)\n",
    "    for epoch in range(1, 1000+1):\n",
    "        _ = sess.run(train_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "        if 500%10 == 0:\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_tr})\n",
    "            print('Training:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_ts, y1_nn:y_ts.reshape(y_ts.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_ts})\n",
    "            print('Test:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path2 = saver2.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [256,512] rhs shape= [512,1024]\n\t [[Node: save_5/Assign_4 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_1/Adam, save_5/RestoreV2/_9)]]\n\t [[Node: save_5/RestoreV2/_34 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_40_save_5/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save_5/RestoreV2:17)]]\n\nCaused by op 'save_5/Assign_4', defined at:\n  File \"c:\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\python\\python36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"c:\\python\\python36\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"c:\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-63-60118ab78e8e>\", line 25, in <module>\n    saver2 = tf.train.Saver()\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 63, in assign\n    use_locking=use_locking, name=name)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [256,512] rhs shape= [512,1024]\n\t [[Node: save_5/Assign_4 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_1/Adam, save_5/RestoreV2/_9)]]\n\t [[Node: save_5/RestoreV2/_34 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_40_save_5/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save_5/RestoreV2:17)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [256,512] rhs shape= [512,1024]\n\t [[Node: save_5/Assign_4 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_1/Adam, save_5/RestoreV2/_9)]]\n\t [[Node: save_5/RestoreV2/_34 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_40_save_5/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save_5/RestoreV2:17)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1724\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1725\u001b[1;33m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1726\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [256,512] rhs shape= [512,1024]\n\t [[Node: save_5/Assign_4 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_1/Adam, save_5/RestoreV2/_9)]]\n\t [[Node: save_5/RestoreV2/_34 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_40_save_5/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save_5/RestoreV2:17)]]\n\nCaused by op 'save_5/Assign_4', defined at:\n  File \"c:\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\python\\python36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"c:\\python\\python36\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"c:\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-63-60118ab78e8e>\", line 25, in <module>\n    saver2 = tf.train.Saver()\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 63, in assign\n    use_locking=use_locking, name=name)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [256,512] rhs shape= [512,1024]\n\t [[Node: save_5/Assign_4 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_1/Adam, save_5/RestoreV2/_9)]]\n\t [[Node: save_5/RestoreV2/_34 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_40_save_5/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save_5/RestoreV2:17)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-62ab383103d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msaver2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX1_nn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX2_sub\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TARGET'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1757\u001b[0m       \u001b[1;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m       raise _wrap_restore_error_with_msg(\n\u001b[1;32m-> 1759\u001b[1;33m           err, \"a mismatch between the current graph and the graph\")\n\u001b[0m\u001b[0;32m   1760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m   def _restore_from_object_based_checkpoint(self, sess, save_path,\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [256,512] rhs shape= [512,1024]\n\t [[Node: save_5/Assign_4 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_1/Adam, save_5/RestoreV2/_9)]]\n\t [[Node: save_5/RestoreV2/_34 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_40_save_5/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save_5/RestoreV2:17)]]\n\nCaused by op 'save_5/Assign_4', defined at:\n  File \"c:\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\python\\python36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"c:\\python\\python36\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"c:\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-63-60118ab78e8e>\", line 25, in <module>\n    saver2 = tf.train.Saver()\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 63, in assign\n    use_locking=use_locking, name=name)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"c:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [256,512] rhs shape= [512,1024]\n\t [[Node: save_5/Assign_4 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_1/Adam, save_5/RestoreV2/_9)]]\n\t [[Node: save_5/RestoreV2/_34 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_40_save_5/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save_5/RestoreV2:17)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')\n",
    "    preds = sess.run(s, feed_dict={X1_nn:X2_sub})\n",
    "    submission['TARGET'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_nn_selec_few.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
