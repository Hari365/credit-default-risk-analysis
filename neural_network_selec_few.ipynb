{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_tr = pd.read_csv('application_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = app_tr['TARGET'].values\n",
    "app = pd.read_csv('ready_for_model_building_appl.csv')\n",
    "del app_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feats = ['CREDIT_INCOME_RATIO', 'AMT_CREDIT_SUM_DEBT', 'AMT_CREDIT_SUM', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_ENDDATE_FACT', 'CNT_INSTALMENT', 'DAYS_REGISTRATION','DAYS_LAST_DUE','DAYS_FIRST_DUE','AMT_ANNUITY_x','NAME_EDUCATION_TYPE_Higher education','ENTIRE_INCOME_PER_CHILD','AMT_CREDIT','LATE_PAYMENT_DAYS','ANNUITY_INCOME_RATIO','ENTIRE_INCOME_PER_FAM_MEMBER', 'DAYS_EMPLOYED', 'DAYS_ID_PUBLISH','HC','SCOFR','MONTHS_BALANCE_x', 'CNT_INSTALMENT_FUTURE','SK_DPD_DEF_x','DAYS_INSTALMENT','Closed','PERCENT_COMPLETION','AMT_GOODS_PRICE','ENTIRE_INCOME', 'AMT_INSTALMENT','CNT_DRAWINGS_CURRENT', 'DAYS_ENTRY_PAYMENT', 'DAYS_LAST_PHONE_CHANGE','DAYS_CREDIT_ENDDATE', 'CREDIT_GOODS_PRICE_DIFF','Active_x','DAYS_CREDIT_UPDATE', 'CNT_DRAWINGS_ATM_CURRENT','AMT_PAYMENT','ANNUITY_ENTIRE_INCOME_RATIO', 'DAYS_BIRTH', 'XAP', 'CREDIT_ENTIRE_INCOME_RATIO', 'YOKIAN_SCORE', 'DAYS_CREDIT', 'EXT_SOURCE_1', 'EXT_SOURCE_3', 'EXT_SOURCE_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = app[selected_feats].values\n",
    "X2_sub = X2[y.shape[0]:, :]\n",
    "X2 = X2[:y.shape[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(app[selected_feats].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = scaler2.transform(X2)\n",
    "X2_sub = scaler2.transform(X2_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_tr, X2_ts, y_tr, y_ts = train_test_split(X2, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hid_layer1 = 512\n",
    "num_hid_layer2 = 1024\n",
    "num_hid_layer3 = 256\n",
    "n_out = 1\n",
    "n_in = X2.shape[1]\n",
    "alpha = 0.0005\n",
    "epochs = 3000\n",
    "p1 = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    X1_nn = tf.placeholder('float', [None, n_in])\n",
    "    y1_nn = tf.placeholder('float', [None, n_out])\n",
    "    weights1 = {'layer1':tf.Variable(tf.random_normal([n_in, num_hid_layer1])),\n",
    "                'layer2':tf.Variable(tf.random_normal([num_hid_layer1, num_hid_layer2])),\n",
    "                'layer3':tf.Variable(tf.random_normal([num_hid_layer2, num_hid_layer3])),\n",
    "                'out':tf.Variable(tf.random_normal([num_hid_layer3, n_out]))\n",
    "        \n",
    "    }\n",
    "    biases1 = {'layer1':tf.Variable(tf.random_normal([num_hid_layer1])),\n",
    "               'layer2':tf.Variable(tf.random_normal([num_hid_layer2])),\n",
    "               'layer3':tf.Variable(tf.random_normal([num_hid_layer3])),\n",
    "               'out':tf.Variable(tf.random_normal([n_out]))\n",
    "    }\n",
    "    h1 = tf.add(tf.matmul(X1_nn, weights1['layer1']), biases1['layer1'])\n",
    "    drop_con = tf.nn.dropout(h1, p1)*p1\n",
    "    h2 = tf.add(tf.matmul(drop_con, weights1['layer2']), biases1['layer2'])\n",
    "    h3 = tf.add(tf.matmul(h2, weights1['layer3']), biases1['layer3'])\n",
    "    s = tf.add(tf.matmul(h3, weights1['out']), biases1['out'])\n",
    "    loss_op1 = tf.losses.mean_squared_error(y1_nn, s)\n",
    "    optimizer1 = tf.train.AdamOptimizer(alpha)\n",
    "    train_op1 = optimizer1.minimize(loss_op1)\n",
    "    init_op1 = tf.global_variables_initializer()\n",
    "with tf.device('/device:CPU:0'):\n",
    "    saver2 = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op1)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        _ = sess.run(train_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "        if epoch%10 == 0:\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_tr})\n",
    "            print('Training:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_ts, y1_nn:y_ts.reshape(y_ts.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_ts})\n",
    "            print('Test:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path2 = saver2.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')\n",
    "    print(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, path2)\n",
    "    for epoch in range(1, 500+1):\n",
    "        _ = sess.run(train_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "        if epoch%10 == 0:\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_tr})\n",
    "            print('Training:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_ts, y1_nn:y_ts.reshape(y_ts.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_ts})\n",
    "            print('Test:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path2 = saver2.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, path2)\n",
    "    for epoch in range(1, 500+1):\n",
    "        _ = sess.run(train_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "        if 500%10 == 0:\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_tr})\n",
    "            print('Training:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_ts, y1_nn:y_ts.reshape(y_ts.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_ts})\n",
    "            print('Test:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path2 = saver2.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, path2)\n",
    "    for epoch in range(1, 1000+1):\n",
    "        _ = sess.run(train_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "        if 500%10 == 0:\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_tr, y1_nn:y_tr.reshape(y_tr.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_tr})\n",
    "            print('Training:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_tr, preds)))\n",
    "            loss = sess.run(loss_op1, feed_dict = {X1_nn:X2_ts, y1_nn:y_ts.reshape(y_ts.shape[0], 1)})\n",
    "            preds = sess.run(s, feed_dict = {X1_nn:X2_ts})\n",
    "            print('Test:- after {} epochs, loss: {}, auc_score: {}'.format(epoch, loss, roc_auc_score(y_ts, preds)))\n",
    "    path2 = saver2.save(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs = pd.read_csv('train_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = pd.read_csv('test_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_probs = pd.read_csv('submission_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt\n",
      "0.5667603916269951\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')\n",
    "    preds = sess.run(s, feed_dict={X1_nn:X2_tr})\n",
    "    print(roc_auc_score(y_tr, preds))\n",
    "    train_probs['nn_less'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt\n",
      "0.5608011743500125\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')\n",
    "    preds = sess.run(s, feed_dict={X1_nn:X2_ts})\n",
    "    print(roc_auc_score(y_ts, preds))\n",
    "    test_probs['nn_less'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, 'E:/kaggle/home-credit-default-risk/dnn/neuralnetwork_selec_few.ckpt')\n",
    "    preds = sess.run(s, feed_dict={X1_nn:X2_sub})\n",
    "    submission_probs['nn_less'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>best_rf</th>\n",
       "      <th>simple_xgbc</th>\n",
       "      <th>xgbc_selec_cv</th>\n",
       "      <th>xgbc_less_cv</th>\n",
       "      <th>nn_selec</th>\n",
       "      <th>nn_full</th>\n",
       "      <th>nn_less</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261379</th>\n",
       "      <td>402535</td>\n",
       "      <td>0.055408</td>\n",
       "      <td>0.046214</td>\n",
       "      <td>0.021470</td>\n",
       "      <td>0.163618</td>\n",
       "      <td>0.123099</td>\n",
       "      <td>-0.072081</td>\n",
       "      <td>-13784.418945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261380</th>\n",
       "      <td>402537</td>\n",
       "      <td>0.138368</td>\n",
       "      <td>0.067537</td>\n",
       "      <td>0.055454</td>\n",
       "      <td>0.074119</td>\n",
       "      <td>0.140188</td>\n",
       "      <td>0.216982</td>\n",
       "      <td>26009.480469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261381</th>\n",
       "      <td>402538</td>\n",
       "      <td>0.067350</td>\n",
       "      <td>0.039181</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.113988</td>\n",
       "      <td>0.158743</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>9699.157227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261382</th>\n",
       "      <td>402539</td>\n",
       "      <td>0.051280</td>\n",
       "      <td>0.191010</td>\n",
       "      <td>0.180102</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.024954</td>\n",
       "      <td>0.028505</td>\n",
       "      <td>-2246.506592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261383</th>\n",
       "      <td>402540</td>\n",
       "      <td>0.241888</td>\n",
       "      <td>0.115924</td>\n",
       "      <td>0.100112</td>\n",
       "      <td>0.037956</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>-95605.765625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0   best_rf  simple_xgbc  xgbc_selec_cv  xgbc_less_cv  \\\n",
       "261379      402535  0.055408     0.046214       0.021470      0.163618   \n",
       "261380      402537  0.138368     0.067537       0.055454      0.074119   \n",
       "261381      402538  0.067350     0.039181       0.033557      0.113988   \n",
       "261382      402539  0.051280     0.191010       0.180102      0.008170   \n",
       "261383      402540  0.241888     0.115924       0.100112      0.037956   \n",
       "\n",
       "        nn_selec   nn_full       nn_less  \n",
       "261379  0.123099 -0.072081 -13784.418945  \n",
       "261380  0.140188  0.216982  26009.480469  \n",
       "261381  0.158743  0.046083   9699.157227  \n",
       "261382  0.024954  0.028505  -2246.506592  \n",
       "261383  0.023978  0.006532 -95605.765625  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_probs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    s = np.exp(x)\n",
    "    return s/np.sum(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((train_probs['nn_less'].values, test_probs['nn_less'].values, submission_probs['nn_less'].values), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "c:\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "x = softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0., nan, ..., nan, nan, nan], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-5d82ad7b8292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    275\u001b[0m     return _average_binary_score(\n\u001b[0;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         fpr, tpr, tresholds = roc_curve(y_true, y_score,\n\u001b[1;32m--> 272\u001b[1;33m                                         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreorder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \"\"\"\n\u001b[0;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 534\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m     \u001b[0massert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \"\"\"\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "roc_auc_score(y_tr, x[:y_tr.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_nn_selec_few.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
